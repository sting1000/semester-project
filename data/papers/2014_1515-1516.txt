Designing and Validating a Story-Based Socio-Emotional LearningAssessment InstrumentMitra Fatolapour, UC Berkeley, CA, mitraf@berkeley.eduSoyeon Hwang, Mario Piergallini, Julie Shim, Steven Dow, and Carolyn Penstein Rosé,HCI Institute, Carnegie Mellon University, Pittsburgh, PASoyeonh@andrew.cmu.edu, mpiergal@andrew.cmu.edu, dshim@cmu.edu,spdow@cs.cmu.edu, cprose@cs.cmu.eduAbstract: Current assessment instruments for socio-emotional skills typically focus ondiagnosing dysfunction and need to be administered by teachers and parents. To exploresocio-emotional learning in novel environments, the learning sciences community needsscalable, easy-to-administer research instruments that measure growth in normal children. Inthis paper, we report on an iterative design process and a series of validation studies for astory-based multiple-choice assessment tool that can be used efficiently by researchers inlarge-scale evaluations of technology-based socio-emotional learning (SEL) environments.Introduction and Theoretical FrameworkTechnology enhanced learning environments such as computer games and intelligent tutors provide theopportunity for early childhood learners to collaborate in order to acquire domain-specific knowledge (Alevenet al 2013). To succeed with technology-based collaborative learning—such as online education—learningresearchers have increasingly focused on supporting development of socio-emotional skills. In order to gaugethe success of emerging technologies for early childhood education with this important goal in mind, theresearch community needs assessment instruments that are reliable and sensitive enough to measure growth ofsocial skills in normal children. This paper contributes a new assessment instrument targeting children in gradesK-3rd for measuring three socio-emotional skills: 1) asking for help, 2) discussing differences in order to resolveconflicts, and 3) cooperating to solve problems. We document our process and progress towards designing amultiple-choice story-based SEL assessment tool (see example item in Figure 1), including multiple rounds ofiteration and three validation studies. We discuss progress and remaining challenges.We hypothesize that stories provide a valuable paradigm for assessing SEL with our target population.Storytelling has been used to gain insight into the thinking processes of a child. A child can envision him orherself as a character in the story and respond through self-projection within that reality (Hordstal, 2012),Figure 1. The "Snowman" story assessment item. Students read the top row and then choose between four possibleoutcomes (bottom row), from left to right: anti-social, social (preferred solution), non-social, and mildly social.ICLS 2014 Proceedings1515© ISLSproviding insights that would not be possible through direct observation. The capability for children to engagein such self-projection develops between the ages of four and six (Waytz & Mitchell). Although stories havedrawn the attention of developmental psychologists and child psychotherapists to diagnose children’sdevelopmental disorders for therapeutic purposes (Kaland et al, 2005), they have not typically been used toassess socio-emotional skills in the broader student population.Illustrated stories have been used in the past for assessing inquiry skills. Specifically, Inquiry Comicspresents cartoons of children discussing scientific ideas in an inquiry process, from choosing a topic ofinvestigation, to collecting data and concluding results (Ainsworth, Jong, Hmelo-Silver, 2010). However, theassessment items evaluate the characters’ scientific investigation skills, not core SEL skills such as discussionand collaboration. This prior work provides inspiration for our own design and development effort.Assessment Design and Validation StudiesOur multiple-choice story-based SEL assessment tool includes twelve different story scenarios, four to measureeach of the three skills. Each assessment item consists of two story panels, a main question, and four answerchoices (see Figure 1). The first story panel introduces the context and characters. The characters are differentin each story, and we have worked to balance assignment of gender and apparent ethnicity to characters. Thesecond panel presents a conflict or challenge. Across all scenarios, the students see the same question: “If youwere [the character] how would you solve the problem?” Students choose among four answer choices,presented in random order, which have been pre-assigned to the categories of Social, Mildly Social, Non-social,and Anti-social. Answer choices are a range of hypothetical actions the main character can choose to solve theproblem. Ideas for the details of the stories and answer options were developed over a series of designworkshops and pilot studies with the target age group.We also developed and tested the digital version of this assessment tool using the Cognitive TutorAuthoring Tool (CTAT) platform (Aleven et al., 2009) with a total of 24 students in grades K-4. The onlineversion adds three more features to the paper-based version. First, it provides a voice-over feature that isenabled by default when students login. The system plays pre-recorded voice recordings for each storypanel, the main question, and the answer choices. Students can re-activate the audio recordings byclicking/tapping panels independently. Second, the digital version also supports data logging, either to thelocal computer or in an online depository. Third, the digital version can be installed on computers locally oraccessed through the Internet using a URL. The combination of multiple-choice scoring and online datalogging creates an opportunity for researchers to measure social emotional learning in large-scale studies.Through user testing, we confirmed that our story assessment instrument provides convenience sincestudents can answer questions relatively quickly; it's also easy to deploy online, especially now that the voiceover feature allows students with reading difficulty to answer questions without human assistance. Weconducted three validation studies with 283 students in K-3rd grade students and achieved moderate reliabilityscores across the three target social skills. We will share further evaluation details in subsequent papers.ConclusionsOur work demonstrates an online story-based assessment instrument to measure social-emotional growth inyoung children. Preliminary studies show that K-3rd grade children can comprehend and respond to the storyscenarios without adult supervision. We still have challenges to address in terms of isolating the specific skillsof interest and achieving the level of sensitivity desired for SEL assessment in the context of technologyenhanced learning. Future work will focus on revising our story items to support greater sensitivity to growth.ReferencesAleven, V., Dow, S., Christel M., et al (2013), Supporting Social emotional Development in CollaborativeInquiry Games for K-3 Science Learning, Games+Learning+Society Conference 9.0.Aleven, V., McLaren, B.M., Sewall, J., & Koedinger, K.R. (2009). A New Paradigm for Intelligent TutoringSystems: Example-Tracing Tutors. Intl Journal of Artificial Intelligence in Education, 19(2), 105-154.Ainsworth, S., Jong, T., Hmelo-Silver, C. (2010), On the Process of Inquiry Learning: Changing Approachesto Assessment, ICLS 2010 Vol. 2.Hordstal, M. (2012). Telling Lives: Exploring dimensions of narratives, Routledge.Jones, S. M., Bouffard, S. M. (2012), Social Emotional Learning in Schools: From Programs to Strategies,Sharing Child and Youth Developmental Knowledge, Social Policy Report, 26 (4).Kaland, N. et al (2005) The Strange Stories test- A replication Study of children and adolescents with Aspergersyndrome, Eur Child Adolesc Psychiatry, 14:73-82.Waltz, A., Mitchell, J P., (2011)Two Mechanisms for Simulating Other Minds: Dissociations BetweenMirroring and Self-Projection, Current Directions in Psychological Science, 20(3) 197-200.ICLS 2014 Proceedings1516© ISLS