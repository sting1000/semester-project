Visualizing Three-Dimensional Spatial Relationships in Virtual andPhysical Astronomy EnvironmentsP. Udomprasert, A. A. Goodman, P. Sadler, E. Lotridge, J. Jackson, and A. Constantin, Harvard UniversityEmail: pudompra@cfa.harvard.edu, agoodman@cfa.harvard.edu, psadler@cfa.harvard.eduZ.H. Zhang, Concord Consortium, Email: hzhang@concord.orgS. Sunbury and M. Dussault, Smithsonian Astrophysical Observatory,Email: ssunbury@cfa.harvard.edu, mdussault@cfa.harvard.eduAbstract: Students used both virtual and physical models in a middle school lab that teachesthe cause of lunar phases. Phase 1 compared two virtual models – a complex 3D model vs. asimplified 2D model. Students who used the 3D model had higher learning gains. Phase 2compared activity sequencing. Preliminary results indicate that students with high priorknowledge benefit from using the virtual model first. Further study may confirm if this resultis statistically significant.IntroductionWe report on the development and testing of a “Visualization Lab,” which includes both physical and virtualmodels, designed to teach middle school students about the cause of the Moon's phases and eclipses, phenomenathat require students to visualize complex 3D relationships amongst the Sun, Earth, and Moon. The virtualcomponent of the lab was implemented mainly in the WorldWide Telescope (WWT) computer program, animmersive astronomy data visualization environment. While visualizations hold promise for improving scienceeducation, research results on efficacy to date have been mixed. When implemented poorly, visualizations donot contribute to student learning, and in fact, students can become overwhelmed or confused, especially if thevisualizations are not well-matched to student ability (ChanLin, 2001). However, Linn and Eylon (2011) citeresearch that suggests the tremendous promise of visualizations, when implemented correctly. Multiple studiessupport the idea that a blend of virtual and physical models may be more advantageous than one or the otheralone (e.g. Liu, 2006). To date, little research has been done on optimal sequencing of virtual/physical modelsin classrooms, but Carmichael et al. (2010) have found evidence that students may benefit from using a physicalmodel prior to the virtual model. We seek to build on this body of knowledge in our work.Methods, Assessment, and ResultsWe use a quasi-experimental method to compare different iterations of our Moon Lab. To assess studentlearning, we created and used identical pre- and post-tests that include multiple choice content questions aboutthe Moon’s phases, and open response questions that probe understanding of the cause of the Moon’s phases.The multiple choice questions were selected from the Astronomy and Space Science Concept Inventory(ASSCI, Sadler, 2009), a compilation of distractor-driven multiple choice questions. Open-response questionsembedded throughout the activities were scored using a Knowledge Integration (KI, Linn, 2000) rubric.A.Textbook simulatorB.C. ResultsWWTFigure 1A. & B. show screenshots of the Textbook simulator and WWT respectively. Figure 1C. shows acomparison of average pre/post-test scores, gains, and Cohen’s d effect sizes for students in School A who usedWWT vs the Textbook Simulator (TS), and for students in School B who all used WWT.Phase 1Phase 1 used a treatment-control design to compare learning results in students who used the complex 3Dvisualizations in WWT as the “virtual model” vs. those who used a traditional 2D simulator. We tested the firstiteration of the lab with a sixth-grade teacher at a public middle school in a suburban Eastern Massachusettstown (School A), who teaches about 80 students in four classes. Each class had one day of pre-assessment; oneday of instruction with the physical model (Styrofoam ball and lamp); two days of instruction with the virtualmodel; then one day of post-assessment. The teacher divided her students into groups (two treatment and twoICLS 2014 Proceedings1511© ISLScontrol classes) with comparable student ability. The “treatment” group used WWT as the computer simulation,and the “control” group used a 2D simulator recommended by the students' textbook, and already in use by theteacher. The simulator can be found at http://www.astro.wisc.edu/~dolan/java/MoonPhase.html, which is usedin Activity 81, pg. F-48, of Issues and Earth Science (University of California, Berkeley, 2006). We refer to the2D visualization as the “textbook simulator” or “TS” and the 3D visualization as “WWT.” Figure 1 showssample screenshots of both the TS and WWT. Students in both Phase 1 groups (WWT and TS) showed stronglearning gains (see Figure 1), but the WWT group outperformed the TS group (t-test p=0.03; N=77).Phase 2We tested a second iteration of the VizLab with one eighth grade teacher and 70 students at a public middleschool in an urban Eastern MA city (School B). For this phase, all students used WWT as the virtual model, butwe tested two different sequencing of activities: virtual, then physical; vs. physical, then virtual. The programincluded one day of pre-assessment; one day with the first intervention; one day with the second intervention;one day using a blend of both interventions; and one day of post-assessment. Figure 1 (third row) showslearning gains and Cohen’s d effect sizes for all students in School B. The effect size measured at School B issmaller than that of both treatment and control groups at School A, but the demographics of the studentpopulations at the two schools are very different.We analyzed a median split of the pretest multiple choice scores and found that students with low priorknowledge benefited slightly from using the physical model first, while students with high prior knowledgebenefited from using the virtual model first (see Table 1). We hypothesize that students with low priorknowledge had trouble interpreting the complex 3D computer visualization because they were not familiarenough with the mechanics of the Earth-Sun-Moon system to understand what they were looking at in thecomputer model. We are unsure why the students with high prior knowledge benefitted from seeing the 3Dvisualization first, but we hypothesize that their high level of engagement with the program could have been afactor. Further study with a larger sample size is needed to confirm the statistical significance of this result.Table 1: A comparison of student learning gains in Phase 2.Low prior knowledgeHigh prior knowledgeGroup(pretest <3)(pretest ≥3)Average Gain (SD), NAverage Gain (SD), NPhysical -> VirtualGain=2.64 (1.60), N=14 Gain=0.88 (1.58), N=17Virtual -> PhysicalGain=2.10 (1.04), N=11 Gain=1.71 (1.16), N=17t-test comparing model ordert=0.99, p=0.33t=1.73, p=0.09t-test comparingLow/High groups.t=3.00, p<0.01t=0.89, p=0.38ConclusionsResearch shows that students of different ability learn differently from visualizations. ChanLin (2001) foundthat novice students with low prior knowledge learn better with static graphics, while experienced students withhigh prior knowledge learn equally well with dynamic visualization or static graphics. In contrast, Hays (1996)reports that middle school students with limited skill in visual processing had stronger learning gains fromcomputer animations than from static pictures, through the use of guided explorations. Our preliminary resultsindicate that sequencing of virtual+physical models may need to be optimized based on student priorknowledge. Further work could illuminate how students of differing ability interact with visualizations.ReferencesCarmichael, A., Chini, J.J., Gire, E., Rebello, N.S., Puntambekar, S. (2010). Comparing the Effects of Physicaland Virtual Experimentation Sequence on Students’ Understanding of Mechanics. Paper at the AnnualMeeting of the American Educational Research Association. Denver, April 30–May 4, 2010.ChanLin, L. (2001). Formats and prior knowledge on learning in a computer‐based lesson. Journal of ComputerAssisted Learning 17, 409–419.Hays, T.A. (1996). Spatial Abilities and the Effects of Computer Animation on Short-Term and Long-TermComprehension. Journal of Educational Computing Research 14, 139–155.Linn, M.C. (2000). Designing the Knowledge Integration Environment. International Journal of ScienceEducation 22, 781–796.Linn, M.C., Eylon, B.S. (2011). Science Learning and Instruction: Taking Advantage of Technology to PromoteKnowledge Integration. Routledge, Taylor & Francis Group, New York, NY.Liu, X. (2006). Effects of combined hands-on laboratory and computer modeling on student learning of gaslaws: A quasi-experimental study. Journal of Science Education and Technology, vol. 15, pp. 89-100.Sadler, P., Coyle, H., Miller, J.L., Cook-Smith, N., Dussault, M., Gould, R.R. (2009). The astronomy and spacescience concept inventory: Development and validation of assessment instruments aligned with the K–12 National Science Standards. Astronomy Education Review 8, 010111.ICLS 2014 Proceedings1512© ISLS