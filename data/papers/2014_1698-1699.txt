Writing Competitive Proposals for Programs in NSF’sDivision of Research on Learning inFormal and Informal SettingsEllen McCallie, Chris Hoadley, Michael Ford, National Science Foundation, USAemccalli@nsf.gov, choadley@nsf.gov, miford@nsf.govAbstract: The National Science Foundation supports innovative research, development, andevaluation of learning and teaching across STEM settings. This workshop focuses onunderstanding the priorities of DRL’s programs and provides guidance in writing competitive,high quality proposals. The workshop is structured to include opportunities for collaborativework, discussion, and questions. The content of the workshop includes: 1) STEM educationalresearch in DRL; 2) priorities and changes in DRL’s major programs, 3) NSF’s proposalreview process; and (4) characteristics of competitive and poorly-rated proposals. Both noviceand experienced researchers are encouraged join in the discussions and to bring proposalconcepts for discussion.Theoretical FrameworkThe primary goal of the workshop is to examine the proposal-writing process and NSF’s review criteria forresearchers interested in submitting proposals to DRL. While the basic structure of NSF and DRL is unchangedfrom the previous review cycle, most DRL programs and solicitations for proposals have been revised, as are thepriorities and emphases of Division administrators. The revisions reflect the changing priorities and the evolvingnature of foundational knowledge and practices in STEM education across settings and age groups. Along withnew approaches to K-12 science education (NRC, 2012) and undergraduate biology education (AAAS, 2011),there are new standards for what students should know and be able to do (NGSS, 2013). The desired changes instudent learning outcomes, instructional practices, and approaches to evaluating progress will require both largescale studies of educational practices and smaller exploratory studies of new innovations that may have thepotential to transform current practices. For long-term success, these efforts must be solidly grounded in soundtheoretical frameworks and based on strong evidence of effectiveness.The National Science Foundation wants to identify and support researchers who will take up these newchallenges. In the broader context of Federal support for education research and evaluation, DRL’s challenge isto be a catalyst for change in advancing theories, methods, measurements, resource development, andapplications in STEM education. The Division seeks to meet this challenge by supporting both early, promisinginnovations and larger-scale adaptations of educational innovations shown to be effective.NSF is the premier Federal agency supporting research and development at the frontiers of discovery inthe STEM fields, so DRL takes as a central principle that new and emerging areas of STEM must figureprominently in efforts to improve STEM education at all levels and in all settings.RationaleThe primary rationale is to increase capacity among the communities of STEM education researchers to writecompetitive and high quality proposals. In this regard, it is important to understand the larger context of NSFgoals for scientific research. The NSF context includes: emphasis on potentially transformative research; NSFculture of evolving programs to meet dynamic opportunities; evaluation and accountability expectations;research and development with respect to the Common Guidelines; and knowledge and evidence base forchange.GoalsWorkshop participants will better understand: DRL’s major research programs and priorities; the NSF reviewprocess; essential elements of strong proposals; common weaknesses in proposals; and the mechanics ofproposal preparation. Presentations will set the context for the priorities of NSF, EHR, and DRL. There will be abrief discussion of NSF’s current structure and organization and funding levels. The bulk of the time will bespent on the NSF proposal review process, what makes a proposal competitive, and how DRL thinks about“rigor” in education research. Participants will have multiple opportunities for interaction. This will beaccomplished two ways: First, participants will critique and discuss prearranged scenarios that demonstrateproposal strengths or weaknesses highlighted in the presentation, and second, participants will haveopportunities to describe and get feedback on their own research ideas.ICLS 2014 Proceedings1698© ISLSStructureThe workshop is comprised of multiple segments to vary the format and provide opportunities for interaction.Part 1 (45 min) begins with an introduction to DRL’s funding programs: Education Core Research (ECR);Advancing Informal Science Learning (AISL; formerly ISE); Discovery Research K-12 (DRK-12), PromotingResearch and Innovation in Methodologies for Evaluation or PRIME, Innovative Technology Experiences forStudents and Teachers (ITEST), and Faculty Early Career Development (CAREER).Facilitators will describe the programs’ objectives, topical strands, types of awards, and provideexamples of projects supported by each program. The session will then continue with an overview of the NSFreview timeline and merit criteria – intellectual merit and broader impact – and DRL-specific expectations andprocedures. A brief overview of related programs within the Education and Human Resources Directorate andacross the NSF directorates will also be provided. The purpose of this session is for participants to understandthe programs’ foci and the review process.In Part 2 (90 min), participants will split into smaller groups. During this time, the participants will firstread a scenario – a short passage designed to stimulate discussion about strengths and weaknesses of proposals.The scenarios are likely to include: 1) brief passages that address important proposal elements such as nationalsignificance, role of STEM content, connections to theory-building or testing, and rigor and evidence in studydesign; and 2) brief summaries of potential research projects or study ideas, which Program Directorsoccasionally receive from potential applicants.The scenarios will be prepared by Program Directors as exemplars. Passages from real proposals areused, and have been approved through the NSF’s Office of the General Counsel's process. This is also anopportunity for participants to discuss their own questions in a smaller and more congenial environment.Part 3 (45 min) will explore the qualities of successful (and unsuccessful) proposals. This presentationwill include discussion of common strengths of highly-rated proposals and typical weaknesses of poorly-ratedproposals. It will also include clear examples that will relate directly to the two NSF merit review criteria and tothe DRL programs. Practical guidelines for presenting a compelling case for a proposed project will bepresented during this portion of the workshop, with suggestions about how to convince reviewers that a proposalis worthy of support. Useful NSF resources, such as the Grant Proposal Guide (NSF, 2013) and relatedguidelines will be described. Participants’ questions are encouraged.The small groups will rejoin for Part 4 (45 minutes). Participants will shift from discussion of prearranged scenarios to discussion of their own questions or individual proposal ideas. This format allowsparticipants to bring up questions or points of discussion about the programs or about the review process in asmaller and more congenial environment. To support open dialogue, participants are invited to share a briefsummary of a potential research topic or study. As mentioned above, Program Directors commonly receive briefsummaries of this type from researchers and are asked to provide feedback on both the selection of theappropriate program and on the potential strengths and weaknesses of the idea. After having read and discussedthe scenarios, participants may be more comfortable with their small group to mention their research ideas.ICLS 2014 Proceedings1699© ISLS