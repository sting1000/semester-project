Using Models for Reasoning and Content Learning: Patterns ofBootstrapping Towards Earth Science UnderstandingsAnn E. Rivet, Cheryl A. Lyons, Alison R. MillerTeachers College Columbia University, 525 W. 120th Street, New York, NY 10027rivet@tc.columbia.edu, cal2154@tc.columbia.edu, mar2218@tc.columbia.eduAbstract: A key aspect of using scientific models and other representations as cognitivelearning tools is the reciprocal relationship between understanding the nature of models asrepresentations, and understanding the specific concepts and phenomena that the model isintended to represent. However, challenges exist regarding how to describe and measureindicators of this reciprocity. We explored the ways in which 8th and 9th grade students utilizedphysical dynamic tabletop models towards developing sophisticated understandings of fullscale Earth System processes. This approach allowed us to identify and describe evidence ofthe “bootstrapping” that occurs between understanding the model as a scientificrepresentation, and understanding the science concepts of the represented entities,configurations, motions, and emergent phenomena in the real Earth System. We argue thatthis notion of bootstrapping is a productive means to conceptualize and support thedevelopment of students’ epistemological understandings of both scientific models and therepresented science concepts.IntroductionOne of the challenges with the current discourse in science education around scientific practices, and modelingpractice in particular, is how the development of these practices interplays with the development ofsophisticated target content understandings. A key aspect of using scientific models and other representations ascognitive learning tools is the reciprocal relationship between understanding the nature of models asrepresentations, and understanding the specific concepts and phenomena that the model is intended to represent(Schwarz et al., 2009). Although the literature fully acknowledges the intertwined relationship between the two,specific attempts to conceptualize, describe, and measure how these different but related constructs evolveacross students’ learning continuum are still in their infancy. In particular, challenges exist regarding both howto describe and measure indicators of this reciprocity, and the conditions under which the interplay betweenstudents’ understanding the nature of models as representations (a key aspect of modeling practice) and robustconceptual understanding developed through working with such models is most productive for learning.Our work attempts to frame this important intersection of practice and conceptual learning.Specifically, we sought to address the following question: what is the nature of the relationship betweenstudents’ demonstrated content understandings and the sophistication of their analogical reasoning aroundrepresentative models? We articulated a progressive analogical reasoning construct to describe the ways inwhich students develop in their ability to conceptualize more abstract and generalized understandings of bothmodels as representations, as well as concepts and phenomena that are represented in specific models. Throughin-depth interviews and written assessments, we explored the ways in which 8th and 9th grade students utilizedphysical dynamic tabletop models towards developing sophisticated understandings of full scale Earth Systemprocesses. This approach allowed us to identify and describe evidence of the “bootstrapping” that occursbetween understanding the model as a scientific representation, and understanding the science concepts of therepresented entities, configurations, motions, and emergent phenomena in the real Earth System (Carey, 2004;Kurtz, Mao & Gentner, 2001). We argue that this notion of bootstrapping is a productive means toconceptualize the development of students’ epistemological understandings of both scientific models and therepresented science concepts, and should be further explored and supported through instructional approachesand other cognitive tools embedded in science learning experiences across the K-12 continuum.Conceptual FrameworkChallenges Particular to Earth Science LearningScience is about developing understandings and explanations of phenomena of the natural world. To thegreatest extent possible, much of science education involves giving students direct experiences with suchphenomena. Yet it is not possible to bring many of the important phenomena of Earth Science into theclassroom setting for students to explore. Key Earth system processes, such as eclipses, ocean currents, anddifferential heating of the atmosphere, are beyond a students’ tangible grasp. The most common way to addressthis challenge is to make extensive use of a wide array of representation types across the Earth Sciencecurriculum (Kastens & Rivet, 2010), including conceptual models. Conceptual models are defined by theICLS 2014 Proceedings354© ISLSNational Research Council (NRC, 2012) as diagrams, physical replicas, mathematical representations, analogiesand computer simulations that are simplified structural, functional, or behavioral analogs for the phenomenabeing represented, and can be used to generate explanations and predictions. Specifically, we focus our researchon dynamic tabletop models that change or move. Research has found that such models are engaging forstudents, and have the ability to mirror the use of models in authentic science practice to both represent anddevelop new understandings (Neressian et al., 2003). However, there are known challenges with using suchmodels in classrooms, including documented cognitive leaps of scale and rate, and instructional approaches thatare often focused on the details of the model rather than on students’ use of the model to develop understandingsof the represented Earth System. To address these challenges in support of Earth Science learning, there is aneed for greater understanding of how exactly students interpret and reason with physical models, and whatkinds of supports (from the teacher, instructional materials, and the model itself) are most effective in guidingstudents’ use of such models towards deep understandings of the Earth.Modeling PracticeThere is a distinction made in the literature between models (particularly conceptual models) and modelingpractice. The practice of modeling, as described by Schwarz et al. (2009), is a weaving together of both theactive engagement with the elements of modeling, and the understanding of the rationale and norms that guidethe practice, referred to as meta-modeling knowledge (Schwarz & White, 2005). Meta-modeling knowledgeincludes understandings of how models are used, why they are used, and what their strengths and limitationsare. Thus simply working with physical representations is claimed to be insufficient for students to develop anunderstanding and appreciation of modeling practice. Rather, it is through this combination of engagement withand knowledge of modeling, that students develop a more robust sense of how science works and the nature ofthe knowledge that science produces (Schwarz et al., 2009).One of the persistent questions around the conceptualization of students’ development of sciencepractices in general, including modeling practice, is the nature of the reciprocal relationship between developingunderstandings of the practice itself and understandings of the specific scientific concepts engaged through thepractices. Researchers have argued that models and the real world phenomena that they represent exist as adialogic: it is through analyzing phenomena one can glean insights into the potential elements, relations,operations, and rules that govern and constrain the model; while concurrently, the model allows for thegeneration of new explanations and predictions regarding the targeted phenomena (Schwartz et al., 2009). TheNational Research Council (2012) goes further to state that developing an understanding of models and theirrole in science can help learners construct and revise their own mental models of phenomena, which in turnresults in more robust reasoning and a deeper understanding of science concepts. However, as strong as thisclaim is in theory, there is scant evidence to illustrate such reciprocity in actual student learning. Due in part tomeasurement challenges, science practices such as modeling are often examined and evaluated in the abstract,apart from the disciplinary content focus in which the modeling practice is embedded. Therefore the questionstill remains regarding the nature of the conceptual and epistemic science learning and meaning making that isgained through engagement with modeling practices around targeted concepts and phenomena under study.Learning from Models: Analogical ReasoningIn light of these challenges we were interested in exploring further the nature of how students come tounderstand the ‘representation-ness’ of models, and how the models are understood to serve as analogies forphenomena that are too big, too slow, or too intangible to be observed directly. To shape our thinking, we drewheavily from the literature on analogical reasoning, and in particular the work of Dedre Gentner. Gentner’sstructure mapping framework for analogy (e.g., Gentner, 1983) focuses the process of establishing a structuralalignment between a familiar source (in this case, a physical model in front of students) and an unfamiliar target(such as a large-scale Earth process like atmospheric circulation or subduction at plate boundaries). Gentner’sframework distinguishes among different forms of similarity that may exist between the source and the target,and articulates a set of implicit rules for mapping knowledge about the source onto the target. This and othereducational research demonstrates how the power of analogy comes from the relationships between objectsrather than from the attributes of objects themselves, and that the most powerful analogy-derived insights comefrom the existence of higher-order relations such as causality that correspond between the source and the target.Building from Wilson’s (2005) approach to construct modeling, in our work we identified three keylevels of analogical reasoning regarding the correspondences and non-correspondences between models and theEarth System that frame an increasingly sophisticated way that students may come to use models to developrobust understandings of Earth Science concepts and phenomena (see Figure 1). To illustrate these three levels,we describe the reasoning that students may engage in around an exemplar model of the phases of the moon(Figure 2). In this model, a basketball is placed on a stand in the front of the room, with a small plastic dolltaped to a point about half-way between the top and the mid-line, oriented so it is facing the classroom. A brightlight is placed to the side of the basketball. The instructor then moves a smaller yellow lacrosse ball around theICLS 2014 Proceedings355© ISLSbasketball, at a sufficient angle so that the light from the lamp continually illuminates one side of the yellow ballas it moves around the basketball. Using this model, we describe the three levels of reasoning aboutcorrespondences and non-correspondences shown in Figure 1 that we believe users of this model would engagein while coming to better understand the target phenomena, that of the observed phases of the Moon from Earth.Figure 1: Levels of students’ analogical reasoningbetween a physical model and the Earth SystemFigure 2: Model of the phases of the MoonThe first, and most basic, level of analogic mapping has to do with identifying and understanding thecorrespondences and non-correspondences between entities in the model and entities in the Earth System. By‘entities’ we are referring to both specific object mapping and mapping of the characteristics of those objects. Inthe example, reasoning about correspondences and non-correspondences at the entity level would includeidentifying and naming the basketball as representing the Earth, the yellow lacrosse ball as representing theMoon, the bright lamp as representing the Sun, and the doll as representing an observer on Earth. Likewise,non-correspondences at the entity level would include noting that the Earth is not actually orange like thebasketball, that the lamp is much smaller than the real Sun, and that the stand holding the basketball has nocorrespondence to any entity in the real Earth System.The second level of reasoning that users of this model would engage in involves considering either theconfiguration or arrangement of entities with respect to each other in the model as corresponding to similarconfigurations of entities in the Earth System, or the motion of entities with respect to other objects in the modelas corresponding to similar motions of objects in the Earth System. For example, students may begin to reasonthat the motion of the yellow lacrosse ball around the basketball may correspond to the motion of the moonaround the Earth. Non-correspondences of configuration or motion would also be recognized, including the factthat the motion of the moon in orbit around the Earth is considerably slower than the motion of the yellow ballin the model. Similarly, the basketball is not rotating in the model, whereas in the Earth System the Earth wouldbe rotating concurrently to the moon orbiting around the planet.The third and most sophisticated level of reasoning involved recognizing the phenomena as it emergesor develops in the model and identifying the cause or mechanism which drives that phenomena, and mappingthat mechanism or cause such that it corresponds to the same mechanism or cause in the real Earth System. Inthe example, students would recognize that the doll on the basketball was observing the illumination of theyellow ball change as it orbited the basketball, resulting in ‘phases’ of the yellow ball at different times. Thisemergent phenomena of ‘phases’ corresponds to the phases of the moon that we observe on Earth, and themechanism causing those phases in the model corresponds to the similar mechanism in the Earth System relatedto the orbit of the moon around the Earth with respect to the position of the Sun.The dimensions of the construct include not only the vertical additive levels of mapping withincreasing sophistication, but also the additional dimension of mapping both correspondences and noncorrespondences at each level. As every representation is by definition some form of simplification orabstraction of actual real world phenomena, we believe fluency in reasoning around models includes both aconceptualization of a model’s similarities and differences to the phenomena being represented. It is importantfor students to recognize not only the affordances but also the limitations of models, as the nature of the inherentapproximations and assumptions of each model limits its range of validity and precision of predictive power(NRC, 2012). Thus in our construct, as well as throughout our assessments of students’ reasoning, analogicalmapping of both correspondences and non-correspondences played a prominent role.Bootstrapping Between Modeling Practices and Analogical ReasoningGiven the conceptualized reciprocity between modeling practice and analogical reasoning around models, itthen becomes important to consider the implications of this claim for describing and identifying observablecharacteristics of this relationship in students’ science learning. We take up the notion of “bootstrapping” as aproductive lens to consider the nature of this relationship. Bootstrapping is a frequent metaphor used in theliterature to refer to the process of “using theory to constrain data and using data in turn to constrain, refine, andICLS 2014 Proceedings356© ISLSelaborate theory” (Koslowski, 1996, p.281). It builds from the uniquely human capacity for learning and usingrepresentative symbols and relations between them, and the ability to integrate across distinctly differentrepresentational systems (Carey, 2004). The metaphor is thus a way to help explain how a learner is able toachieve conceptual endpoints that far transcend where she is starting from, particularly through the creation ofsuccessively new and more powerful mental representations. This process of conceptual bootstrapping is notadditive, in the sense that the development along any single dimension or representational system does notlogically follow a successively cumulative linear fashion. Rather, progress within such a reciprocal relationshipis marked by co-concurrent development across two or more systems, with the sophistication of intermediatesteps in each progression exceeding what would be anticipated if addressed in isolation.Bootstrapping in our case refers to the ways in which students recognize and make meaning ofsimilarities and differences between the physical model as a representation and their understanding of the fullscale Earth System, in order to generalize and abstract to broader science principles. This perspective alsopromotes the perspective of conceptual models as cognitive tools (Brown, Collins & Duguid, 1989). Forexample, the more a learner are able to recognize and use the “tool” (conceptual model) of convection to explainboth real world phenomena and tangible representations, the better she is able to understand both what theconcept of convection stands for in the abstract, as well as the nature of an increasing array of instances andphenomena where the concept of convection is an appropriate explanation. The iterative movement betweenpartial insights gleaned through the consideration of the “representation-ness” of physical models and theparticular analogical similarities and differences between models and real Earth phenomena results in thedevelopment of more sophisticated models that account for previously unrepresented structures or behaviors,and thus enhanced conceptual understanding (Nersessian & Chandrasekharan, 2009).However, evidence of this bootstrapping between models and conceptual scientific understanding isstill minimally described in the literature. Missing are robust accounts of what students look like as they areproductively (and not so productively) engaged in this process of learning. Such characterizations are needed inorder to inform instructional strategies aimed to support students’ effective engagement with and use of modelsacross phenomena, as well as the nature of assessment tasks to evaluate and inform modeling practice androbust conceptual understandings. Our work aims to address this need by exploring the following researchquestion: What is the nature of the relationship between students’ demonstrated conceptual understanding andthe sophistication of their analogical reasoning around physical models of full-scale Earth System phenomena?MethodsSetting and data sourcesThe two-year study examining the nature of students’ analogical reasoning around Earth System models wasconducted in partnership with three 8th and three 9th grade Earth Science teachers in schools outside of a largecity in the Northeastern US, which reflected a range of demographics and achievement levels. In Year 1 of thestudy, teacher used models as part of their typical Earth Science instruction. In Year 2, they incorporatedspecific instructional strategies to support students’ reasoning around models (see Rivet, et al. 2013).We developed parallel assessment activities around three Earth Science topics: phases of the moon, thecause of the seasons, and differential sorting in depositional environments. Teachers addressed each of thesetopics at various times across the year in lessons spanning 1-4 class periods, utilizing their own selected array ofmodels and other representations in each lesson. For our assessment activities, we featured a researcher-run 3Ddynamic model of the Earth System process that we developed, set up in the front of the room for students toobserve (e.g., see Figure 2). A pre/post written assessment consisting of 20-22 short answer and multiple-choiceitems was developed for each topic. Items were crafted to elicit students’ understanding of either acorrespondence or non-correspondence between the assessment activity model and the targeted aspect of theEarth System, at one or more levels of the analogical reasoning construct. Additionally, individual videotapedinterviews with selected target students from each teacher were conducted after each posttest administration tofurther elicit more detailed explications of their reasoning and content understanding. These interviewsinvolved asking students to elaborate on their understanding and reasoning around a selected group of 6-8posttest items for each topic. During these interviews, students were provided with a miniature version of themodel used for the written assessments and told that they could use the model at any time to help them explainor figure out an answer. Further information about the assessment instrument design, including samplequestions, is described in detail in Rivet & Kastens (2012).Data collection and analysisThe assessments activities were administered in a pre/post format to all of the sections of each of our partnerteachers in both Year 1 and Year 2 of the study, for a total of 357 consenting participants. As we were interestedin understanding the relationship of assessment items as reflecting the proposed construct rather than studentgain, we examined both the pretest and posttest together in the same data set. Therefore, the total number ofICLS 2014 Proceedings357© ISLScases considered was 707, with 323 cases from year 1 and 384 cases from year 2. An expanded outcome spacewas used to map each item response made by the student to a particular level of the construct. A kappacalculation of .84 for moon, .86 for seasons, and .90 for deposition provided a strong sense of inter-raterreliability. Prior analysis (Rivet, et al., 2013) demonstrated that the three assessments were generallycomparable at measuring student reasoning around the levels of the construct, providing validity for claimsdrawn by looking across assessments in the three different topic areas.With parameters estimated using R software, the assessment data was analyzed using a Rasch modelingapproach for polytomous data. This approach provides an estimate of student ability and test item difficulty,both of which can be approximated based on the overall performance of a given sample of students on aninstrument (Wilson, 2005). A Cronbach’s alpha of .81 was established for the multidimensional analysis acrossthe three topics, and the expected a posteriori (EAP) was 0.84 for moon assessment items, 0.82 for seasons, and0.80 for deposition. Ability estimates were calculated for each student on every test they completed to determinetheir proficiency score in relation to the difficulty of the items. The average ability estimate for moon posttestswas 0.51, or about a level 2 non-correspondence, 0.25 for seasons (level 2 correspondence), and -0.35 fordeposition (level 2 correspondence). For each posttest, the students’ ability estimate was utilized to assign alevel of analogical reasoning based on our construct. Levels were determined by taking the average abilityestimate score from the two adjacent levels, which produced a threshold score. For example, the threshold scorewas calculated by averaging the mean score of level 1 correspondence (1c) and mean score of level 1 noncorrespondence (1n) within a topic. This average score established the cut-off point for a student to receiveeither a level 1 correspondence or level 1 non-correspondence score.Of the 357 students included in the above analyses, 29 were identified as target students for furtherexamination. These target students had completed all six tests (except for one group of six students from year 1that did not receive a seasons pretest) and had participated in at least two interviews from the three topics. Thestudents’ demographics are outlined in Table 1. In examining the ability estimates of the target students’posttests in comparison to the overall data set, these students appear to be representative of the larger studentpopulation included in this study.Table 1: Target student demographics.Target Student Demographics (n total = 29 students, n year1 = 16 students, n year2 = 13 students)SchoolMS1 = 11MS2 = 8MS3 = 2HS1 = 8TeacherT1 = 8T2 = 8T3 = 5T4 = 3T5 = 2T6 = 3LevelLower = 1General = 20Advanced = 8GenderFemale = 11Male = 18The target student interviews were transcribed and analyzed along several dimensions, including therobustness of their articulated conceptual understanding of the causal mechanism driving each of the modeledEarth phenomena (moon phases, seasons, and deposition). Student responses in each interview were rated on ascale from weak to excellent. Weak understanding included descriptions of relative motions or configurationsof entities in the Earth System, but no connections to causes or mechanisms of the emergent phenomena. Agood understanding was rated when there was a single cause or preliminary mechanism given, whereas anexcellent understanding indicated the influence of multiple coordinated factors on the resulting phenomena. Thespecific criteria for each level were tailored to the particular content focus of the interview. Each target studentreceived a single rating score for each topic based on their responses across questions in the interview. We thencompared target students’ content scores from the interviews with their posttest analogical reasoning levelascertained from the written assessment for each topic. These ratings were categorized to identify clusters ofstudents that shared similar profiles of content understanding and analogical mapping across content areas.FindingsOverall, there were a few observed trends across the target student group focused on in this analysis. First,based on the analogical mapping proficiency scores calculated by the assessments, none of these students werefound to reason only at the lowest measureable level, that of only being able to map correspondences betweenthe model and the Earth System at Level 1: Entities and Attributes. Everyone in this group was also able to atminimum reason around both correspondences and non-correspondences at this level for every topic. The Moonassessment demonstrated the greatest range of proficiencies along the construct, with four studentsdemonstrating proficiency at only Level 1 correspondences and non-correspondences, and eleven studentsdemonstrating proficiency at mapping non-correspondences at Level 3: Causation and Mechanism, the mostsophisticated reasoning measured on the written assessment. The other two assessments, focused on seasonsand deposition, were more challenging for students. None of the students in this group were found toICLS 2014 Proceedings358© ISLSconsistently demonstrate proficiency at Level 3 for either of these two topics. That is not to say that they did notoccasionally respond accurately to assessment items targeted to these levels. Rather, with respect to the wholestudent population who completed these assessments, the target students were not the most proficient atsophisticated Level 3 mapping in the seasons and deposition assessment activities.We identified four clusters, or profiles, of the relationship between the sophistication of students’analogical reasoning around science models and their content understanding as articulated during the interviews.Each of these profiles is described in detail below.Profile 1: “Level 1” Mapping with Weak ContentThe first pattern that emerged were a relatively small group of target students (3 of the 29, or 10%) whoseaverage proficiency rating on each of the three assessments indicated overall ability to articulatecorrespondences and non-correspondences only at the “Level 1: entity and attribute” stage of the construct map.These students also demonstrated limited understanding of the science concepts under study consistently acrossthe interviews. The combination of relatively weak content understandings and limited proficiency atidentifying and articulating the relationship between the model and the Earth System phenomena is to beexpected as students are just beginning to develop fluency with both the science concepts and modeling practice.We would consider such students to be near the beginning of a progression that describes this kind of learning.What is also of note in these groups of students is the consistency of their typical responses across topics, bothin terms of mapping between the model and the Earth System and the sophistication of their descriptions of thescience phenomena itself. Unlike other profiles identified, described in more detail below, students’performance in both the three posttest assessment tasks and the two or three interviews they participated in wasconsistently near the lower end of both the content and the analogical mapping scale.One student who fit this profile, Stephanie, demonstrated proficiency at mapping between the modeland real Earth System only at a Level 1 during the written assessment, and no higher than a Level 2 during theinterview. For example, during the Moon Phase interview she said that the model was like the phases of themoon because “as the moon revolves around, it should show the changes.” Epistemologically, such commentsreflected a common perception amongst students in this profile that the model “shows” the science concept thatit is intended to represent, without indicating clearly what that science concept was or how the modelrepresented that idea. Stephanie did not make any statements to suggest why we see phases beyond explainingthat it relates to the revolution of the moon around earth. She showed similar limitations for the topic ofseasons. Her poor content knowledge and limited mapping ability did not deter Stephanie from using thephysical model to communicate, as she was observed using the physical model to illustrate both accurate andinaccurate conceptions about the entities in the real Earth System and the relative motions of these entities.Profile 2: Medium Proficiency for Content Understanding and Analogical MappingA second profile that emerged from the target student analysis was that almost a quarter of these students, 24%,were generally in the middle in terms of both sophistication of mapping the correspondences and noncorrespondences between the model and the real Earth System, and the robustness of their contentunderstanding. This pattern also reflects the ability level achieved by the majority of students in the largerstudy. As students are moving through the Earth Science curriculum in middle and high school, there isevidence that they have a better understanding of both the ways that scientific models represent, and can be usedto understand, specific Earth Systems phenomena than they did in the lower grades. Specifically, they generallycharacterize the phenomena under study in terms of spatial relationships between entities, and are able toaccurately identify and describe Level 2: Configuration and Motion correspondences between the model and thephenomena. However, these students still struggle with characterizing the non-correspondences of motion orconfiguration in the model, and are limited in their explanations of the mechanism behind emergent phenomenaacross topics. We consider this an appropriate “stepping stone” understanding (Wiser, Smith & Doubler, 2012)as students develop increased fluency with both modeling and Earth System understandings.One student who fit this profile, Robert, demonstrated consistent Level 2 mapping and good, but notexcellent content knowledge. During the seasons interview, Robert attributed the changing seasons to the tilt ofthe Earth’s axis in different positions in its revolution around the sun, but did not explain more sophisticatedaspects such as the effect that the changing angle of light has on the amount of solar energy received at a pointon Earth. Robert was able to explain his mapping between the real Earth’s revolution and tilt and that of themodel, but illustrated tilt inconsistently using the physical model. During the deposition interview, Robertexplained how the attributes of sediment might influence settling rates but conflated density and size. Robertnever used the physical model for deposition, in contrast to the seasons model which he used frequently.Profile 3: Robust Content and Mapping FluencyA rather surprising result of our analysis was the finding that over 40% of the target students (12 of the 29interviewed) demonstrated robust content understanding of the science concepts across the three topics, andICLS 2014 Proceedings359© ISLSrelatively high sophistication in terms of their ability to map correspondences between the model and the realEarth System in the assessment activities. As described earlier, the assessments for the seasons and depositiontopics were limited in the extent to which evidence of Level 3: Causation and Mechanism correspondences, andparticularly non-correspondences, was measured. There was also observed a relative range of both mappingproficiency and robustness of content explanations in this group. However, when looking across the three topicson their posttest and post-instruction interview responses, it was evident that a majority of our target studentswere able to demonstrate both modeling and conceptual understanding with an appropriately expected level ofsophistication given the population.One student, Emily, demonstrated both strong knowledge of each topic and a strong ability to explainhow the model illustrated the real system at various levels. Emily did not use the physical model providedduring the interviews frequently; however, she did use it to communicate sophisticated ideas and demonstrateLevel 3 mapping.Profile 4: Consistency of Analogical Mapping Ability with Variable ContentUnderstanding Across TopicsSeven students in our target group (24%) did not fit into any of the three prior categories. Four of these students(14% of the total group) demonstrated an interesting pattern in that the sophistication of their analogic mappingbetween the model and the Earth System demonstrated through the written assessment was consistent acrosstopics, yet during the interview they displayed vastly different levels of conceptual understandings of thescience phenomena under study. Three of these students were proficient at the Level 2 mapping, howeverdemonstrated excellent understanding of either moon or seasons phenomena but poor understanding ofdeposition. One of these students showed a similar trend in terms of content, but mapped at the lowest levelacross the written assessments.One student, Sarah, demonstrated poor mapping consistently despite variations in the robustness of hercontent knowledge across the topics. Sarah demonstrated Level 1 mapping along with poor knowledge ofdeposition. For Moon Phases, Sarah was able to explain verbally, and with the aid of a physical model, what thecauses are for the phases of the moon. However, she was not able to map between the model and real Earth formore specific questions relating to particular configurations of the model and how these mapped to real phases.For questions such as these, Sarah struggled to explain her reasoning.Outlier ExamplesThe three students who did not fit into any of the above categories showed unique patterns of mapping andcontent understanding across the three topics. One student consistently mapped at the mid to upper range ofability levels for a Level 2, but demonstrated poor content understanding across the board. A second studentdemonstrated consistently excellent conceptual understanding across topics, but performed at the lowest level ofanalogical mapping consistently across the assessments. The third student in the group showed a pair-wisetrend: excellent content understanding of moon and high sophistication of mapping; a level 2 mapping ability onseasons (no interview); and a lower conceptual understanding of deposition with proficiency of analogicalmapping on this assessment at a Level 1. To our surprise, this was the only student out of the 29 target studentsinterviewed who showed this trend.One example of a student in this group is Michael, who showed difficulty applying the knowledge hehad of the causes of the seasons to a model, both on the written assessment and during the interview. Thisstudent never used the provided physical model of seasons during his explanations, and when describing howthe model was like the seasons, he gave a response that was only at a Level 2, stating “the earth goes around thesun and it is rotating [like] the ball orbiting around the [basketball], the seasons change in different areas.”However, throughout the interview Michael showed that he understood more sophisticated aspects of the causesof the seasons including the influence of the tilt of Earth on the angle of sunlight, which he explained affectedthe amount of sunlight an area received.Discussion: Bootstrapping Towards Conceptual UnderstandingsThe analysis of target student profiles illustrates some significant characteristics that demarcate the evolvingreciprocal relationship between understanding Earth System models as scientific representations, andunderstanding the science concepts of the represented entities, configurations, motions, and emergentphenomena in the real Earth System. First, it is notable that none of the target students included in the analysiswere capable of mapping at any significant level without robust content understanding as well. Our findingsdemonstrate that it is not the case that analogical mapping is a generalized and transferrable context-independentskill. If it were, it is possible that we would have observed students engaged in sophisticated analogicalreasoning while also demonstrating weak conceptual understanding. Rather, our data support the claim thatanalogical reasoning only exists in the context of the phenomena and concepts that are being reasoned about.This indicates that the power of bootstrapping between representations and phenomena to develop robustICLS 2014 Proceedings360© ISLSconceptual understandings must begin with at least some limited understanding of the phenomena under study toinitiate the bootstrapping process.A second important trend observed in this analysis is that the sophistication of analogical mappingaround models and the robustness of students’ conceptual understanding co-vary across the profiles. Overall 22of the 29 target students (over 75%) were consistent in terms of falling into either a “low mapping/low content”,“medium/medium”, or “high/high” profile. This finding in particular supports the claim that increasedsophistication in modeling practice and increased sophistication of conceptual scientific understanding doindeed co-vary, and exist together in a reciprocal developmental relationship. This lends support to the power ofconsidering bootstrapping as a productive mechanism to describe the relationship between developing modelingand conceptual understandings.This research points to both specific recommendations for instruction and curriculum design, and areasin need of further research. By recognizing the nature of the reciprocal relationship between contentunderstanding and modeling practice, this work encourages curriculum and instruction to avoid teaching scienceconcepts and modeling practices as separate knowledge domains. Additionally, the profiles themselvesilluminate the nature of both students’ engagement and use of models and the sophistication of their conceptualreasoning at each of these levels. Such information can be used by teachers to help assess and support studentlearning within and across content areas. Next steps in this work include further analysis of science classroomenvironments engaged with robust model use, with the aim of understanding the various ways that instructioncan influence the relationship between students’ modeling practices and concurrent development of sciencecontent understanding.ReferencesBrown, J. S., Collins, A., & Duguid, P. (1989). Situated cognition and the culture of learning. Educationalresearcher, 18(1), 32-42.Carey, S. (2004). Bootstrapping and the origin of concepts. Daedalus, Winter, 59–68.Gentner, D. (1983). Structure-Mapping: A theoretical framework for analogy. Cognitive Science, 7(2), 155-170.Kastens, K., & Rivet, A. (2010). Using analogical mapping to assess the affordances of scale models used inearth and environmental science education. In C. Holscher et al. (Eds.), Spatial Cognition VII, LNAI6222 (pp. 112–124). Berlin: Springer-Verlag.Koslowski, B. (1996). Theory and evidence: The development of scientific reasoning. Cambridge, MA: MITPress.Kurtz, K. J., Miao, C. H., & Gentner, D. (2001). Learning by analogical bootstrapping. The Journal of theLearning Sciences, 10(4), 417-446.National Research Council. (2012). A framework for K-12 science education: Practices, crosscutting concepts,and core ideas. Washington, D.C.: The National Academies Press.Nersessian, N. J., & Chandrasekharan, S. (2009). Hybrid analogies in conceptual innovation in science.Cognitive Systems Research, 10(3), 178-188.Nersessian, N. J., Kurz-Milche, E., Newsletter, W. C., & Davies, J. (2003). Research laboratories as evolvingdistributed cognitive systems. In R. Alterman & D. Kirsh (Eds.), Proceedings of the Twenty-fifthAnnual Conference of the Cognitive Science Society (pp. 857–862). Mahwah, NJ: Lawrence Erlbaum.Rivet, A. E. & Kastens, K. (2012). Developing a construct-based assessment to examine students’ analogicalreasoning around physical models in earth science. Journal of Research in Science Teaching, 49(6),713-743.Rivet, A., Lyons, C., Miller, A., Schmalstig, M. & Kastens, K. (2013). Exploring students’ reasoning aroundmodels in Earth Science. Paper at the annual meeting of the National Association for Research inScience Teaching. Rio Grande, Puerto Rico: April 2013.Schwarz, C., Reiser, B., Davis, B., Kenyon, L., Acher, A., Fortus, D., et al. (2009). Designing a learningprogression for scientific modeling: Making scientific modeling accessible and meaningful forlearners. Journal of Research in Science Teaching, 46(6), 632-368.Schwarz, C. V., & White, B. Y. (2005). Metamodeling knowledge: Developing students' understanding ofscientific modeling. Cognition and Instruction, 23(2), 165-205.Wilson, M. (2005). Constructing measures: An item response modeling approach. Mahwah, NJ: Erlbaum.Wiser, M., Smith, C. L., & Doubler, S. (2012). Learning Progressions as Tools For Curriculum Development.In Learning Progressions in Science (pp. 359-403). SensePublishers.AcknowledgmentsWe would like to thank Kim Kastens and Mariana Schmalstig for their assistance with this research. Theresearch reported here was supported in part by the National Science Foundation # DRL09-09863 and DRL0909982. All opinions expressed are those of the authors and do not necessarily represent either the fundingagency or Teachers College Columbia University.ICLS 2014 Proceedings361© ISLS