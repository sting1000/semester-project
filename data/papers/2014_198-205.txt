How Interpreters Make Use of Technological Supportsin an Interactive Zoo ExhibitBrian Slattery, Leilah Lyons, Priscilla Jimenez Pazmino, Brenda Lopez Silva, Tom MoherUniversity of Illinois at Chicago, 1240 W. Harrison St., Chicago, IL 60607Email: bslatt2@uic.edu, llyons@uic.edu, pjimen5@uic.edu, brendita@uic.edu, moher@uic.eduAbstract: Informal science institutions are depending more and more on dynamic,technology-enabled exhibits. These engaging firsthand experiences often need to becontextualized so that peripheral audiences are able to learn from them. We investigate howinterpreters (a.k.a. docents, explainers) equipped with a tablet support tool (TST) are able tofacilitate learning in a dynamic exhibit with high visitor traffic. This TST focused on rerepresenting user performance in the exhibit, and was designed to help interpreters shapevisitor discourse and inquiry. Four cases are presented to illustrate how interpretersorchestrate their collaborative facilitation when a meditational tool is present, and how theepistemological role of TST shifts. We document interpreters successfully using TSTs tocoordinate shifts in facilitation based on the state of the interactive exhibit, and using live datarepresentations to connect visitors’ personal experiences with exhibit content, demonstratingseveral potential uses of TSTs as mediational tools for dynamic exhibits.Background and IntroductionInformal science learning in institutions such as museums, zoos, and science centers is depending more andmore on interactive technology and dynamic exhibit content, which is a trend that has been noted by theNational Research Council (Bell et al., 2009) as well as the Learning Sciences community (Yoon et al., 2013).But an increased reliance on dynamic, technology-dependent exhibits increases the degree of human-technologyinteraction while often decreasing the degree of human-human interaction, raising the challenge of how tosupport groups of learners at these exhibits without disrupting the beneficial social learning that takes place(Heath, vom Lehn, & Osborne, 2005; Hall & Bannon, 2006; Hornecker & Stifter, 2006).Support for human-human interactions within technology-based exhibits could come from a resourcealready present in informal learning institutions: interpreters (also known as docents, explainers, or facilitators),who are trained to facilitate learning for large, diverse groups of museum visitors through shared meaningmaking around exhibit resources (Tilden & Craig, 1977; Falk & Dierking, 2008; Beck & Cable, 2012).Successful interpreters are expert improvisers: they assess existing visitor interests and knowledge levels, andattempt to build bridges between visitors and the exhibit’s content. This becomes more challenging for dynamicdigital exhibits, where the state of the exhibit can change moment-to-moment. This suggests that there may bevalue in a digital tool that can help interpreters remain apprised of these changes to the exhibit’s state. There issome research on the value of interpreters appropriating technology to facilitate dynamic exhibits (Hsi, 2008),indicating that there is a potential role that interpreters can play in these new kinds of exhibits. Our question ishow to intentionally design technological support tools that can be used by interpreters in their facilitation ofdynamic exhibits, especially for the goal of supporting the learning of a large, diverse visitor base that is oftenperipheral to the central exhibit interactives.The possible utility of designing technology to support facilitators of collaborative learning has beenacknowledged for formal learning environments, especially through the use of mobile tools, which have beendesigned for both teachers and students (Roschelle & Pea, 2002). Interpreters could be considered the “teachers”of informal learning environments, but they face challenges that are not shared by their formal learningcounterparts. Learners in informal spaces vary widely in age and background, so there is no guarantee (or evenclear indication) that they have been exposed to particular representations, or ways of thinking. Also, informalinstitutions are “free-choice” spaces where learners are able to decide what they want to do from moment tomoment, so there is variation in how long visitors will spend in any given interaction with an exhibit orinterpreter. Thus, it is unclear what lessons can be applied from the design of technological supports for formallearning instruction, as these rely on an expectation of instructor autonomy and control that is not possible forinterpreter-facilitated learning. Instead, the design of support technology for interpreters must come from adetailed understanding of its situated use in an informal learning context, as this highlights the consistencies andinconsistencies of practice and enactment that drives the iterative improvement of a design (Bodker, 2009).Designing for Dynamic Exhibit InterpretationA successful tool for interpreters is one that would serve as a mediational means for interpreters’ interactionwith visitors, allowing them to engage in facilitative practices that they would not have normally been able toperform without the tool (Wertsch & Rupert, 1993). In the context of interactive, dynamic exhibits, whereICLS 2014 Proceedings198© ISLSvisitors are generating exhibit content through their own actions, support technology could potentially helpinterpreters to shape the discourse around visitors’ contributions, influencing visitors’ expectations for learningand interaction (Gutierrez, 1994). It would be helpful to provide interpreters with real-time guidance on how toorchestrate learning for groups of peripheral visitors who are not interacting directly with an exhibit, since thecontent they can engage with changes based on the actions of visitors who are participating.Interpreters could also benefit from a support tool that improves their ability to recontextualize exhibitresources for the purpose of improving visitors’ meaning-making (Falk & Dierking, 2008). Interpreters aretrained to draw analogies and make personal connections between themselves, visitors, and the exhibit, which indynamic exhibits involves connecting different modalities of exhibit content (e.g. visitor movements translatedinto real-time graphs of performance data) as well as grappling with variation in the visitor-drivenrepresentations that learners are able to make sense of and reason around. In this difficult meaning-makingcontext, a support tool would be beneficial if it allowed interpreters to position exhibit resourcesepistemologically as accessible sources of inquiry, facilitating visitors’ own sense-making of the exhibit(Bezemer & Kress, 2008; Jaipal, 2010).This work has taken a combined action research and user-centered design approach to exploring how todesign meditational tools for interpretation. From the practice-oriented literature on interpretation we can gleansome lessons for what makes for successful interpretation experiences, but we must acknowledge that as withany meditational tool, the creation of the tool simultaneously disrupts existing practice while making new formsof practice possible. We investigated interpreter practice by working closely with the interpretation staff atBrookfield Zoo in Chicago, IL. We then tested the prototype in situ with actual interpreters, so that we couldobserve how the tool would be appropriated in an actual use context. Observations made during this in situstudy provide the cases that this paper presents.Design of the Exhibit and Support ToolWith this study, we introduced a dynamic, technology-driven exhibit into a zoo environment. This exhibit, AMile in My Paws (Jimenez Pazmino et al., 2013), presented new interpretive challenges to the zoo staff, as itrelied on player-generated content, presented a semi-controversial topic (climate change), and used real-timerepresentations (e.g. player-generated line graphs) that are not commonly used in zoos. In the exhibit, only onevisitor at a time controls a virtual polar bear with “swimming” and “walking” motion controls to traverse anarctic environment in search of food. Paws presents computer generated arctic environments in the past, present,and future, highlighting the reduction in sea ice extent and subsequent increase in polar bears’ caloricexpenditure (it requires more energy to swim rather than walking across ice).Our goal was to gather information about how interpretation looks in this context, for the purpose ofimproving interpreters’ practice through iterative design revisions of Paws and the TST. However, since we arenot interpreters, our understanding of the practice of interpretation needed to come from the community ofinterpreters that we were working with. One way we approached this understanding was through conversationswith Brookfield Zoo’s interactive programs manager, who outlined the interpretive training that takes place atthe zoo, which ultimately derives from the principles proposed by Tilden & Craig (1977). This approachstresses the importance of conversational dialog between interpreters and visitors, with the interpreter focusingon the visitors’ unique interests and background knowledge, the exhibit’s learning goals and expectedtakeaways, and any possible analogies or references that can clarify exhibit content. Additionally, the primarydesigner of the TST took an action research approach (Noffke, 1997) and spent thirty hours “embedded” as aninterpreter, participating in the standard interpretation training given to new hires as well as interpreting atseveral traditional exhibits with visitor inquiry activities. This helped ground the more abstract theoreticalknowledge of interpretive practice with experience enacting these practices, which gave the design team a moresituated understanding of interpreters’ core concerns and goals. This also informed our later analysis as itallowed us to contextualize differences in TST usage in terms of interpreter practices, and balance our researchgoals against the real-world demands of interpretation when designing the initial TST prototype.The prototype TST was made to provide interpreters with resources for contextualizing the Pawsplayer’s actions in terms of data representations relevant to climate change literacy. These include maps of seaice extent over time, and graphs illustrating changing trends (in this case, the virtual polar bear’s caloricexpenditure over time). These would allow interpreters to make connections between exhibit content (both theimmediate events going on in Paws and the foundational climate change content) and visitors’ individualexperiences and understanding, which is a facilitative skill that interpreters normally exercise at static exhibitsand animal viewing areas. The performance graphs were also intended to provide additional information toperipheral visitors about the level of exertion of the Paws player, as relative levels of exertion are typicallydifficult to judge by observation alone (Rejeski, 1981; Jimenez Pazmino et al., 2013).We also included “just-in-time” discussion prompts that would appear on the TST based on the state ofthe player’s progress. The prompts presented questions about polar bears, climate change, and human activitythat had been gleaned from observations in previous Paws pilots and discussions with interpretive staff. TheseICLS 2014 Proceedings199© ISLSwere designed to aid interpreters in identifying upcoming “teachable moments” (Jimenez Pazmino et al., 2013)that might resonate with events occurring onscreen or drive ongoing discussions with visitors. The TSTinterface was designed in Unity and implemented on an iPad for the pilot studies at the zoo (see Figure 1).Study Setting and ProceduresAfter two controlled pilot studies (Jimenez Pazmino et al., 2013), our team organized a two-day installation ofthe Paws exhibit in Brookfield Zoo’s underwater polar bear viewing area. Each day, the exhibit was availablefor roughly one and a half hours. Although exhibits at Brookfield Zoo are typically staffed by two interpretersworking independently, at any given time Paws was being facilitated by a slightly larger team of two to fiveinterpreters due to its novelty. These interpreters were mainly part of the “Roving Naturalist” program atBrookfield Zoo, which is a paid seasonal interpretation program made up of college- and middle-agedinterpreters, and which focuses on both scheduled and spontaneous discussions with visitors. Each day, one ofthe interpreters was also drawn from the “Youth Volunteer Corps,” an unpaid interpretive program for highschool-aged teenagers. All interpreters involved with Paws were already trained in facilitation using artifacts,specimen carts, and other specialty installations, and had been introduced to the idea behind Paws and its mainlearning goals. Only one of the interpreters (“Lorraine”) had prior experience facilitating Paws, as part of apreplanned talk with a youth summer camp group.Figure 1: On the left, the main view of the prototype TST, showing progress map, calorie graph, and just-intime question prompt. On the right, an overview of the elements that make up the Paws exhibit.Interactions between visitors and interpreters were captured through a combination of video and audiorecordings. Interpreters were equipped with lavalier microphones that recorded both their speech as well as thespeech of visitors in their immediate vicinity. A fixed camera at the back of the exhibit (see Figure 1) providedan overview of Paws and captured visitor and interpreter gesture, gaze, stance, and relative positioning. Afterthis implementation, we held two post-hoc design revision meetings that included Lorraine as well asBrookfield Zoo’s interpretive programs manager and another interpreter who had received additional training infacilitation for climate change and arctic issues. These meetings were recorded and gave additional insight intothe reasoning behind the style of facilitation Brookfield Zoo’s interpreters are trained in.Using Quicktime Pro and ChronoViz, a qualitative data analysis application, the audio and videorecordings of the two-day implementation were combined using multiple audio tracks (from the differentlavalier microphones). For each day, the researchers identified and marked the spans of time where aninterpreter was holding the TST. These timespans were transcribed, with particular attention paid to interactionswhere the TST was referenced or used by either the interpreter holding it, the visitor, or another interpreter.The cases below were selected to show instances where interpreters were using the TST as part of theirfacilitation. When a Paws session was in progress (i.e. for almost all of the time recorded), interpreters werecontinuously conversing with visitors, but not all of these conversations referred to TST resources. This is notsurprising, as the TST was still relatively new to this group of interpreters. These cases are therefore meant toillustrate some potential ways that the TST can be incorporated into and mediate interpreters’ facilitation.Case Analyses: Orchestrating Facilitation with the Support ToolWhen facilitating Paws, the interpreters faced a challenge that was novel in some ways compared to theirtypical interpretive tasks, which generally are comprised of individual interpreters having extended discussionswith families and small groups, or presenting scheduled, lecture-style talks with preplanned content. Paws, incomparison, incorporated multiple learning goals related to climate change (e.g. understanding regional changeover time, representational literacy, “experiencing” polar bears’ struggles) as well as a dynamic simulation thatrequired extended visitor participation. The TST was designed to help interpreters orchestrate Paws bypresenting multiple representations of the player’s progress (location on the map, distance and time meters, anda caloric expenditure graph), but the introduction of the tool also impacted the relationship between theinterpreters in the exhibit. In one case on the first day of the implementation, Lorraine accidentally interruptsICLS 2014 Proceedings200© ISLSClaire’s discussion with a group of visitors around the differences in sea ice between the different simulations ofthe arctic environment:<Claire walks forward towards mixed-age group of visitors around stanchions at theperiphery of the exhibit. She is holding the TST in front of her like a screen>Claire: So now in 2045 there’s gonna be a *lot* more *water* than there will be ice, so she’sgonna be swimmin’-- swimming a lot more [points back to current Paws player] than our lastguest, <previous player> did, in 2010.<Short pause as Claire looks back at current player and visitors look at TST and the currentplayer, while Lorraine approaches the same group of visitors>Claire: <simultaneously> And that’s-Lorraine: <simultaneously> Now have you guys-- sorry-Claire: Go ahead.Lorraine: Sorry, have you guys gotten to see the polar bears here? We have two polar bears,do we know-- do you guys know who our polar bears are here?<Lorraine has discussion with visitors about the polar bears at the zoo, Claire turns back tothe Paws player>Claire: <cheering on the player> Good job, keep it goin’, you’re doin’ a good job!Claire begins a discussion about changes in sea ice extent due to climate change, showing the player progressmap on the TST to a group of visitors, and connecting this to the differences in effort between two Paws playerswho experienced different years. However, Lorraine accidentally interrupts Claire’s discussion during a shortlull, and introduces a different conversation about the identities of the resident polar bears at the zoo. Clairedecides to turn backwards from the group and join another interpreter in cheering on the player’s efforts (whichwas a common action for many interpreters to engage in when there weren’t visitors available to speak to).This case illustrates the additional attentional demands that the TST creates for interpreters. Typically,joint facilitation of an exhibit (which is common at Brookfield Zoo) involves a pair of interpreters discussingexhibit content with visitors. Interpreters largely use social norms to negotiate conversational turn-taking, butthe introduction of TST complicates this arrangement. It creates a situation where visitors’ silent observation (ormanipulation) of a screen is an additional “relationship” present in the social space. This can make it difficultfor interpreters to judge when they should change the conversational focus (since the TST creates anothersource of stimuli that interpreters must monitor), as well as complicating visitors’ attention (as the TST can playthe role of another “participant” in the conversation). It is especially critical that interpreters are able tonegotiate these new attentional challenges when using the TST.In the above case, the visitors were mainly at the periphery of the exhibit, which may have made itadditionally difficult for Claire and Lorraine to accurately judge the visitors’ engagement with the exhibit. In thefollowing case from day two, Lorraine and Audrey—facilitating for a group of visitors who, in this case, weregathered at the center of the exhibit—used the TST to support their joint facilitation based on conceptual andtemporal divisions between different Paws topics, at the point where one run of the simulation was ending:<Lorraine and Audrey are standing on either side of the main screen. One child is controllingthe bear (“Player”) while the other three are pantomiming along by mimicking the player’sswimming and walking motions (“Pantomimers 1-3”). This behavior is also being modeled byLorraine who is in the middle of an extended interaction with the visitors. Audrey is holdingthe TST and watching their progress>Lorraine: […] So we gotta get to that seal. <Speaking to the pantomimers> Are you helpin’her swim? Are you helpin’ her swim?Pantomimer 1: Why-- why-Pantomimer 2: Yeah I am.Pantomimer 1: Why does she-- need to eat the seal?Player: Cuz I’m hungryyy!Lorraine: It’s because, is-- is she a person? No, she’s a what?Children: <in unison> Polar bear.Lorraine: And polar bear-- and what-Audrey: <interrupting> Alright you’re almost close!Lorraine: Oh she’s almost there!Pantomimer 1: Yeah!<The player reaches the seal, which is the goal of the game>Lorraine: She got it, yay, she eats her seal, it’s delicious!Audrey: Alright so I’m--ICLS 2014 Proceedings201© ISLSLorraine: Good job, good job.Audrey: [looking down at TST] Alright, so in two minutes and eighteen seconds, you burnedfour hundred and eighty nine—[turns to group and points to screen] fifty two calories. So ifyou were a polar bear [points to screen, turning TST away from group] and you were tryin’ toget that food, that’s how much calories you would've burned in that little time.Player: Is that good?Audrey: That’s a lot, that’s a lot of calories. And if they burn a lot of calories, that means thattheir body's gonna go lower and lower and they’re gonna have to find more food.<One of the pantomimers says something inaudible>Audrey: So do you guys think that it’s possible to help out polar bears that live over there, doyou think it’s possible that we can do something here to help them out? Like what? What doyou guys think we can do?As the player is nearing the end of their run, Lorraine guides the discussion around a few topics: the identity ofthe player as a virtual polar bear, the differences between running and swimming, and that seals are eaten bybears for energy. Audrey interrupts this conversation when she sees the player is approaching the seal on theTST map. Upon reaching the seal, Audrey reads out the amount of calories that the virtual bear spent, and has aback-and-forth with the player about the meaning of bears spending energy to find food, and that bears mightnot be able to recoup their caloric losses if they have to travel far. She then shifts the discussion towards climatechange mitigation actions that visitors can engage in, asking the children for ideas on how their actions canaffect the arctic environment.In this case, the TST mediates Audrey’s interaction with the visitors, as she plays the role of shiftingthe visitors’ focus towards complex topics of caloric expenditure and climate change mitigation. Here, the TSTis used to expand on ideas introduced in an abstract manner during gameplay (e.g. energy usage), which thesevisitors were already attending to as a group. Audrey builds on the ideas that Lorraine introduced, situating themin the immediate experience that the visitors had just shared (e.g. What does the player’s performance meanrelative to polar bears’ need for energy?). Rather than using the TST to continue the discussion led by Lorraine,Audrey uses the TST to move from playing Paws, to reflecting on the larger topic of climate change mitigationthat forms the context for the entire exhibit. Audrey’s use of the TST was also skillful because she recognizedthe correct time to interrupt Lorraine’s interaction. If Audrey had tried to shift the visitors’ focus to climatechange mitigation before the game had ended, she would not have been able to make use of the final “caloriesexpended” value displayed on the TST to motivate the interest of the visitors, and instead would have had torely on a less immediately relevant argument. When facilitating dynamic player-driven exhibits, it is critical thatinterpreters have a keen sense of the appropriate time to introduce new ideas into a discussion. Coveringinstructional content “just-in-time” allows for interpreters to make use of coherences between the playerexperience and the behavior of the simulation (Crowley & Galco, 2001; Jimenez Pazmino et al., 2013).Although the first case shows that the TST can introduce new challenges for how interpreters coordinate theirjoint facilitation, it is also able to provide representations—in the second case, the map of player progress—thataid interpreters in judging when is the optimal time to step in and engage in facilitation around a new topic.Case Analyses: Shifting the Support Tool's Role in InquiryOne of the central practices emphasized in Brookfield Zoo’s interpretive training is connecting the personalexperiences of visitors with the instructional content at exhibits, which is often removed from visitors’ everydayunderstanding of biology or ecology. While making content relevant is difficult and can be a challenge in formallearning environments, it is additionally so in informal learning environments where visitors—especially zoovisitors—are very diverse in age, interest, background knowledge, and group composition (e.g. parents withteenage children, elderly couples, elementary school groups). This means that interpreters have to be adept athaving back-and-forth conversations with visitors. Lecturing didactically or engaging in rigidly structuredinteractions such as the common Initiate-Response-Evaluate classroom pattern (Mehan, 1979) would not offerserendipitous information about a learner’s interests or knowledge. This information is critical to interpreters asthey are trained to seek out unexpected ways of making exhibit content relevant to visitors.Often, interpreters will rely on personal anecdotes and comparisons between their own and visitors’lives as a way to initiate conversations, build rapport, and establish analogies that can be used to explainunfamiliar topics. They are also trained in using props, especially animal remains (nicknamed “skulls andskins”), to serve the aforementioned conversational functions. In a sense, the TST is one such prop, as itprovides at-hand visuals that can be used to engage visitors. However, the TST differs in that it mainly displaysre-representations of the digital exhibit (the progress map and calorie graph). This allows TSTs to play ananalogical role affording a different point of access to exhibit content, similar to interpreters’ personalanecdotes. But since the TST is built around data representations, the interpreters perceived it as less accessibleor attention-grabbing for visitors compared to a personal story or connection. Thus there is a risk that during anICLS 2014 Proceedings202© ISLSinteraction with visitors, the interpreter might have difficulty establishing the epistemological role of the TST(what function it is supposed to serve as a source of knowledge for supporting collaborative learning).During the first day of the implementation, Kristina (who was the one teenaged YVC interpreter at theexhibit) used the TST to shift an “off-topic” conversation towards the Paws exhibit’s core learning goal:<An adult visitor (“Visitor”) who had been cheering on the player initiates a conversationwith Kristina, who is holding the TST, about how to make the game even more “embodied”>Visitor: What would be funny is if you had a squirt bottle and a sprayer.Kristina: It would-- that would be-- that’s actually kind of a good idea.Visitor: [laughs]Kristina: I don’t know if we’re allowed to do that, we might have to look in-- that would befun, just when you hit the water.Visitor: Just when she hits the water.Kristina: [laughs] Now you swim, yeah.Visitor: Yeah, that would be fun. [laughs]<Kristina angles the TST towards the visitor>Kristina: And you see if you pick the year like-- if you pick the projected year of 2045<Visitor looks down at TST> you’d get squirted a lot more often.Visitor: Yeah.Kristina: More water in the area. <Visitor looks up and nods>Although the conversation begins with a seemingly minor remark about an addition to the exhibit facilitation,Kristina subtly turns the conversation towards the central exhibit topic of change in sea ice and polar bearenergy usage over time. The visitor may not have even noticed the TST when she initiated the conversation, butKristina was able to include it in their conversation fluidly because it was already in her hands. Without theTST, Kristina would not have had a means of connecting future sea ice extent, the player’s experience, and thesquirt bottle idea directly, assuming she would have even chosen to make that conversational move at all. In thiscase, the TST is being positioned as a source of information about a potential experience (“if you pick…2045you’d get squirted a lot more often”) but also as a bridge from visitors’ personal contributions to exhibit content.Having a ready means of drawing connections between the unpredictable statements of visitors and the topic ofa nearby exhibit is something that interpreters value. The TST gives them a resource that they can rely on to turna conversation towards the topics they are trained to discuss, and that they judge as valuable for learners.Later in the first day, another interpreter, James, has an extended interaction with a family group as thethree young siblings (“Eli”, “Aaron”, “Adam”) take turns playing Paws one after another (Figure 2 below).Most families with multiple siblings would only allow one child to play, since each run took about five minutes,which is a lengthy stay in the context of typical zoo exhibits. However, James interacted with the group forfifteen minutes while the other interpreters at the exhibit worked with the player and other visitor groups. Thisgave James multiple opportunities to position the TST as a tool for inquiry.Figure 2. James (green shirt, middle) shows the TST to Eli and Aaron while their sibling plays Paws.<James standing with Eli, Aaron, and their mother. Aaron has just finished playing Paws andis James’ focus>James: [leans down to show Aaron the TST] Alrighty, so now you can kinda see what you hadto travel, you see that distance from the blue dot to the red star? That’s what you traveled. Butyou had, did you think, did you think there was more ice or more water?Parent: < ? > faster too on ice.Aaron: Wa- ice.James: Right, that’s right. So, now did you notice, was it harder to swim or was it easeharder to walk?Aaron: Harder to swim.ICLS 2014 Proceedings203© ISLSJames: Exactly, it was harder to swim. So you can kinda see how that’s gonna happen on thislittle chart. ‘Cause graphs are awesome, they tell you a little bit about everything.<Later in the conversation>James: [kneels down and shows TST to Eli and Aaron, who both look at it] Now! On thisgraph! Where do you think he was swimming? When less energy was used, or more energy?[pointing at different segments of the line graph]Eli: More.James: More? Yeah. So you can kinda take a look at this graph, and it’s gonna kinda showyou how over time, more energy is used when you're swimming. So that's proof right there,that you’re not crazy, you do get more hungry after you swim.Here, James is positioning the TST—specifically the caloric expenditure graph and map—as a source ofinformation, in particular as a way to find out more about what the player experienced and how it changed overtime. This differs from the more didactic stance that interpreters take when presenting exhibit content in scriptedtalks. Even though the conversation is relatively one-sided (part of this likely being due to the age of thechildren), James repeatedly positions the TST as the source of his observations about the game state, by makingreference to the graph as proof that “you’re not crazy” and that more energy is used while swimming. AsBrookfield Zoo has been increasingly incorporating inquiry activities into facilitation, this interpretive practicealigns well with their institutional goals. By using the TST and its data representations as an accessible means ofproviding evidence for questions, rather than just being proof of an interpreter’s assertions, it becomes availablefor inquiry driven by both visitors and interpreters. Despite the fact that these questions (“Was it harder to swimor was it harder to walk”) were stated by an interpreter, and were asked because they lead to a particular desiredconclusion (i.e. the visitor realizing that swimming is harder), the TST was being positioned as providing accessto the answer, which is a critical epistemological move for instructors (Jaipal, 2010).Interpreters using the TST had a range of resources that they could draw on as they interacted withvisitors, but they did not use all of these resources in the same way, or in the ways that we designed. Forinstance, the “just-in-time” discussion prompts were designed to aid interpreters in connecting the ongoingactivity at the exhibit with Paws learning goals, but they were not used to drive visitor inquiry. Rather, the mapand graph were more frequently used for this purpose, even though the interpreters had to specifically clarify theconnection of those resources to the activity at hand during discussions with visitors. Interpreters exercised theirown ad hoc judgments of how best to facilitate visitor inquiry with TST and Paws resources (e.g. James’question about Aaron’s experiences as a player), rather than relying on the pre-designed contextual prompts.Both Kristina and James were able to connect the Paws players’ experiences with the re-representation of thoseexperiences on the TST, indicating their ability to position the TST as a means for visitors to gather evidenceabout questions the interpreters had posed. We still believe “just-in-time” notifications can be helpful, but wouldbe better used for non-inquiry practices, such as supporting interpreters’ situational awareness and their abilityto collaboratively shift visitors’ attention and discourse, rather than initiating and supporting visitor inquiry.Discussion and ConclusionsEven with little training in how to facilitate exhibits with a handheld tool, the TST was able to supportinterpreters by allowing for facilitative practices that they did not previously have access to. Interpreters wereable to use the resources and awareness provided by the TST to coordinate collaborative facilitation of theexhibit. The interpreters transitioned between topics based on the state of the interactive exhibit, requiringinterpreters to make use of their own training as well as situational awareness provided by the TST to makethese shifts at appropriate times. Interpreters were also able to use live data representations as a way to establishconnections between visitors’ personal comments and exhibit content, as well as for positioning exhibitresources as available for collaborative meaning-making. Interpreters facilitated inquiry in this way bygenerating questions around TST resources that allowed those resources to be used by visitors as evidence. Thefact that lightly-trained interpreters were able to enact these practices suggests that TSTs hold much promise,certainly as a mediational tool in interactive exhibits like Paws, but possibly in more traditional exhibits as well.This work raises a number of questions about interpreter practice, especially about the decision-makingprocess that interpreters use to guide their interaction with other interpreters and visitors. Why did interpreterschoose to discuss particular topics at the times they did? How and when should the TST be strategicallyemployed to guide visitor inquiry? Investigating these questions would also contribute to literature and trainingaround interpreter-supported visitor inquiry (Garibay et al., 2010), by introducing the potential for technologicaltools to support and facilitate inquiry in informal learning settings. These tools provide interpreters with ways tofacilitate STEM skills (e.g. situating abstract data representations) with visitors, including with younger learnersthat have limited representational fluency.Our next revision of the TST is centered on improving interpreters’ situational awareness andproviding them with a wider range of resources. This involves keeping easy access to key representations suchICLS 2014 Proceedings204© ISLSas the map and graph that interpreters used consistently to organize their facilitation, while also presenting andsorting additional resources (e.g. sea ice seasonal variation, polar bear habitat shifts, caloric expenditure ofanalogous human activities) based on their relevance to the current state of the simulation. This is designed toallow interpreters to keep track of the player’s progress, identify potential connections they can illustrate for theperipheral visitor audience, and have greater flexibility of resources that can be incorporated into discussionswith visitors. The introduction of a TST for interpreters doesn’t just improve on existing facilitative practices,but has the potential to support qualitatively different forms of facilitation. This is possible when interpretersrecognize the ways in which the TST can change the contextual landscape of an exhibit, and can change thekinds of conversations that interpreters have with visitors.ReferencesBeck, L., & Cable, T. (2012). The gifts of interpretation: Fifteen guiding principles for interpreting nature andculture: Sagamore.Bell, P., Lewenstein, B., Shouse, A., & Feder, M. (2009). Learning science in informal environments: People,places, and pursuits. National Research Council.Bezemer, J., & Kress, G. (2008). Writing in multimodal texts: A social semiotic account of designs for learning.Written Communication, 25, 166-195.Bodker, S. (2009). A human activity approach to user interfaces. Human-Computer Interaction, 4(3), 171-195.Crowley, K., & Galco, J. (2001). Everyday activity and the development of scientific thinking. In K. Crowley,C. Shchunn & T. Okada (Eds.), Designing for science: Implications from everyday, classroom, andprofessional settings. Mahwah, NJ: Erlbaum.Falk, J., & Dierking, L. (2008). Enhancing visitor interaction and learning with mobile technologies. In L.Tallon & K. Walker (Eds.), Digital technologies and the museum experience: Handheld guides andother media: AltaMira Press.Garibay, C., Martin, L., Rubin, A., & Wright, T. (2010). Math in Zoos and Aquariums: The Evolution of aProfessional Development Workshop.Gutierrez, K. (1994). How talk, context, and script shape contexts for learning: A cross-case comparison ofjournal sharing. Linguistics and Education, 5, 335-365.Hall, T., & Bannon, L. (2006). Designing ubiquitous computing to enhance children's learning in museums.Journal of Computer Assisted Learning, 22(4), 231-243.Heath, C., vom Lehn, D., & Osborne, J. (2005). Interaction and interactives: collaboration and participation withcomputer-based exhibits. Public Understanding of Science, 14(1), 91-101.Hornecker, E. & Stifter, M. (2006). Learning from interactive museum installations about interaction design forpublic settings. Paper presented at the 2006 Computer-Human Interaction SIG of the Human Factorsand Ergonomics Society of Australia (OzCHI).Hsi, S. (2008). Designing for mobile visitor engagement. In L. Tallon & K. Walker (Eds.), Digital technologiesand the museum experience: Handheld guides and other media (pp. 125-146): AltaMira Press.Jimenez Pazmino, P., Lopez Silva, B., Slattery, B., & Lyons, L. (2013). Teachable mo[bil]ment: Capitalizing onteachable moments with mobile technology in zoos. In Extended abstracts of the 2013 Conference onHuman Factors in Computing Systems (CHI EA 2013). Paris, France.Jaipal, K. (2010). Meaning making through multiple modalities in a biology classroom: A multimodal semioticsdiscourse analysis. Science Education, 94, 48-72.Mehan, H. (1979). Learning lessons: Social organization in the classroom. Cambridge, MA: HarvardUniversity Press.Noffke, S. (1997). Professional, personal, and political dimensions of action research. Review of Research inEducation, 22, 305-343.Rejeski, W. (1981). The Perception of Exertion: A Psychosociological Integration. Journal of Sport Psychology,4, 305-320.Roschelle, J., & Pea, R. (2002). A walk on the WILD side: How wireless handhelds may change computersupported collaborative learning. International Journal of Cognition and Technology, 1(1), 145-168.Tilden, F., & Craig, R. (1977). Interpreting our heritage: University of North Carolina Press Chapel Hill.Wertsch, J., & Rupert, L. (1993). The authority of cultural tools in a sociocultural approach to mediated agency.Cognition and Instruction, 11(3/4), 227-239.Yoon, S., Quintana, C., Lyons, L., Perry, J., Osterweil, S., & Lindgren, R. (2013). Promises and perils of usingdigital tools in informal science learning environments: Design considerations for learning. Paperpresented at the 10th Int’l Conference on Computer Supported Collaborative Learning (CSCL).AcknowledgmentsThis work was supported by NSF CCEP-I Grant 1043284.ICLS 2014 Proceedings205© ISLS