Towards the Facilitation of an Online Community ofLearners: Assessing the Quality of Interactions in YammerMarcela Borge, Pennsylvania State University, mborge@psu.eduSean Goggins, University of Missouri, gogginss@missouri.eduAbstract: This paper focuses on evaluating a theoretically informed approach to using socialmedia as a means to support the development of a community of learners in an introductoryhuman computer interaction course at a major US research university. Social network andcommunication analysis were used to examine the form and function of social interactions inYammer. The data suggests that the theoretically informed approach to using Yammersucceeded in encouraging processes associated with a community of learners. The methodsused in this paper may contribute to more effective ways of assessing the quality of discoursein socio-technical environments and the findings provide potential models for using socialmedia as new contexts for developing conceptualization and discourse practices.IntroductionUser-Centered Design is a methodological approach within the field of Human Computer Interaction (HCI) thatrequires diverse knowledge and expertise. Both user-centered design and science share an inherent complexity,and the need for practitioners to make sense of many facts in order to advance solutions. Specific similaritiesinclude the requirement for a deep understanding of practice, higher order reasoning, and the ability to applytheory in concert with the accepted methods of the field. The inherent problem in teaching an introductorycourse in user-centered-design in higher education is that students expect a traditional lecture-based pedagogy, aform of instruction that is ineffective in helping beginning designers to develop necessary knowledge andabilities. In order to become designers, students need opportunities that require them to start thinking likedesigners: to critically evaluate artifacts in the real-world, think about user needs, cognition, emotion, resources,markets, and how all of these variables lead to the design of innovative solutions. Progressive instructionalmethods that emphasize student-centered learning have the potential to allow students to become more activeparticipants in the learning process. The problem is that senior college students come with rigid mental modelsof what classroom interactions should be like in college settings. These student expectations have been shapedby past experiences and create obstacles for those aiming to introduce more progressive instructional methods,such as the development of a community of learners. If previous experiences create obstacles, then perhaps therewould be fewer obstacles to progressive instructional methods in environments where students have had lesseducational experiences. Therefore, we wanted to examine the utility of using a social media environment,called Yammer to create learning environments outside of the classroom. We applied educational theory toguide the use of Yammer and examined the extent to which it could provide an engaging socio-technical contextfor learning. Yammer was used as a means to facilitate back channel discourse and communication in anintroductory HCI Course at a major US research university. We then examine whether the form and function ofdiscourse activity coincides with expected outcomes derived from learning theory.Related LiteratureBecoming Human-Centered DesignersHuman-centered design (HCD) is a complex approach to developing design solutions that requires deepunderstanding of psychological theories and design practices. A central consideration of HCD is theidentification of the needs, goals, and limitations of end-users. In order to become an effective user centereddesigner, students need to develop a wide range of content-specific and domain-general knowledge and skills.Students have to understand multiple theories related to how people think, learn, and interact with theirenvironment as well as how these theories can be articulated through design (Carroll, 1997; Norman, 2002).Students also require domain general skills. They must learn to collaboratively illustrate their understanding ofdesign problems and potential design paths, create representations to summarize findings, and communicatetheir ideas and reasoning to diverse audiences (Dym et al., 2005).Unfortunately, students in HCD courses have been shown to lack domain-general skills: they do notreflect on their practice, negotiate or evaluate ideas with others, and also have problems applying courseconcepts to real world examples (Borge & Carroll, 2010). Students learn how to replicate methods and practice,but without a full understanding of why they are necessary or when they are useful. Such a findings are likelywhen students are not provided with opportunities to develop content specific and domain general knowledge insynchrony (Schunk, 2012).ICLS 2014 Proceedings753© ISLSCharacteristics of Learning Communities and ImplicationsStudents have been historically treated as peripheral in the learning process (Cuban, 1984). Most classroomsfollow a model in which an instructor transmits knowledge to students and the main instructional goal is tomotivate students to be receptive to the transmission (Rogoff, 1994). These types of classrooms are typicallylecture-based, where the teacher is the primary source of verbal activity (Dunkin & Biddle, 1974).Many researchers have advocated against traditional instructional practice in support of a more studentcentered learning model. A student-centered learning model requires the instructor to shift from the role centralknowledge authority to a facilitator of knowledge building activities, while students move from the peripherytowards becoming central contributors of ideas for the community (Lave & Wenger, 1991; Papert, 1993).Fostering a Community of Learners (FCL) is one such model with certain key features: (1) students engage inindividual research in order to (2) complete an important task and (3) share information in order to help eachother complete the task. Meanwhile, students are also trying to deeply understand the disciplinary content that isinherent to the task (Brown & Campione, 1996). Another important aspect of FCL is for the instructor to maketime to model thinking processes (Brown, Collins, & Deguid, 1989; Collins, Brown, & Houlm, 1991). For thisreason metacognitive reflection is also an important element of this learning environment. Brown and Campione(1996) argue that it is not enough to have scripts or rules for how to behave, but that it is necessary to develop asystem comprised of the previously mentioned components to provide a meaning and philosophy to support theculture of a community of learners.The literature presented suggests potential methods that could be used to examine whether a learningcommunity is actually developing in a virtual environment. For example, certain patterns of social interactionwould need to be present. The instructor (expert) would likely be a central participator towards the beginning ofa course with more posts and more interaction with students. In the beginning, students would likely belegitimate peripheral participators, participation in regular, low-risk behaviors that still aid the learning process(Lave & Wenger, 1991). As the course progresses, we would expect to see the expert slowly move to theperiphery, while the students move towards central participation; the students would gradually become primaryverbal contributors and participate in more sophisticated and risky social interactions. High quality and riskierinteractions for design students in particular would include evidence of students reflecting on their learningpractice or course concepts, evaluating course concepts, and applying course concepts to real-world examples inorder to explore ideas in different contexts (Borge & Carroll, 2010). We can also infer from Brown & Campione(1996) and Brown et al. (1989) that it is crucial for the majority of a learning community’s discussions to centeron disciplinary content, where students use the language of the course, and try to develop their understanding bysharing resources, opinions, or interpretations meaning and implications in order to effectively apply courseconcepts to a task or practice.Analysis of online participation data opens an opportunity to visually represent the patterns ofinteraction in an online community and examine the extent to which they coincide with theory. The ontologyand methodological approach of group informatics (Goggins, 2013) will help us to systematically connectquantitative, visual indicators of movement from a network core to a network periphery with a qualitativeunderstanding of how participants interact through Yammer. This can help to identify the primary ways thatstudents discuss disciplinary content and to what extent this “talk” shows evidence of collaborative analysis andinterpretation of course content.Study designDesign-Based Research Methods and Research QuestionsThe overall methodology was design-based research, a method used to evaluate the potential of an educationaltechnology that is grounded in theory or prior work and evaluated in real classroom settings (Brown, 1992). Themain research questions were, (1) to what extent do patterns of interaction support or negate the development ofa digital community of learners and (2) to what extent would students demonstrate sophisticated levels ofthinking in the environment. The first question explores the extent to which the instructional approachsucceeded in pushing students to communicate with each other about course content and become the primaryproviders of information for the community. Whereas, the last question focuses on ensuring that the discourse isproductive from a learning perspective, as content related interpretation is more conducive to learning than offtask discourse (Wienberger & Fischer, 2006).Course Content, Learning Objectives, and Student AssessmentThe introductory course to user-centered design is a requirement for students in the design and developmenttrack of an information sciences and technology college in a large, US University. The course introducesstudents to fundamental concepts and practices of interaction design. Interaction design bears a resemblance toHCI, but goes beyond HCI’s traditional emphasis on interaction with computers to include designing for avariety of human experiences (Rogers, Preece, & Sharp, 2007). Nonetheless, interaction design and HCI shareICLS 2014 Proceedings754© ISLSmany core concepts and techniques. The course builds on a foundation of knowledge from cognitive anddevelopmental psychology in order to help students understand “users”, the people they design products for. Thecourse presents users as thinking beings with specific cognitive limitations that learn to interact with objects bysynthesizing present experiences with past experiences and the knowledge, tools, and values associated withthose experiences. These psychological theories serve as the foundations for design heuristics, additionaltheories, and methodological frameworks that evaluate the products that designers and developers create in theirattempts to solve everyday problems.The introductory 16-week user-centered design course was divided into two parts: Part 1 (knowledgecomprehension) and Part 2 (knowledge application). It was taught by one instructor and supported by anundergraduate learning assistant. During each week of Part 1 of the course, students worked on a designchallenge connected to course concepts. During Part 2, students picked their own design challenge and wereexpected to complete a project to demonstrate their ability to apply the core concepts and techniques covered inthe course. The class met three times per week for 50-minutes sessions. On the first day of the week theinstructor would take 20 minutes to go over difficult concepts, on the last day of the week the instructor woulduse 15 minutes to review the week and answer questions. During the rest of class time, students worked ondesign challenges with a team of five-to-six members. During these work sessions the instructor and the learningassistant would walk around the class and check in on teams. In place of additional homework, students wererequired to post on a professional social media site, called Yammer, outside of class each week and discusscourse topics. Students would receive credit for starting new discussion threads by creating an original post.They would also receive credit for engaging in an existing discussion by replying to an original post or byreplying to a reply. Students could also “like” posts or replies, but would not get full credit for this kind ofactivity. This was the primary form of discussion for students with other class members that were not in theirimmediate team. Course participation accounted for 25% of the students’ overall grade and consisted ofattendance, posting to and moderating Yammer, and providing one peer review of another team’s designchallenge.ParticipantsThe study participants were junior and senior college students enrolled in an introductory human-centereddesign course at a large, US university. Students were divided into nine teams of five-to-six students in part oneof the course and a different team in in part two of the course. There were 38 participants included in the study,four of which were women; this is fairly representative of the gender distribution in the college.Introducing Social Media as a Learning ToolWhen integrating Yammer into classroom, there were design principles derived from the learning theory that theinstructor followed. These were used as a means to increase the likelihood that Yammer would serve as aneffective learning tool. For example, a modified version of cognitive apprenticeship was used as a means toacculturate students to the online community and present it as a situated learning environment (Brown et al.,1989; Collins et al., 1991). The Instructor would model desired posting behaviors, coach students on their posts,encourage sense-making activity, provide guides to help students learn how to moderate Yammer, slowly shiftmoderating responsibility to student teams, and then slowly fade from the environment. The goal was for thestudents to eventually take ownership of the environment.Students were introduced to Yammer in the first week of class and the instructor modeled a variety ofdifferent original posts: reflecting, sense making, resource sharing, coaching, and polling students. Studentswere told that posts should relate to weekly course content. Throughout the next four weeks, the instructor usedYammer to model how to use and evaluate a range of outside resources, (i.e., academic articles, professional UXdesign blogs, magazine articles, and Wikipedia) and thinking (how sources could be used as a means to furtherdevelop understanding). The instructor maintained full responsibility for moderating Yammer for four weeksand then assigned each team to moderate thereafter. When moderating, students were responsible forencouraging each other to connect course content, respond to posts, and keep track of participation. Themoderation of Yammer was a large part of their participation grade.Data CollectionThe data from the Yammer environment was extracted and exported to excel spreadsheets. There are three typesof posts in Yammer: original posts, replies, and replies to replies. Each original post was the start of a newconversation and was time stamped. The data also provided the name of each poster, a unique ID, and created aThread ID matching the unique ID of the poster. When students replied to original posts, the replier would beidentified by a new unique ID and associated with a Thread ID that matched the original poster’s ID. Thisallowed us to see who replied to whom and identify different threads of conversation. The data also allowed usto see replies to replies. These posts contained the users unique ID, as well as a Replied to ID that matched theunique ID of the person they replied to; the thread ID still match the unique ID if the original poster. The termICLS 2014 Proceedings755© ISLS“post” refers to original posts, replies, and replies to replies. Whereas, the top-level post that starts a newconversation thread refers to an original post. The data also included the entire content of what was beingshared and links to any additional articles or materials that students attached to the post. This allowed us toanalyze the quality of content.Examining Social Interaction PatternsGroup informatics methods were used to examine patterns of interaction that emerged over time (Goggins,Mascaro, & Valetto, 2013). The data was cleaned and exported to a social networking analysis tool, calledGephi. In total, 503 posts were analyzed in Gephi. This tool facilitated the creation of visualizations to captureactivity: people are represented as nodes and lines between nodes represent connections. Connections indicateevents where students respond or are responded to in the Yammer. Two separate students exported the data intoGephi and produced independent visualizations and ran analysis in order to ensure that the system andsubsequent analysis was reliable. Besides aesthetic differences, the results of the analysis were the same.Classification and Assessment of PostsThe objective of this analysis was to assess the quality of discourse that students engage in while using theenvironment, for this reason the 98 instructor posts were excluded from the analysis. The remaining 405 studentposts were classified according to the topic of the contribution and whether it was connected to course content.Posting behavior was categorized according to the type of cognitive activity represented in each post. In order todevelop a valid and reliable coding construct, coding activity was initially based on differing levels of cognitiveactivity that coincided with previous work (Borge et al., 2012). When possible behaviors were exhausted, aconstruct map was developed with levels of cognitive behaviors, definitions, and concrete examples. Thedifferent types of activity were then compared to research from communication analysis and sense-makingliterature (Convertino et al., 2009; Dyke, Howley, Adamson, Rosé, 2012; Pirolli & Card, 2005). It is importantto note that the levels of did not assess writing quality, but rather the level of cognitive activity that studentsdisplayed in the post. Utilizing methods similar to interaction analysis (Jordan & Henderson, 1995), meetingswere held with student researchers to pick out behaviors and distinguish between codes in order to refine thecoding construct. Level of cognitive activity was used as a means to assess the quality posts in the social mediaenvironment: informal, practice oriented conversations. Once the coding construct was finalized, the first authorand a research assistant analyzed 20% of the data. The inter-rater reliability was substantial (Landis & Koch,1977): r = .89, p < .001; Kappa = .78, p < .001. Disagreements were discussed and resolved. The researchassistant then coded the full data set.ResultsSocial Interaction PatternsSocial network analysis revealed three major patterns in the data. These patterns support the claim that there wasa high-level of student participation and connections between students during discourse, and that studentseventually took responsibility over the learning environment. Our findings use the language of social networkanalysis and group informatics. Conceptually, lower centrality measures correspond with what Lave & Wenger(1991) describe as “peripheral” participation. High “degree centrality” corresponds with membership in thecore. The first pattern is related to the density of participation and level of connectedness of students. Findingsindicate that there was a high degree of participation from the class as a whole and students were very connectedto classmates through posting behavior. This is characterized by the visualizations in Figure 1, which shows ahigh degree of participation and ties between students at each four-week time interval. Nodes indicate studentswho contributed posts and the size and color of the nodes indicate frequency of posting behavior. Lines betweennodes indicate connections between people, meaning they received a post from or sent a post to anothercontributor. Of the 38 students enrolled in the class, only 2 did not participate in the environment at all. Of thosethat participated, four did not establish any connections to other students. On average, students made a total of10.28 posts to the environment over the 12-week period, SD = 7.18, Min = 0, Max = 29. Total posts includeoriginal posts and replies. The total number of student posts was 405, compared to 98 for the instructor.The second pattern identified is related to ownership and cognitive presence in the environment(Garrsion, 2003). The instructor moves from a central to peripheral participator over time, while studentsbecome more central contributors. Figure 1 shows this pattern over three time intervals. Degree centrality, or theimpact a member has in the discussion, is shown by the relative position in the network: the more impactful aperson is relates to how centrally they are located in the network. At P1 the instructor (with the alias of II) is inthe central left with a relatively high degree of posts and connections. At P2, “II” shows movement towards theperiphery of the graph, with fewer connections and posts than at P1. At this time, several students start tobecome more central than the instructor. By P3, “II” has moved to the periphery with very few posts and farfewer connections, whereas students’ posting behavior becomes more equitable and central to the network. WeICLS 2014 Proceedings756© ISLSalso find a shift in type of participation from P1 to P3, addinganalysis of the direction of degree centrality and weight ofconnection, shown in figure 2. “In degree” centrality (x-axis) isexpressed as replies to a person; “out degree” centrality (y-axis) asreplies from a person. Figure 2 illustrates increasing diversity ofparticipation across the time periods, with more people favoring “indegree” or “out degree” centrality. To calculate weight of aconnection, we assign less weight to communications engaging alarger group and greater weight to direct replies to another student,following benchmarks established by Goggins, Laffey, & Gallegher(2011), and a systematic methodological approach for analysis oftrace data, called Group Informatics (Goggins et al., 2013).P1Types of PostsPosts were initially classified as containing course content talk or“other” talk. Course content talk is defined as posts or replies relatedto core concepts and techniques of the class, as well as projectrelated discussions. “Other” talk included course management andmetacognitive behaviors related to awareness and reflection ofstudents’ own learning needs, practices, or experiences. Of the 98Instructor posts, 58 (59.2%) were related to course management, atype of “other” talk. In contrast, only 55 of the 405 student posts(13.6 %) were “other” talk and 86.15 were directly tied to coursecontent. Some of this “other” talk was included posts where studentsshared resources that challenged traditional learning models andwould discuss their own learning experiences. Only 0.25% of totaltalk was considered off-task, not dealing with content or learning.Content-related posts were examined for level of cognitivebehavior. There were five levels of exhibited cognitive behaviors forcontent related talk: sharing, extending, checking/ rephrasing,synthesizing and interpreting (see table 1 for a list of exhibitedbehaviors, definitions, and frequency counts). Though extendingposts were not ranked as highly as interpretation posts, these wereused a great deal by students. Students would regularly go back tosearch for content materials or resources other students shared andwould refer to them in class or use them for their projects. In fact, themost common student complaint of Yammer was that it was hard tofind previous posts.Findings indicate that the quality of posts were relativelyhigh. Sixty-six percent of the posts were classified as synthesis orinterpretation of course content. However, there was a range ofquality within each level. For example, a post would be classified asinterpretation if students made a content related claim and (1)supported this claim with evidence or rationale or (2) consideredalternative viewpoints and weighed options. There were better andworse examples of rationale, evidence, and weighing of concepts inP3Figure 1. Social network diagramsof Yammer activity at three timeperiods: P1, P2, and P3. Theinstructor is labeled “II” and iscircled for easier identification.Nodes are color-coded based oncentrality from least to most central.Figure 2. Increasing diversity of participation role across three time periodsICLS 2014 Proceedings757© ISLSTable 1: Types and levels of talk exhibited by students in the Yammer environment.Level/Type1- Sharing (SHR)2- Extending(EXT)Contentrelated Talk3. Checking/Repeating (C/R)4- Synthesizing(SYN)Non-contentRelated Talk5- Interpreting(INT)MCmetacognitiveReflection/AwarenessCM- ClassManagement% ofDefinitionsPostsDiscussing content or facts without making claims that are supported byrational or evidence. Cannot include concrete examples related to real-worlduse, links or attachments to additional material, reference to previous reply,or reflections on learning or thinking processes.9.1%Extending available readings or content material by providing links orattachments to additional content (video, article, concrete example, etc.) tohelp think about or understand course content. May include level 1behaviors, but cannot Include rational, concrete examples related to realworld use, reference to previous reply, or reflections on learning or thinkingprocesses.17.3%Checking understanding, clarifying what someone previously said, orrepeating/rephrasing previous post without adding new ideas. May includelevel 1 or 2 behaviors, but cannot include new fact, claim, rational,evidence, connections to the real world, or reflections on learning orthinking processes.1.7%Connecting info to other info - making connections to the real world,bringing multiple ideas together. Evidence that post is referring to previouspost and adding to the idea, or that poster is connecting a previous idea to areal-world example that no one else has mentioned. May include level 1-3behaviors, but cannot include evidence or rational for claims, or reflectionson learning or thinking processes.31.6%Connecting course content info to other info and making a judgment aboutit or evaluating a claim or work. Claims or opinions MUST be supportedwith rational or evidence, or they must show that they are weighing ideasagainst each other. May include level 1-4 behaviors, but cannot showevidence of reflecting on learning or thinking processes.26.4%Thinking about or sharing awareness of learning experiences as an object ofthought. Reflecting on learning process, or demonstrating awareness oflearning process by articulating learning patterns, or needs as learners. Mayinclude level 1-5 behaviors.4.7%Posts related to organizing, coordinating, documenting, or deciding onclassroom activity.8.9%posts. For example, a project team was gathering requirements for a design idea aimed at college students,posted a survey, and asked the class to help by providing data. A fellow classmate responded to the post bysaying, “Hey I really liked the way your survey was designed, in terms of asking questions that all relate to eachother in a series, and having repeating variables. Good luck with everything!” In this example, the student shareshis opinion and supports that opinion with a rationale. For that reason it was coded as a level five, but it was oneof the least sophisticated examples found. The following example shows a higher range of sophistication ofthinking. The chapter students read, the week of the post, focused on different user interfaces and their affectson user experience. In Yammer, a student started a new thread, asking students to think about different userinterfaces, trade-offs and design ideas related specifically to air-based gestures. The student presented Kinect forXbox360 as an example from the book and asked, “Do you think adding a hand-held motion sensor controloption would help to improve the Kinect's interface? Yes, it would make gameplay easier, No, the Kinect is finehow it is, Indifferent, I dislike the Kinect and prefer controller-based games?” Many students responded to thispost and what follows is a response rated as a higher range level five post:“I agree with Stanley [tagged], Don [tagged], and Jack [tagged]. I prefer controllers overmotion sensor gaming, and I think adding a "sensor controller" would make it way too similarto the Wii. I think the Kinect is a good concept, and is perfect for casual gamers or familieswho have younger kids, since I find that a lot of Kinect games are geared towards that agegroup. I think it helps to balance the Xbox360 as a whole to be more marketable to a widerranged audience. It allows hardcore gamers to continue using controllers while allowing theiryounger siblings (or possibly children) participate in game time. In response to Julie [tagged],I was able to find statistics that say in 2011, 59 million Xbox 360's were sold and 18 millionKinect's were sold. Not the exact statistics we're looking for, but I think that it shows not allgamers who have 360's are strictly one type of gamer, although I think it does show that moreusers tend to use the 360 for hardcore over casual gaming.”The student begins by choosing which students he agreed with, indicating that he read their posts and begins tosynthesize their input with his own. He repeats one of the claims made in a previous post, “adding a "sensorICLS 2014 Proceedings758© ISLScontroller" would make it way too similar to the Wii” and “Kinect is a good concept, and is perfect for casualgamers”, but then adds his claim about appealing to younger kids. The student supports this claim, stating thatKinect games are mainly marketed to younger audiences. He further supports the claim that adding the Kinectappeals to different audiences, citing facts about the number of Xbox consoles and Kinects sold. He interpretsthe difference in sales as meaning that only small portions of Xbox users add the Kinect option and concludesthat this is indicative of different markets. Here there is evidence of sharing, synthesizing, and interpreting.Interpreting is the highest level of cognitive activity; this post is categorized as a Level 5, interpretation post.DiscussionOur approach examined the form and function of the social interactions that took place over time in the Yammerenvironment. Group informatics methods provided visual tools that allowed us to see changes in the structure ofsocial interactions and changes in member activity. Communication analysis informed us as to the type ofdiscourse activity that occurred and whether it matched to the designer’s intent. Combining these researchmethods provided us with a clear understanding of how the instructional approach for using Yammer functionedin practice. Our findings shed light on the use of social technologies as a means to provide a place for studentsto share, explore, and think about course concepts with others. The learning goals for such a discourseenvironment are comprehension and application, not pure problem solving. This fills an important gap inresearch, as previous studies examining collaborative discourse, are directed at assessing the quality of jointproblem-solving (Roschelle & Teasley, 1995), creation of common ground (Convertino et al., 2009), orconceptual change (Gunawarda, Lowe, & Anderson, 1997). These are important contributions, but they are notfocused on more casual forms of knowledge application and the quality of discourse in a learning community.Our data suggests that the combination of theoretically informed pedagogical design paired with theuse of lightweight social media technology can provide students with opportunities to engage in learningprocesses associated with a community of learners approach to instruction without requiring unsustainablemanagement practices from instructors. This is an important finding because it paves the way for exploringwhether such approaches might scale to larger online learning environments. As online learning environmentsbecome more prevalent, a critical consideration should be what kinds of learning experiences do theenvironments model and support and how will these experiences shape students’ understanding of importantlearning processes and expectations for student-instructor interaction. Our approach enabled students to learnhow to become members of a design community, by connecting course content to real-world examples, seekingout ways to better understand course content, and engage in discussions with other students about core conceptsand techniques related to human-centered design. Also of importance, it planted a seed in students about what itmeans to learn that challenged traditional instructional models. Students were also extremely connected withinthe environment, discussed disciplinary content in fairly sophisticated and meaningful ways, and eventuallyreplaced the instructor as the central information giver and evaluator. Such processes may be even more criticalfor purely online courses as it may help students to feel more connected to each other and to the course content.Another important contribution of this work is that presents social media environments as learningenvironments in their own right, spaces for learning through discourse rather than supplements for transmittingor checking information. These learning environments will likely never be the same as face-to-face interactionsand this fact has both costs and benefits. Rather than emphasizing the ways in which these environments fail toemulate real-world learning activity, we must start figuring out how to use the inherent differences of theseenvironments to extend learning opportunities. We can leverage the lack of students’ experiences with theseenvironments to create a “space” for students to engage in processes they might avoid in face-to-faceinteractions. Previous findings related to students’ lack of ability in college courses, may be the product of acontext that prioritizes task completion over quality of discourse. When groups face time pressures they tend toprioritize task completion over the processes they use to complete tasks (Kerr & Tindale, 2004). This impliesthat the pressure of time constraints and required activities imposed by college course structures, combined withstudents’ previous experiences, may interfere with students’ ability to exercise and improve processes ofconceptualization and discourse. Providing students with a less stressful context, new structures, andtheoretically informed interaction designs may help to mitigate this problem.Future studies will examine student perceptions of the Yammer as a learning tool and include a morefine grain analysis of the strengths and weaknesses of the pedagogical design. We also plan to comparedifferences between resident and online student populations. Through this work we aim to develop a betterunderstanding of the variables associated with rich discourse environments so as to better meet the needs ofstudents and incorporate the application of learning theory into the design of new digital learning environments.ReferencesBorge, M., & Carroll, J. M. (2010). Using collaborative activity as a means to explore student performance andunderstanding. In K. Gomez, L. Lyons, & J. Radinsky (Eds.), Learning in the Disciplines: ProceedingsICLS 2014 Proceedings759© ISLSof ICLS 2010: 9th International Conference of the Learning Sciences. Chicago, IL: InternationalSociety of the Learning Sciences.Borge, M., Ganoe, C., Shih, S., and Carroll, J. (2012). Patterns of team processes and breakdowns ininformation analysis tasks. In Proceedings of the ACM 2012 conference on Computer SupportedCooperative Work. (CSCW '12). ACM, New York, NY, USA.Brown, A. L., & Campione, J. C. (1996). Psychological Theory and the Design of Innovative LearningEnvironments : On Procedures , Principles , and Systems. Innovations in Learning: New Environmentsfor Education (pp. 289–325). Hillsdale, New Jersey: Lawrence Erlbaum Associates.Brown, A. L. (1992). Design Experiments : Theoretical and Methodological Challenges in Creating ComplexInterventions in Classroom Settings. The Journal of the Learning Sciences, 2(2), 141–178.Brown, J. S., Collins, A., & Deguid, P. (1989). Situated cognition and the culture of learning. EducationalResearcher, 18(1), 32–42.Collins, A., Brown, J. S. & Holum, A. (1991). Cognitive Apprenticeship: Making Thinking Visible. AmericanEducator, p.6-11, 38-46.Carroll, J. M., (1997). Minimalism: Beyond the Nurnberg Funnel. MIT Press, Cambridge, MA.Convertino,G.,Mentis,H.M.,Rosson,M.,Slavkovic, A., and Carroll, J. M. (2009). Supporting content and processcommon ground in computer-supported teamwork. In Proc. CHI 2002, ACM press (2002), 2339-2348Cuban, L. (1984). How teachers taught: Consistency and change in American classrooms 1890-1980. NewYork: Knopf.Dunkin, M. J., & Biddle, B. J. (1974). The study of teaching. New York: Rinehart & Winston.Dyke, G., Adamson, D., Howley, I., Rosé, C. P. (under review). Enhancing Scientific Reasoning andExplanation Skills with Conversational Agents, submitted to IEEE Transactions on LearningTechnologies.Dym, C. L., Agogino, A. M., Eris, O., Frey, D. D., & Leifer, L. J. (2005). Engineering design thinking, teaching,and learning. Journal of Engineering Education, 94(1), 103-120.Garrison, D. R. (2003). Cognitive presence for effective asynchronous online learning: The role of reflectiveinquiry, self-direction and metacognition. Elements of quality online education: Practice and direction,4, 47-58.Goggins, S., Mascaro, C., & Valetto, G. (2013). Group Informatics: A Methodological Approach and Ontologyfor Understanding Socio-Technical Groups. JASIS&T, 64(3), 516–539.Goggins, S. P., Laffey, J., & Gallagher, M. (2011). Completely online group formation and development: smallgroups as socio-technical systems. Information Technology & People, 24(2), 104–133.Gunawardena, C. N., Lowe, C. A., & Anderson, T. (1997). Analysis of a global online debate and thedevelopment of an interaction analysis model for examining social construction of knowledge incomputer conferencing. Journal of educational computing research, 17(4), 397-431.Jordan, B., & Henderson, A. Interaction analysis: Foundations and practice. Journal of the Learning Sciences, 4,1 (1995), 39-103.Landis, J. R., Koch, G. G. The measurement of observer agreement for categorical data. Biometrics 33 (1977),159-174.Lave, J. & Wenger, E. (1991). Situated learning: Legitimate peripheral participation. Cambridge: CambridgeUniversity Press.Kerr, N. L., & Tindale, R. S. (2004). Group performance and decision making. Annu. Rev. Psychol., 55, 623655.Norman, D. A. (2002). The design of everyday things. Basic books.Papert, S. (1993). The children's machine: Rethinking school in the age of the computer. New York: BasicBooks.Pirolli, P., & Card, S. (2005). The sensemaking process and leverage points for analyst technology as identifiedthrough cognitive task analysis. In Proceedings of International Conference on Intelligence Analysis(Vol. 5, pp. 2-4).Roschelle, J., & Teasley, S. D. (1995). The construction of shared knowledge in collaborative problem solving.In Computer supported collaborative learning (pp. 69-97). Springer Berlin Heidelberg.Rogoff, B. (1994) Developing understanding of the idea of communities of learners. Mind, Culture, andActivity, 1(4), 209 – 229.Rogers, Y., Sharp, H., & Preece, J. (2011). Interaction design: beyond human-computer interaction. John Wiley& Sons.Schunk, D. H. (2012). Learning Theories an Educational Perspective (6th ed.). Boston, MA: PearsonEducation, Inc.Weinberger, A., & Fischer, F. (2006). A framework to analyze argumentative knowledge construction incomputer-supported collaborative learning. Computers & education, 46(1), 71-95.ICLS 2014 Proceedings760© ISLS