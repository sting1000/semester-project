Enhancing Self-Regulated Learning through Metacognitively-AwareIntelligent Tutoring SystemsBenjamin Goldberg, Robert Sottilare, Army Research Laboratory—Human Research & EngineeringDirectorate—Simulation and Training Technology Center, Orlando, FL, {Benjamin.S.Goldberg,Robert.Sottilare}@us.army.milIdo Roll, University of British Columbia, Vancouver, British Columbia, Canada, Ido@.ubc.caSusanne Lajoie, Eric Poitras, McGill University, Montreal., Quebec, Canada, {Susanne.Lajoie,Eric.Poitras}@mcgill.caGautam Biswas, James R. Segedy, John S. Kinnebrew, Vanderbilt University, Nashville, TN, {Gautam.Biswas,James.Segedy, John.Kinnebrew}@vanderbilt.eduEliane Stampfer Wiese, Yanjin Long, Vincent Aleven, Kenneth R. Koedinger, Carnegie Mellon University,Pittsburgh, PA, Grace.Long@gmail.com, {Stampfer, Aleven, Koedinger}@cs.cmu.eduBenjamin Goldberg, ChairPhil Winne, Simon Fraser University, DiscussantAbstract: This symposium identifies current trends and future directions in research onmetacognition and Self-Regulated Learning (SRL) in educational technologies, andspecifically, Intelligent Tutoring Systems (ITS). Each paper will elaborate on detection andassessment of metacognition/SRL, forms of support and scaffolding, and self- and coregulation processes and authoring of environments that support ITS. The symposium willconclude with discussions that describe the manner in which metacognitive development canbe promoted through strategies that support individual differences in multiple contexts. Thealternative perspectives presented in this session will help advance our understanding ofsupport for metacognition and SRL in ITS, as well as identify gaps that will influence futureresearch pursuits.Overall Focus of the SymposiumIntelligent Tutoring Systems (ITS) are designed to manage and regulate learning experiences within a specifieddomain. While shown to be effective in helping individuals gain new knowledge and learn problem solvingprocedures, a typical ITS confines its pedagogical approach to the domain material alone, with little emphasison promoting metacognitive learning strategies that are general across domains. Recent research strives toenhance such systems through the incorporation of tools and methods that promote Self-Regulated Learning(SRL) by incorporating strategies linked to metacognitive awareness and regulation. Metacognition is oftendescribed as being made up of two constituent parts: (1) Metacognitive knowledge, which is declarative anddeals with the interplay between knowledge of one's abilities to perform tasks, the nature of the task, and thestrategies one can employ to successfully perform the task; and (2) Metacognitive regulation, which includesactivities related to goal selection, planning, monitoring, control, and reflection (Flavell et al., 1985; Schraw etal., 2006; Veenman, 2012). Because metacognition involves the explicit management of one’s own cognitiveresources, there exist strong interrelationships between learners’ metacognitive abilities and their understandingof, familiarity with, and effectiveness in executing the cognitive tasks required for success (Bransford, et al.,2000; Winne, 1996). Thus, tutors in open-ended environments must be able to measure and interpret studentbehaviors at both the cognitive and metacognitive level in order to provide support for both types of mentalprocesses (Biswas, et al., 2010; Land, 2000; Kramarski, 2004; Roll, Aleven, McLaren, & Koedinger, 2007). Thepurpose of this symposium is to present current research and perspectives that address this problem space fromrelevant experts in the field.This session includes four papers that adopt the common theme of using technology-based instructionalsystems to help students become more independent learners. Presentations will cover research derived frommodels and constructs linked to SRL, modeling and monitoring techniques to gauge students’ cognitive andmetacognitive abilities, defined strategies and tactics for guiding and improving metacognitive processes, andimplications for developing authoring tools to facilitate monitoring, modeling, and scaffolding metacognitiveprocesses in an ITS. Collectively, the presentations will be oriented toward discussing pragmatic issuesassociated with supporting metacognition and SRL in ITSs, and how the application of metacognitive strategiescan enhance learning outcomes as they relate to improved learning performance and transfer. As metacognitiondeals with one’s awareness of the knowledge and regulation of cognition, it is important to understand thedistinctions between these two parts and how they compliment learning within SRL environments that are openended in nature. In turn, ITS developers need to understand how individuals apply metacognitive strategies toICLS 2014 Proceedings1352© ISLSfully embed modeling techniques and pedagogical strategies that fit within the theoretical constructs of howstudents regulate resources and emotions when learning. This includes looking at various modeling approachesthat take into account theoretical foundations associated with a domain, along with methods to monitor actionsin an environment to identify patterns of successful behavior that may be linked to metacognitive strategies. Inaddition, the use of instructional strategies to improve students’ metacognition must be explored, looking both attriggers (i.e., static vs. adaptive) and distinguishing characteristics of strategies as they relate to the varyingprocesses linked to learning (i.e., cognition, behavior, motivation, and affect). Furthermore the application ofITS technologies outside of academic settings (i.e., K-12) is becoming more prevalent, with a push for systemsto support simulations in real-world contexts. Student profiles and learner models must now accommodate thelife-long adult learner. Implications for tailoring systems to support individuals in varying phases of their lifeand career must be identified, as these characteristics will dictate how systems will adapt to aid in thedevelopment of independent learning skills. In addition to establishing a foundation for how to assess andinstruct metacognitive behaviors, we describe tools to author these mechanisms into an Intelligent Tutor.A Combined Theory- and Data-Driven Approach for Interpreting Learners’Metacognitive Behaviors in Open-Ended Learning EnvironmentsGautam Biswas, James R. Segedy, John S. Kinnebrew, ISIS/ Department of EECS, Vanderbilt UniversityAdapting to learners’ needs and providing useful individualized feedback to help them succeed has been ahallmark of most intelligent tutors (Anderson, et al., 1995; Gertner & Van Lehn, 2000). More recently, topromote deep learning, critical thinking, and problem-solving skills in STEM disciplines, researchers havebegun developing tutoring systems that present learners with complex problems and a set of tools for learningand problem-solving (Hannafin, 1994; Land, 2000). To be successful in such open-ended learning environments(OELEs), learners must be metacognitively aware, apply metacognitive strategies that promote effectivelearning, and manage, coordinate, and reflect on their use of a number of cognitive processes to succeed in theirlearning and problem solving tasks (Bransford et al., 2000; Zimmerman, 2001). A typical learning task maycombine a number of activities, such as searching for information, interpreting information in the context of thelearning and problem solving tasks, and applying it to the construction and testing of potential problemsolutions. This can present significant challenges to novice learners; they may have neither the proficiency forusing the system’s tools nor the experience and understanding necessary for explicitly regulating their learningand problem solving (Chi et al., 1988; VanLehn, 1996). Furthermore, their abilities to reflect on past activitiesand relate them to task outcomes may not be well developed (Schunk & Zimmerman, 1997). Not surprisingly,research has shown that novices often struggle to succeed in such complex environments.Measuring Metacognition in Open Ended Learning Environments (OELEs)Adaptive tutoring systems regularly capture and analyze student activities in order to make decisions about howand when to scaffold learners. However, the complexity of OELEs poses considerable challenges to accuratelyinterpreting and understanding student behaviors. Traditionally, learning behavior is assessed with top-downmetrics based on theory and hypotheses about student learning activities in the context of their learning tasks(Hmelo-Silver, 2004; Segedy, Loretz, & Biswas, 2013). In recent years, however, bottom-up data miningtechniques that analyze students' logged activity data have been utilized to discover important aspects of howstudents learn (Kinnebrew, Loretz, & Biswas, 2013). We present a framework for analyzing learning activitydata in OELEs that combines top-down metrics and bottom-up pattern discovery. This integrated framework canbe employed to build detailed models of students' learning behaviors and strategies, and subsequently to identifyopportunities for providing adaptive scaffolds to students as they use the system.For top-down, theory-driven analysis of learning behaviors, our framework focuses on (i) the learner'sacquisition and application of knowledge and information encountered while they perform their task-relatedactivities in the OELE and (ii) the impact of these activities with respect to the learning task (e.g., whether anaction directly resulted in progress toward completion of the task). For bottom-up, data-driven discovery oflearning behaviors, our framework employs data mining techniques for identifying frequent patterns of action inlogs of their activity in the environment. Our approach enhances the analysis and assessment of student learningbehavior by combining these complementary top-down and bottom-up techniques. This allows us to identifyspecific learning behaviors for a group of students, behavior differences between groups that are relevant tounderstanding their approach to learning in the environment, and the connections between specific patterns ofactivity and the relevant skills or strategies for learning and problem solving. More specifically, the theorydriven metrics are used for evaluating and differentiating instances of the discovered patterns in order to betterunderstand whether or not the discovered patterns were used as part of coherent strategies and, if so, which ones.The theoretical measures also provide valuable information about individual differences among students thatmay employ the same pattern of actions but in different manners or for different purposes. Therefore, thisICLS 2014 Proceedings1353© ISLSanalysis framework provides concrete results in the form of action patterns with associated measures that arelinked to relevant learning strategies and behaviors.Case Study: Application to the Betty’s Brain OELEBetty's Brain is an open-ended learning environment (Biswas, et al., 2005) that provides students with a learningcontext and a set of tools for pursuing authentic and complex model building tasks. Students working in theBetty's Brain system are expected to apply a number of cognitive skills that relate to the four primary activitiesthat the students can perform in the environment: (1) read and understand the science content, (2) translate therelevant content into specific causal relations to build the causal map to teach Betty, a computer agent, (3) checkthe correctness of the causal map by asking Betty questions and getting her to take quizzes, and (4) use the quizand question results to identify the correct, incorrect and incomplete parts of the map. Together (1) and (2) arereferred to as Knowledge Construction skills, and (3) and (4) are referred to as Solution Evaluation skills.Building up from the cognitive skills, we hypothesize four categories of metacognitive strategies that studentsneed to develop and deploy in the Betty's Brain environment: (1) Goal Setting & Planning, (2) KnowledgeConstruction, (3) Solution Evaluation, and (4) Help Seeking (Kinnebrew, Segedy, & Biswas, 2014).An important aspect of our hierarchical task model is its non-linearity; students are expected tocontinually navigate among the cognitive and metacognitive processes as they go about their task of teachingBetty a correct and complete map of the domain. Thus, this model also serves as a framework for interpretingstudents' learning activities and activity sequences that we characterize as learning behaviors. This matchesother approaches (e.g. (Hadwin et al., 2007)) that describe students' evolving metacognition in terms of asequence of events using trace methodologies. The structure of the model also implies that it is unlikely studentscan be effective in metacognitive strategies unless they are proficient in the related cognitive strategies.Our analytic framework for analyzing OELE learning activity data comprises extracting sequences ofcanonical actions from log files of student activities, sequential pattern mining to identify common actionpatterns, mapping identified patterns back into action sequences to analyze them with the theory-drivenmeasures in the context of the students' other activities, and linking the identified behaviors (described by both asequential pattern of actions and the relevant measure values that distinguish it from other instances of the sameaction pattern) to skills and strategies in the cognitive/metacognitive task model. To assess a student'smetacognitive regulation, our approach evaluates student behaviors using a measure of coherence called actionsupport. Support for a particular student action represents the extent to which it is informed by informationgained from previous actions. For example, information seeking actions (e.g., reading about a causalrelationship) can provide support for future solution construction actions (e.g., adding the corresponding causallink to the map). Students with higher proportions of supported actions are considered to have a higher masteryof strategies for coordinating their use of tools within the environment.We present results from analyzing data from recent studies with Betty’s Brain that we have run inmiddle school science classrooms. The results of this analysis provide a foundation for developing performanceand behavior-based learner models in conjunction with adaptive scaffolding mechanisms to promote effective,personalized learning experiences.Assessment and Instruction of Self- and Co-Regulation of Medical DiagnosticProcesses in Technology-Rich Learning EnvironmentsSusanne Lajoie and Eric Poitras, McGill UniversityBroadly speaking, learning is often described in terms of the relationship between what goes on in the mind andhow the environment influences what is learned. By environment we refer to: the learning materials presented inor outside of class; the real or augmented context; the presence and influence of others (human or computersupported) be they peers, tutors or teachers, and; the structure of the environment (ill-structured or structured).We are seeing an evolution in the constructs of SRL that better articulate the components of the environmentthat need to be considered in defining and supporting SRL. In this paper, we describe BioWorld (Lajoie et al.,2013), a computer based learning environment (CBLE) in terms of how it supports learners’ SRL of diagnosticreasoning processes while solving virtual patient cases.Fostering Regulatory Processes in Diagnostic Reasoning with BioWorldThe social cognitive perspective of SRL states that self-regulation involves cognitive, affective, motivational.,and behavioral activities that are planned and adapted in order to attain a goal., such as solving a problem(Zimmerman, 2000). Problem-solving processes occur in three phases: forethought, performance, and selfreflection. Self-reflection processes occur after performance efforts, and in turn, influence forethought inrelation to subsequent steps taken to solve the problem. SRL processes are recursive in that feedback from priorperformance informs subsequent adjustments efforts (Zimmerman & Campillo, 2003). We apply SRL theoriesto phases of problem-solving processes relevant to domain-specific knowledge involved in diagnostic reasoning.ICLS 2014 Proceedings1354© ISLSBioWorld is designed to foster SRL by supporting cognitive and metacognitive activities that arecritical in diagnosing virtual patient cases. Forethought processes involve learners’ efforts to orient themselvesto a patient problem, and plan the necessary next steps. Self-regulated learners activate their prior knowledge ofdisorders in response to relevant information pertaining to the case in an effort to list hypothetical diagnoses. Atypical learner might then formulate a plan to order a lab test that will confirm the most likely diagnosis, lookfor particular information from the library, or seek external help by asking for a consult. During the performancephase, learners execute the steps, and then monitor the outcomes. After receiving the outcomes of a lab test forinstance, learners determine whether the results are pertinent or non-pertinent to the diagnosis. In doing so,learners might determine that their overall understanding of the case improved, or if their test results areunexpected, or contradictory, confusion may occur which may lead to a re-evaluation of the plausibility of thetentative diagnoses. Self-reflection processes consist of learners’ evaluation of and elaboration on their overallprogress in problem solving. Self-regulated learners check the relevant evidence and symptoms, while at thesame time verifying each hypothetical diagnosis. A typical learner connects evidence and relevant informationby drawing conclusions and updating their confidence in each diagnosis.Assessing Novices along the Trajectory towards ExpertiseA learner model is a computational representation of learner characteristics that includes relevant statespertaining to knowledge and skill acquisition as inferred through their interaction with the learning environment(Shute & Zapata-Rivera, 2012). The representation of relevant learner characteristics is continually updatedthroughout the learning session as they practice their skills. Learner interactions are recorded and analyzed bythe CBLE with the aim of guiding instruction. Table 1 shows an overview of learner modelling techniques usedfor the purposes of assessing SRL in BioWorld. The current version of BioWorld implements a novice-expertoverlay model to deliver feedback. This method relies on the comparison of novice actions to the expert solutiontrace. These actions are recorded through the evidence palette, which is designed to assist novices in orientatingthemselves to the problem space (i.e., patient symptoms highlighted in case description, relevant libraryinformation accessed, lab tests ordered etc.). The feedback palette shows similarities and differences betweenthe novice and expert solution paths on these key processes.Table 1: An overview of learner modelling techniques used to assess self-regulation in BioWorld.SRL phaseTool descriptionForethoughtEvidence palettePerformanceLibraryConsult toolSelfreflectionCase summaryFeedbackpaletteLearner modelingData channelsmethodImplemented in BioWorld version 2.1Overlay methodAction attributesUnder development for BioWorld version 3.0Machine learningAction attributesmethodMachine learningLinguistic attributesmethodMachine learningLinguistic attributesmethodQuantitative modellingAffective/MotivationalattributesMeasuresLog filetraceLog filetraceThink aloudLog filetraceSelf-reportWe are using a data-driven approach that uses educational data mining techniques to redesigncomponents of BioWorld’s learner model. First, we have created a decision tree classifier that allows BioWorldto trace Novice library searches and infer whether the library topics explored leads novices to engage ordisengage from the expert solution path. Data from the library classification model stands to improve instructionthrough the recommendation of specific topics in the library. Second, we examined the novice think-aloudprotocols and clustered them based on sequences of cognitive and metacognitive activities, outlined by the SRLmodel, that occur prior to asking for a consult in BioWorld. The cluster model allows researchers to tailor thecontent of hints delivered by the consult tool in response to different profiles of help-seekers.Although these models targeted different aspects of task performance, the following tools are designedto support novices in reflecting about their own approach to solving the problem. We evaluated the writtenpatient case summaries using a neural network classifier to assess disease type and correctness of diagnosis onthe basis of linguistic features. We plan to broaden the scope of the text classification model to provide noviceswith feedback on the quality of case summary sections and instruction on text writing strategies. Finally, weexpanded the scope of the SRL model by modelling the impacts of achievement emotions and goals towardsattention given to feedback in BioWorld. The logic model allows the system to assess learner characteristicsICLS 2014 Proceedings1355© ISLSthrough self-report, and direct novices’ attention to aspects of the feedback that are most often overlooked bylearners with a similar profile of characteristics.Developing a Community of Co-Regulated Problem-SolversBioWorld serves as a platform to develop a community of practice, using cognitive apprenticeship principles todeliver instruction that brings in expertise from outside the classroom to the learning environment. We involveexpert medical instructors in the case creation and expert knowledge building by having them use CaseBuilder,an authoring tool designed to allow domain experts and researchers to modify cases and explore instructionalactivities. Expert problem-solving traces are collected using verbal protocols, and researchers create visualrepresentations that converge multiple solution paths for the purposes of validating the case solution. Casescenarios are built with medical staff and the case solution is uploaded to the server database, which can beuploaded by novices while solving problems with BioWorld. In doing so, instructors can design cases to besolved by groups of novices in the classroom, teaching on collaborative strategies that are critical in regulatingthe progress of groups and teams of problem-solvers. Recent advances in conceptualizing the context-specificnature of SRL, focusing on group collaboration, stands to better guide instruction (Jӓrvelӓ & Hadwin, 2013;Volet, Vauras, Khosa, & Iiskala, 2013). Future research will evaluate the effects of adding new components tothe BioWorld user model in terms of co-regulating processes involved in solving problems.Supporting Self- and Co-Regulation in Intelligent Tutoring Systems to HelpStudents Acquire Better Learning SkillsIdo Roll, University of British ColumbiaEliane Stampfer Wiese, Yanjin Long, Vincent Aleven, Kenneth R. Koedinger, Carnegie Mellon UniversityProviding scaffolding to help students regulate their learning has become an increasing focus within educationaltechnologies, and specifically, within ITS. Overall, there is compelling evidence that scaffolding students’ SRLcan improve their learning gains (Aleven & Koedinger, 2002; Holmes, Park, Day, Bonn, & Roll, 2013; Woodand Wood, 1999). In this presentation we aim to extend the theory of SRL scaffolding in ITS by identifyingthree important developments in this area. First, we focus on the objectives of scaffolding. While domainlearning remains an important objective, a more ambitious goal is to help students acquire better SRL skills andattitudes. Thus, the scope of the desired effect should extend beyond the supported environment and associatedpost-assessments to new learning situations. Second, we focus on the role of the scaffolding. Traditionally, thediscussion around self regulation in ITS is framed either in terms of students’ self-regulation (Winne, 1996), orexternal-regulation by the environment (Azevedo, Moos, Greene, Winters, & Cromley, 2008). However,learning in ITS can also be viewed as the emerging outcome of negotiations and interactions between learnersand the system. We discuss this perspective in terms of co-regulation (Hadwin, Järvelä, & Miller, 2011), andinvestigate its implications on the design of regulatory scaffolding. Last, we discuss the form of the scaffolding,where we identify grounded feedback uses (Nathan, 1998; Stampfer & Koedinger, 2013) to implicitly encouragestudents to monitor their progress.We ground the discussion on the objectives, roles, and form of SRL scaffolding by focusing on threeimportant families of SRL strategies: Help seeking and help giving (Roll, Aleven, McLaren, & Koedinger,2011; Walker, Rummel, & Koedinger, 2011); self assessment (Long & Aleven, 2013; Roll, Aleven, &Koedinger, 2011); and planning and monitoring (Holmes et al., 2013; Kinnebrew et al., 2013; Stampfer &Koedinger, 2012). In conclusion, we argue that these developments enable new modes of SRL support thatcould lead to sustained improvement in students’ learning skills and attitudes.From Domain Learning to Metacognitive LearningAs mentioned above, several successful examples show that students who receive relevant support for theirlearning processes demonstrated better learning outcomes. However, can we aim higher than that? Can supportfor SRL achieve the ambitious goals of helping students learn to regulate their learning, and thus become morecompetent learners?We previously proposed a hierarchy of goals for SRL scaffolding (Koedigner, Aleven, Baker, & Roll,2009). Support for SRL should first help students apply better learning behaviours within the supportedenvironment. Second, it should lead to better domain learning outcomes within the supported environment.Third, students should demonstrate better SRL behaviour in a future learning event without the SRL support.Last, the support should lead to improvement in future learning outcomes without the SRL support.In recent years, several studies have looked at transfer of SRL behaviours, allowing us to evaluatecharacteristics of SRL support that seek to improve future learning. Roll et al. (2011) gave students adaptivefeedback on their help-seeking actions in a geometry tutor. They found that students who received feedbacktransferred better help-seeking skills to new topics within the same environment, when no support was offered,but not to a new (paper) environment. Long & Aleven (2013) found a similar pattern. After each problem in anICLS 2014 Proceedings1356© ISLSITS on linear equations, students were prompted to assess their understanding. While these studentsdemonstrated more productive learning behaviours on subsequent problems within the tutored environment,they did not transfer their improved self-assessment behaviors to a new environment. Limited transfer ofimproved SRL behaviours was also found in environments that support planning and monitoring. In theseenvironments, SRL support for some components of the task led to improved SRL on other, unsupported,elements, but so far failed to show significant improvement on SRL strategies in transfer topics, even within thesame environments (Biswas et al., 2009; Holmes, 2013). Thus, while well-designed SRL support can lead totransferable results, the patterns of transfer across tasks, topics, and environments should be further examined.From Self- to Co-RegulationTo date, most efforts to scaffold SRL in ITS have focused on explicitly directing students to apply prescribedstrategies, mainly through the use of static support. In such cases, regulation of learning could be consideredExternally Regulated Learning (ERL; Azevedo et al., 2008), as the system chooses the sub goals and strategiesfor the student (e.g., using self-explanation prompts).While the constructs of SRL and ERL are useful for discussing learning either from the studentperspective (SRL) or the system perspective (ERL), they are somewhat less relevant when the regulationemerges from negotiations between the student and the system. A similar debate in regulation of groups sparkedthe idea of co-regulation (Hadwin et al., 2011). Here, we would like to extend the use of co-regulation todescribe ITSs where the learning process emerges from negotiations and interactions between the learner andthe environment. A good example for that process is the Open Learner Model (OLM; Long & Aleven, 2013;Zapata-Rivera & Greer, 2002). In OLMs, learners can view the ITS’s estimation of their skills. Furthermore,several examples of OLM engage students in a discussion over desired goals and future activities. Anotherexample is the work on peer tutoring (Walker et al., 2011). Rather than defining the interaction process for thestudent, the ITS offers strategies but does not impose them. The actual learning process is the result ofcontributions by the ITS and the two students who engage in the learning process. We argue that consideringSRL support as a process of co-regulation can inform the design of support mechanisms that give more agencyto learners and create stronger partnerships between ITS and the students.From Explicit to Implicit SupportWhile many theories of self-regulation emphasize monitoring and reflection as key components of learning,students often fail to engage in these processes. One reason may be the failure of many ITSs to providemeaningful opportunities for student reflection. For example, when asked to calculate standard deviation ofcertain data sets, or to add two fractions, how can students know whether their answers are correct? GroundedFeedback supports triangulation, as the student can recognize the correct or incorrect application of a to-belearned skill by evaluating the system response in alternative, familiar representation (which could besituational., visual., or based on already mastered procedures; cf. Natahan, 1998). We demonstrate this processusing two environments: a fraction-addition ITS that uses graphical representations to help students evaluatemagnitude, and a data-analysis ITS which uses contrasting cases to give students a baseline with which they canmake intuitive predictions.While Grounded Feedback allows students to monitor their performance, recent classroom experimentssuggest that this approach is met with only limited success (Stampfer & Koedinger, 2012). A more powerfulsupport may combine Grounded Feedback with explicit feedback on students’ use of that information to assesstheir performance. Such feedback follows an intelligent novice model, or “immediate + 1” feedback, asfeedback is suppressed when students commit domain-level errors (giving them a chance to detect their ownerrors), and is given when students fail to use the grounded clues to successfully make sense of their domainlevel mistakes (Mathan & Koedinger, 2005).To summarize, we identify three developments in the landscape of SRL support in ITS. Put together,we believe that SRL scaffolding should aim for co-regulation by involving students in the pedagogicaldecisions, and giving students opportunities to monitor their progress. At the same time, the ITS should, like askilled human tutor, intervene when students are off track. These directions could lead to SRL scaffolding that ismore responsive to students’ interactions with the environment, gives students more agency over their learningprocess, and subsequently, may lead to sustained gains to students’ SRL skills and attitudes.From the Classroom to Industry: The Push for Intelligently Guided SelfRegulated Training to Support Complex Skill DevelopmentBenjamin Goldberg, Robert Sottilare, U.S. Army Research LaboratoryThe culture of education and training is quickly shifting. Technology is being utilized in the classroom morethan ever, with new tools and methods completely reshaping how people interact with learning content andmaterials (i.e., interactive e-textbooks distributed to students on Apple iPads; Sloan, 2012). In turn, whereICLS 2014 Proceedings1357© ISLSpeople learn is also rapidly changing. With enhanced mobile networks that support on-the-go internet access andthe availability of advanced light-weight portable computers, someone can conceivably learn and train fromanywhere in the world. This is leading to a culture based around the self-regulation of learning, especially withinindustries like medicine and the military that value continual on-the-job training for skill development. In thiscontext, ITSs are being defined as major focal points in regulating interaction and instilling metacognitive skillsto support future training opportunities (TRADOC, 2011). This is based on empirical evidence in the learningsciences community showing the benefit of training metacognitive strategies and their subsequent impact onfuture learning outcomes (Koedinger, Aleven, Roll, & Baker, 2009; Poitras, Lajoie, & Hong, 2012; Roll,Aleven, McLaren, & Koedinger, 2011). The challenge is overcoming barriers linked to authoring such systems(Sottilare, Goldberg, Brawner, & Holden, 2012). At the current moment, authoring systems that support SRL istime consuming and requires expertise. Can tools and methods be employed to streamline the authoring ofenvironments that take into account metacognitive functions?From this perspective, there are two fundamental problems that must be addressed. First, military andindustry training domains are extremely volatile in nature, with continual changes in task procedures as theresult of advancements in technologies and techniques. With a change in task execution, an effective ITS mustbe able to accommodate shifts in procedural knowledge so as to continue providing efficient performanceassessment and feedback. This needs to be accomplished without completely overhauling a system to accountfor new domain information. Next, with the role of the instructor being redefined in a SRL culture, there is alarge burden placed on the student to regulate their training experience. This requires planning, executing a setof actions, monitoring and assessing performance, recognizing error, troubleshooting potential solutions, andidentifying cause and effect as it relates to the context of the experienced problem (Zimmerman & Campillo,2003). Especially with tasks that evolve over time, focusing instruction to improve cognitive processes andpromote higher-order thinking, rather than improve task-specific procedures, is needed.As such, research is required to identify streamlined processes that produce ready to use ITSs that aremetacognitively aware outside of the laboratory setting. To further deconstruct these challenges, the authors willprovide a comprehensive overview of the current gaps in ITS authoring that must addressed before trainingcommunities buy-in to adaptive training technologies. These include: (1) putting intelligent authoring tools inthe hands of the instructor to create ITS-embedded training, (2) development of a systematic method ofprocesses and standards to author such functions, and (3) providing sound pedagogical methods based onempirical evidence to enhance an individual’s ability to regulate their own learning experience. These identifiedchallenges will serve as the focal point of the discussion, where we examine current work surrounding authoringissues linked to SRL in post-academic training spaces and the role metacognition plays in pedagogical planning.The Generalized Intelligent Framework for Tutoring (GIFT): Putting Authoring in theHands of the InstructorsAuthoring ITSs to aid in metacognitive development across training-based industries is a challenge that must beaddressed. Training environments for military and industry relevant domains are often drastically different fromthe academic settings ITSs are typically applied within. Much of the training in job-related instances focuses onspecific tasks and procedures that require proficiency before they can be fully conducted under properoperational contexts. In addition, how tasks are conducted depend largely on context, which is often ill-definedin nature. Thus, performing a task under one context may differ greatly from performing the same task under adifferent set of conditions. Therefore, a focus of instruction needs to be based on developing strategies toimprove how individuals monitor performance, troubleshoot complications, and regulate attentional resources,rather than solely on executing task procedures. This will improve an individual’s ability to self-regulate theirfuture learning, as well improve how they conduct and adapt procedures based on reflections of actions taken.The current issue is that building ITSs is expensive, labor intensive, and requires expertise across anumber of disciplines (Murray, 1999; Sottilare, Goldberg, & Durlach, 2011). They are also commonly built asstand-alone solutions to a specific program, offering minimal reuse for future applications. Tools need to bedeveloped that address these gaps and enable instructors to build and modify ITS model components that can beplugged into any training application available. This requires standardized methods and processes to build tutorsfrom, along with an intelligently guided authoring process to assist instructors in building core components.Existing tools are available for standardized authoring of ITSs linked to cognitive example-tracing andconstraint-based modeling techniques. These include Carnegie Mellon’s Cognitive Tutor Authoring Tools(CTAT; Aleven, McLaren, Sewall, & Koedinger, 2006) and University of Canterbury’s ASPIRE AuthoringTool (Mitrovic et al., 2008). They provide a generalized authoring environment, but lack elements linked tointeractive simulation-based training systems such as gaming platforms commonly used in industry training.The U.S. Army Research Laboratory (ARL) is currently addressing this problem. ARL is in the processof developing the Generalized Intelligent Framework for Tutoring (GIFT), an open source domain-independentarchitecture that provides standardized approaches for authoring, delivering, and evaluating ITS componentsand functions (Sottilare et al., 2012). Essentially, GIFT is a set of tools and standards used to author ITSICLS 2014 Proceedings1358© ISLSsolutions to promote and accelerate learning, regardless of the task being trained (Sottilare & Goldberg, 2013).What GIFT provides is a modular approach to ITS development, enabling a swap and play capability, whichpromotes reuse of standardized modeling techniques designed to accommodate any instructional domain. WhereGIFT needs to shine is in compensating for the expertise and knowledge a particular author or instructor lacks.This requires tools that aid an author in modeling a domain to the parameters set forth by GIFT standards,developing assessments and triggers associated with the modeled domain, and identifying instructionalstrategies to utilize when triggers are activated.The caveat is that all of these processes need to be defined in a generalized fashion so that they extendacross domain implementations. Currently, GIFT monitors performance through an ontological representation ofa domain by expressing objectives and concepts in a relational hierarchy. For each concept identified in thehierarchy, an assessment is authored that designates metrics linked to competency. These metrics are used toproduce a learner state for each defined concept, which is used by the pedagogical model to inform guidancefunctions. From there, GIFT makes informed pedagogical recommendations on a domain-independent level(e.g., provide hint, provide prompt), leaving it to the instructor to author that strategy as an actionable tactic(Goldberg, Brawner, Sottilare, et al., 2012). In this instance, a developer authors multiple levels of tacticsenabling the system to vary the level of detail provided in feedback messages based on individual differencesassociated with a learner. In the event that a system requires updates to task procedures, tactic definitions foreach affected concept will need to be updated. This can be a taxing process on the course administrator if thetask is modified on a regular basis. The same process can be said for supporting metacognitive tutoring. SRLbehaviors require representation in GIFT’s domain model that enables tracking of user interaction. This allowsbuilding rules to determine proper and improper execution. The goal would be to support the methods describedabove from the various authors. These determinations are used by the pedagogical model to enact a designatedintervention; however, where metacognitive prompts differ is in their representation. They can be represented asstandardized prompts that can be maintained across domains, without required edits.Metacognition and Domain-IndependencyAs described above, GIFT works with system authors by providing instructional strategy recommendations,which are then translated into tactics as they relate to the training context. These tactics are used during ITSruntime and are selected based on a learner’s individual differences. At the current moment, feedback in GIFT isdomain dependent and requires explicit content linked to each concept modeled. When it comes tometacognitive feedback, what are the implications to a domain-independent approach? First, modelingtechniques, such as the one presented in Biswas et al.’s paper, need to be developed to monitor an individual’spractice of metacognitive strategies that can be expressed in a generalized format. Another example would beincorporating a help-seeking model, as highlighted in Koedinger et al. (2009). Researching and establishingmodels based around commonly available GIFT interactions (e.g., request hint button) can be used to buildtheoretical representations of how effective students use the interface to solve problems and troubleshoot errors.Depending on the domain, an assessment model will need to be generated that associates cognitive andmetacognitive processes with task execution. This can be used to establish an assessment model for detectinglearners exhibiting poor metacognitive behaviors, and is used to trigger feedback interventions to improvesubsequent behavior. With support for applying varying modeling techniques, generic tactics can be identifiedthat are based around effective metacognitive behavior, and should be based around learning theory identifiedby Roll et al. and Lajoie & Poitras. While tactics can be represented in a domain independent format, monitoringhow a learner adapts their behaviors as a result of the intervention is an open question, and is dependent on themodeling approaches being applied.In summary, we identify the desire from military and industry-based training communities toincorporate technologies to enable SRL. With technology being utilized more than ever for this purpose, usingITSs to monitor and improve metacognitive behaviors can greatly enhance the learning. To streamline thisdevelopment, authoring needs to be taken out of the lab and put in the hands of those using the tools.ReferencesAleven, V., & Koedinger, K. R. (2002). An effective metacognitive strategy: Learning by doing and explainingwith a computer-based Cognitive Tutor. Cognitive Science, 26, 147–179.Aleven, V., McLaren, B.M., Sewall, J., & Koedinger, K. R. (2006). The Cognitive Tutor Authoring Tools(CTAT): Preliminary evaluation of efficiency gains. M. Ikeda, K. D. Ashley, & T. W. Chan (Eds.)Proceedings of 8th International Conference on ITSs (pp. 61-70). Berlin: Springer Verlag.Anderson, J. R., Corbett, A. T., Koedinger, K. R., & Pelletier, R. (1995). Cognitive tutors: Lessons learned. TheJournal of the Learning Sciences, 4(2), 167-207.Azevedo, R., Moos, D., Greene, J., Winters, F., & Cromley, J. (2008). Why is externally-facilitated regulatedlearning more effective than self-regulated learning with hypermedia? Educational TechnologyResearch and Development, 56(1), 45-72.ICLS 2014 Proceedings1359© ISLSBiswas, G., Leelawong, K., Schwartz, D., Vye, N., & TAG-V (2005) Learning by teaching: A new agentparadigm for educational software. Applied Artificial Intelligence 19(3), 363-392.Biswas, G., Roscoe, R., Jeong, H., & Sulcer, B. (2009). Promoting self-regulated learning skills in agent-basedlearning environments. Paper presented at the 17th international conference on computers in education.Biswas, G., Jeong, H., Kinnebrew, J. S., Sulcer, B., & ROSCOE, R. (2010). Measuring self-regulated learningskills through social interactions in a Teachable Agent environment. Research & Practice inTechnology Enhanced Learning, 5(2), 123-152.Bransford, J., Brown, A., & Cocking, R. (eds) (2000) How people learn. National Academy Press Washington,DC, Washington, D.C.Chi, M., Glaser, R., & Farr, M. (1988). The nature of expertise. Lawrence Erlbaum Associates, Inc.Flavell, J., Miller, P., & Miller, S. (1985) Cognitive development. Prentice-Hall Englewood Cliffs, NJ.Gertner, A. S., & VanLehn, K. (2000). Andes: A coached problem solving environment for physics. InIntelligent Tutoring Systems (pp. 133-142). Springer Berlin Heidelberg, January.Goldberg, B., Brawner, K. W., Sottilare, R., Tarr, R., Billings, D. R., & Malone, N. (2012). Use of Evidencebased Strategies to Enhance the Extensibility of Adaptive Tutoring Technologies. Paper presented atInterservice/Industry Training, Simulation, and Education Conference (I/ITSEC) 2012, Orlando, FL.Hadwin, A. F., Nesbit, J. C., Jamieson-Noel, D., Code, J., & Winne, P. H. (2007). Examining trace data toexplore self-regulated learning. Metacognition and Learning, 2(2-3), 107-124.Hadwin, A. F., Järvelä, S., & Miller, M. (2011). Self-regulated, co-regulated, and socially shared regulation oflearning. Handbook of self-regulation of learning and performance, 65-84.Hannafin, M. J. (1994). Learning in Open-Ended Environments: Assumptions, Methods, and Implications.Educational Technology, 34(8), 48-55.Hmelo-Silver, C. E. (2004). Problem-based learning: What and how do students learn? Educational PsychologyReview, 16(3), 235-266.Holmes, N.G., Park, A.K., Day, J., Bonn, D.A., & Roll, I. (2013) Making the failure more productive:scaffolding the invention process to improve inquiry behaviours and outcomes in productive failureactivities. Instructional Science, doi:10.1007/s11251-013-9300-7Jӓrvelӓ, S., & Hadwin, A. F. (2013). New frontiers: Regulating learning in CSCL. Educational Psychologist,48(1), 25-39.Kinnebrew, J.S., Segedy, J.R., & Biswas, G. (2014). Analyzing the Temporal Evolution of Students' Behaviorsin Open-Ended Learning Environments. Metacognition and Learning. DOI: 10.1007/s11409-014-9112-4Kinnebrew, J.S., Loretz, K.M., Biswas, G. (2013) A contextualized, differential sequence mining method toderive students' learning behavior patterns. Journal of Educational Data Mining 5(1),190-219.Koedinger, K., Aleven, V., Roll, I., & Baker, R. (2009). In vivo experiments on whether supportingmetacognition in intelligent tutoring systems yields robust learning. Handbook of metacognition ineducation, 897-964.Kramarski, B. (2004). Making sense of graphs: does metacognitive instruction make a difference on students'mathematical conceptions and alternative conceptions?. Learning and Instruction, 14(6), 593-619.Lajoie, S. P., Naismith, L., Poitras, E., Hong, Y. J., Cruz-Panesso, I., Ranellucci, J., Mamane, S., & Wiseman,J. (2013). Technology rich tools to support self-regulated learning and performance in medicine. In R.Azevedo & V. Aleven (Eds.). International Handbook of Metacognition and Learning Technologies, pp.229-242. New York, NY: Springer.Land, S. M. (2000). Cognitive requirements for learning with open-ended learning environments. EducationalTechnology Research and Development, 48(3), 61-78.Long, Y. & Aleven, V. (2013). Supporting Students’ Self-Regulated Learning with an Open Learner Model in aLinear Equation Tutor. In H. C. Lane, K. Yacef, J. Mostow, & P. Pavlik (Eds.), Proceedings of the 16thInternational Conference on Artificial Intelligence in Education (pp. 219-228). Memphis, TN: Springer.Mathan, S. A., & Koedinger, K. R. (2005). Fostering the intelligent novice: Learning from errors withmetacognitive tutoring. Educational Psychologist, 40(4), 257-265.Mitrovic, A., Suraweera, P., Martin, B., Zakharov, K., Milik, N., & Holland, J. (2006). Authoring ConstraintBased Tutors in ASPIRE. In M. Ikeda, K. D. Ashley & T. W. Chan (Eds.) Proceedings of the 8thInternational Conference on Intelligent Tutoring Systems (pp. 41-50). Berlin: Springer Verlag.Murray, T. (1999). Authoring intelligent tutoring systems: An analysis of the state of the art. InternationalJournal of Artificial Intelligence in Education (IJAIED), 10, 98-129.Nathan, M. J. (1998). Knowledge and situational feedback in a learning environment for algebra story problemsolving. Interactive Learning Environments, 5(1), 135-159.Poitras, E., Lajoie, S., & Hong, Y.-J. (2012). The design of technology-rich learning environments asmetacognitive tools in history education. Instructional science, 40(6), 1033-1061.Roll, I., Aleven, V., McLaren, B. M., & Koedinger, K. R. (2007). Designing for metacognition - applyingcognitive tutor principles to the tutoring of help seeking. Metacognition and Learning, 2(2), 125-140.ICLS 2014 Proceedings1360© ISLSRoll, I., Aleven, V., McLaren, B. M., & Koedinger, K. R. (2011). Improving students’ help-seeking skills usingmetacognitive feedback in an intelligent tutoring system. Learning and Instruction, 21, 267-280.Roll, I., Aleven, V., & Koedinger, K. R. (2011). Metacognitive practice makes perfect: Improving students’ selfassessment skills with an intelligent tutoring system. In G. Biswas (Ed.), Proceedings of theInternational conference on artificial intelligence in education (pp. 288-295). Berlin: Springer Verlag.Schraw, G., Crippen, K., & Hartley, K. (2006) Promoting self-regulation in science education: Metacognition aspart of a broader perspective on learning. Research in Science Education, 36(1), 111-139.Schunk, D. & Zimmerman, B. (1997) Social origins of self-regulatory competence. Educational Psychologist32(4), 195-208.Segedy, J., Loretz, K., & Biswas, G. (2013). Model-driven assessment of learners in an open-ended learningenvironment. In Proceedings of the Third International Conference on Learning Analytics andKnowledge, 200-204, New York, NY, ACM.Shute, V. J., & Zapata-Rivera, D. (2012). Adaptive educational systems. In P. Durlach (Ed.), Adaptivetechnologies for training and education, pp. 7-27. New York, NY: Cambridge University Press.Sloan, R. H. (2012). Using an e-Textbook and iPad: Results of a Pilot Program. Journal of EducationalTechnology Systems, 41(1), 87-104.Sottilare, R., & Goldberg, B. (2013). Designing Adaptive Computer-Based Tutoring Systems to AccelerateLearning and Facilitate Retention. Cognitive Technology.Sottilare, R., Goldberg, B., Brawner, K. W., & Holden, H. (2012). Modular Framework to Support theAuthoring and Assessment of Adaptive Computer-Based Tutoring Systems. Paper presented at theInterservice/Industry Training, Simulation, and Education Conference (I/ITSEC), Orlando, FL.Sottilare, R., Goldberg, S., & Durlach, P. J. (2011). Research Gaps for Adaptive and Predictive ComputerBased Tutoring Systems. Paper presented at the International Defense and Homeland SecuritySimulation Workshop (DHSS), Rome, Italy.Stampfer, E., & Koedinger, K.R. (2012). Tradeoffs between immediate and future learning. Paper presented atthe European Association for Research on Learning and Instruction Conference. Bari, Italy.TRADOC. (2011). The U.S. Army Learning Concept for 2015. TRADOC.VanLehn, K. (1996) Cognitive skill acquisition. Annual review of psychology 47(1), 513-539.Veenman, M. (2012) Metacognition in science education: Definitions, constituents, and their intricate relationwith cognition. Metacognition in Science Education, 21-36.Volet, S., Vauras, M., Khosa, D., & Iiskala, T. (2013). Metacognitive regulation in collaborative learning:Conceptual developments and methodological contextuals. S. Volet & M. Vauras (Eds.), Interpersonalregulation of learning and motivation: Methodological advances, pp. 67-101. NY, NY: Routledge.Walker, E., Rummel, N., & Koedinger, K. R. (2011). Adaptive support for CSCL: Is it feedback relevance orincreased accountability that matters? In N. Law (Ed.), Proceedings of the 10th InternationalConference on Computer-Supported Collaborative Learning (pp. 334-342).Winne P. (1996) A metacognitive view of individual differences in self-regulated learning. Learning andindividual differences, 8(4), 327-353.Wood, H. A., & Wood, D. J. (1999). Help seeking, learning, and contingent tutoring. Computers and Education,33(2), 153-169.Zapata-Rivera, D., & Greer, J. E. (2002). Exploring various guidance mechanisms to support interaction withinspectable learner models. 6th International Conference on Intelligent Tutoring Systems, 442-452.Zimmerman, B. (2000). Attaining self-regulation: A social cognitive perspective. In M. Boekaerts, P.R. Pintrich,& M. Zeidner (Eds.). Handbook of self-regulation: Theory, research, and application, pp. 13-29. SanDiego: Academic Press.Zimmerman, B. (2001) Theories of self-regulated learning and academic achievement: An overview andanalysis. In: Zimmerman B, Schunk D (eds) Self-regulated learning and academic achievement:Theoretical perspectives, Erlbaum, Mahwah, NJ, 1-37.Zimmerman, B. J., & Campillo, M. (2003). Motivating self-regulated problem solvers.vJ. E. Davidson & R.Sternberg (Eds.). The nature of problem solving. New York, NY: Cambridge University Press.Acknowledgments(Paper 1): This work was supported by NSF-IIS Award #0904387 and IES CASL Award #R305A120186.(Paper 2): This work was supported by the Social Sciences and Humanities Research Council of CanadaLEADS Research Partnership grant, the Tier 1 Canadian Research Chair in Advanced Technologies forLearning in Authentic Settings, the Canadian Foundation for Innovation, and by McGill University.(Paper 3): This work was supported by the Pittsburgh Science of Learning Center, through the National ScienceFoundation (#SBE-0836012), the University of British Columbia through the Carl Wieman Science EducationInitiative. and a Graduate Training Grant awarded to Carnegie Mellon University by the Department ofEducation (# R305B090023).ICLS 2014 Proceedings1361© ISLS