Exploring A Digital Tool for Exchanging IdeasDuring Science InquiryCamillia Matuk and Marcia C. Linn, University of California, BerkeleyEmail: cmatuk@berkeley.edu, mclinn@berkeley.eduAbstract: Practicing science increasingly involves knowing how to participate in a networkedknowledge community. This includes expressing scientifically informed ideas, sharing ideaswith peers, and evaluating multiple sources of information. Effective instruction builds onstudents’ prior ideas, enables them to benefit from exchanging ideas with others, and supportsthem learning from one another. How might technology support these exchanges? And howmight documenting these exchanges inform teachers’ and researchers’ improvements to theirinstruction and design? We describe the Public Idea Manager, a new curriculum-integratedtool that supports students exchanging ideas during web-based science inquiry. Ourexploratory analyses show relationships between the diversity and sources of students’ ideasand the quality of their explanations. We discuss implications for formative assessment, andfor the role of technology in supporting students to engage more meaningfully withinformation and with each other.Supporting the Exchange of Ideas During Science InquiryOne of the most effective ways to support the understanding of science is to build upon learners’ priorknowledge. But amid the multiple constraints of the classroom, it can be difficult for teachers to addressstudents’ diverse ideas, which are often conflicting and incomplete (diSessa, 2000). Tools that promotecollaboration offer numerous advantages for students promoting one another’s understanding. They alsoemphasize participation in authentic scientific communities. The potential for such tools to capture fine-grainedinformation on students’ exchanges can moreover help researchers and teachers better understand and supportstudents’ inquiry.In this paper, we describe a curriculum-integrated tool that supports students exchanging ideasthroughout the process of constructing scientific explanations. We present classroom findings on how middleschool students used the tool during a life sciences unit, and how the sources and diversity of their ideas relatedto the quality of their explanations. We discuss implications of our findings for inquiry instruction, and nextsteps in research and design.Theoretical BackgroundExplanation is a hallmark of science inquiry, but challenging for students. They have difficulty using evidenceto support their claims (Sandoval, 2005), coordinating evidence from multiple sources and with multiplealternative hypotheses (Kuhn et al., 1995; Schauble, 1996), refining arguments in light of new evidence (Chinn& Brewer, 1998), and articulating ideas in writing (McNeill & Krajcik, 2008; Sandoval & Millwood, 2005).Planning activities, such as generating, organizing, and linearizing ideas can help, but students rarely do this(Andriessen et al., 1996). It is therefore not surprising that continuous guidance for developing explanations isuseful (Quintana et al., 2004).Our research and curriculum design is guided by the Knowledge Integration (KI) pattern (Linn &Eylon, 2011). This perspective assumes that learners hold multiple, often contradictory views of any one sciencetopic and that learners deliberately distinguish and make connections between new and existing ideas (diSessa,2000; Eylon & Linn, 1988; Linn & Hsi, 2000; Slotta et al., 1995). Instruction guided by KI thus emphasizeseliciting students’ existing ideas; helping them explore additional; more normative ideas; and guiding them toreflect on distinguishing and sorting out alternatives as they build an integrated understanding.In other words, the KI pattern would suggest learning benefits in initially diversifying and thenconverging on ideas as learners reflect upon and refine their understanding. Research on brainstorming acrossdomains finds differential benefits of convergent and divergent thinking during different phases of problemsolving (Cropley, 2006). Other research suggests that the kind of information encountered in collaborativeknowledge building environments can affect how one revises their ideas. Exposure to incongruous informationin Wikipedia, for instance, was more likely to prompt editors to revise their ideas than exposure to congruousinformation (Moskaliuk, Kimmerle, & Cress, 2012).Existing collaborative environments offer tools with which learners can build upon one another’s ideas(e.g., Scardamalia & Bereiter, 2006). Often, however, middle schools students require more explicit scaffoldingto guide their construction of scientific explanations than are available in such environments. Questions alsoremain over how to make sense of what occurs during the free exchange of ideas. For instance, one mightanticipate the exposure to peers’ ideas to result in either the diversification or the reinforcement of students’ICLS 2014 Proceedings895© ISLSown ideas. But how do students make decisions over which ideas from their peers to incorporate? And how cantechnology capture these decisions to inform more effective instruction?Goals and Research QuestionsWe designed a tool called the Public Idea Manager (IM), which would (1) allow students to access each others’ideas as learning resources when refining their own understanding; and (2) capture students’ exchanges of ideasin order to inform teachers and researchers of better ways to support students collaborative learning.In this initial exploratory study of a larger design-based research program, we wished to know howstudents would take advantage of the tool. Our specific research questions were (1) how would students use atool that supports the exchange of ideas among peers? That is, would they freely share ideas, or would they bereluctant to do so? Would they tend to copy ideas from their peers rather than generate their own? Whenstudents do copy peers’ ideas, would they recognize good quality ideas? And (2) how would the diversity ofstudents’ individual repertoires of ideas change as a result of their access to a public idea repository? Moreover,how might the relative diversity of students’ ideas, and the source of those ideas (generated by oneself or copiedfrom one’s peers), relate to the quality of students’ scientific explanations?Through the design of a tool for exchanging ideas, this research provides opportunities for students toparticipate in more authentic collaborative science inquiry. It moreover provides researchers and teachers waysto better understand the role of technology in mediating students engaging with each other’s ideas, and drawingon their peers to support their explanations.MethodsParticipants and SettingParticipants were 297 students in a middle school in the western United States. Their two teachers had 5 classperiods each, and collaborated closely to coordinate lesson plans and grading. One teacher had taught the WISEunit (described below) for more than 8 years, while the other teacher had taught it for 3 years. Students mostlyworked as partners on the unit during one 50-minute class period on each of 7 consecutive school days. Twomore days before and after this time were spent completing a pre and posttest (described below). Meanwhile,the teachers circulated the classroom to offer guidance on the material or assistance with the technology asneeded. A researcher was also present in the room on most days, but mainly sat apart from the class to recordobservations.WISE and the Public Idea ManagerThe platform for our curriculum and technology development is the Web-based Inquiry Science Environment(WISE, wise.berkeley.edu). WISE is a free, open-source, and customizable online learning environment. WithWISE, students engage in self-paced, collaborative investigations, in which they collect and interpret evidencefrom dynamic visualizations, and use various tools to express their understanding. WISE meanwhile logsstudents’ interactions, which enables teachers to grade and give feedback, and designers and researchers tobetter study the impacts of technology on student learning.Figure 1. Over the course of a unit, students enter short text entries into their Idea Baskets (left), andspecify attributes (e.g., source, tags, rating). Students can choose to share any private idea to the Public Basket,from which they may also copy any idea into their Private Baskets. Entries accumulate in a sortable list to whichstudents can return and revise (middle). In the Explanation Builder (right), students drag ideas into authordefined categories, and refer to these as they write an explanation in response to a prompt.The Public Idea Manager (Figure 1) is a feature of the Idea Manager (IM), a tool integrated intoWISE. The IM scaffolds explanation according to the KI pattern by making explicit the acts of gathering,distinguishing, and sorting ideas (Matuk, et al., 2012). As WISE logs these actions, the IM provides teachersand researchers a record of students’ changing ideas that can inform instruction and design. For example, priorresearch used the IM in a chemistry unit to identify when in the process of explaining students found specificICLS 2014 Proceedings896© ISLSideas more or less difficult to apply (McElhaney, et al., 2011). Such analyses indicate the kind of assistanceneeded, as well as which students need it. As such, the IM adds value over typical pre and posttests of students’understanding. The Public IM extends the functionality of the IM from a private repository to a common spacethrough which students can exchange ideas. First piloted in classrooms as a hybrid prototype (Matuk, et al.,2013), this feature makes it possible to track how ideas emerge and spread within a classroom, and howexchanging ideas affects students’ developing understanding.The design of the Public IM was inspired by previous and existing argumentation and explanationscaffolds (e.g., Bell, 2004; Zhang & Quintana, 2012). By supporting freeform documentation, the tool allowsfor the various kinds of ideas students may have, which do not always conform to teachers’ and designers’expectations. The interface of the Public IM is moreover customizable, including the selection of idea attributes,the categories for sorting, and the names Idea Basket and Explanation Builder. As such, teachers andresearchers can adapt the tool to align with their own research and instructional goals.Integrating the Public Idea Manager into MitosisWhat Makes a Good Cancer Medicine? (aka, Mitosis) is a middle school unit publicly available atwise.berkeley.edu (Preview the unit at http://wise.berkeley.edu/webapp/previewproject.html?projectId=6498).In it, students assist a fictional scientist in investigating the potential of three different plant-derived chemicalsin treating cancer. This sequence of activities was designed to follow the Knowledge Integration pattern bystructuring activities to support eliciting, adding, distinguishing, organizing, and reflecting on ideas as studentsprepare to write recommendations for cancer medicines based on their observations (Matuk & Linn, 2013).As students examine animations to compare the effects of each chemical on cell division, they learn thephases of mitosis and cell division. At several points throughout the unit, students are prompted to gather ideasin the IM about specific topics (e.g., cell division, cancer medicine, observations made of the animations). Atfour different points in the unit, students sort their ideas in preparation to write explanations (What happenswhen cells divide? How might a medicine stop cancer cells from dividing? Which treatment would yourecommend? and Why does hair fall out during cancer treatment?). At these same points, students areencouraged to share at least one of their ideas to the Public Basket, and to copy at least one of the Public ideasinto their Private Baskets. After each exchange, students are asked to write justifications for their choices ofideas.Data and AnalysisBecause this study is part of a larger research program on technology-enhanced curricula, we focus our analysison just the relevant portion of all data collected. Specifically, our analysis aimed to explore how studentsexchanged ideas through the Public Idea Manager, and how the diversity of their ideas related to the quality oftheir explanations. Thus, we sought correlations in student log files on private ideas generated, private ideasshared to the Public Basket, and public ideas copied into students’ Private Baskets. We analyzed students’written explanations to culminating questions in the final Idea Manager sequence of the unit, and analyzed theirwritten justifications for exchanging ideas. Details of our analysis are described below. We triangulated this datawith classroom field note observations, video of student pairs working together on the unit, and retrospectiveinterviews with teachers, from which we selected cases to illustrate and explain our quantitative findings.Among other questions in the interviews, we asked teachers to reflect on students’ uses of the tool, and to sharetheir observations of its impact on students’ learning and collaboration.A pre and posttest included a paper-and-pencil test that asked students to draw and describe the phasesof cell division, and a computer-based test with open-ended and multiple-choice questions that asked students touse their understanding of cell division to reason about the mechanism of an effective cancer treatment. Theseassessments were designed to measure the overall effectiveness of the unit on improving students’ conceptualunderstanding of key ideas introduced in the unit. Each item was scored on a 5-point rubric that measured thedegree to which students integrated ideas into a coherent explanation (Linn & Eylon, 2011).ResultsPre and Post-Test GainsStudents showed significant average gains from the pre to the posttest (M=1.38, SD=1.09, t(219)=-12.88,p<.0001). This indicates that the unit had a positive impact on students’ learning. In what follows, we discussfindings that illuminate students’ uses of the Idea Manager.How Did Students Exchange Ideas?By the end of the unit, students’ Private Baskets contained an average of 18.7 ideas (SD = 6.8). A significantlygreater number of these ideas were self-generated (M=14.53, SD=5.52) than were chosen from the PublicBasket (M=4.17, SD=3.42). This finding is encouraging because it suggests that in spite of their access to theICLS 2014 Proceedings897© ISLSPublic Basket, students were not reliant on their peers for ideas. Instead, they tended to start with ideas of theirown.Students appeared more inclined to contribute ideas to the Public Basket (M=5.11) than they were tocopy ideas (M=4.26). They moreover appeared highly selective in the ideas they decided to exchange, as only22.8 - 27.3% of the mean 18.7 ideas in their Private Baskets were ever in circulation. To determine whetherstudents were making good decisions in their choices of Public Ideas, we scored each Public idea based on howwell it integrated two or more relevant concepts into a supported statement (Table 1.)Table 1. Scoring rubric for the quality of ideas in the Public BasketScore012345DescriptionNo responseOff taskUninterpretable; nonnormative ideas orobservations;Declarative or factual statements ordefinitions; unconnected ideas; or a mixtureof normative and nonnormative ideas.A normative observation or claim, but lacksinterpretation, explanation, or sufficientsupporting evidence.Integrates more than one concept into awell-supported, normative claim; offers acausal explanation for an observation.Example(None found)(None found)They divide during mitosis because cancer cellmake them spread the sickness.its bad, you can die, theres many types of cancer.The medicine stops the centrioles and spindle fibersfrom pulling the choromosomes apart.The cell was able to undergo mitosis, but one of thecell's chromosomes was obliterated by the Zingiberzerumbet, possibly making that cell useless.Mean number oftimes chosenPublic ideas had a mean quality score of 3.77, and were copied a mean number of 0.83 times. Results show thathigher quality public ideas also tended to have been copied more frequently (F(2, 721) = 10.76, p<.0001)(Figure 2). This finding suggests that students appear to successfully recognize good quality ideas from amongthose available in the Public Basket.1.210.80.60.40.201.11High [5] (N=198)0.730.72Medium [4] (N=216)Low [2, 3] (N=308)Quality of Public ideaFigure 2. Students more frequently chose higher quality ideas than they chose medium or low quality ideas fromthe Public Basket. Quality scores are shown in square brackets.Students’ Reasons for Exchanging Public IdeasReasons for choosing Public ideas010203040060ValidNo reasonHelpfulAltruisticRelevantBlankLast resortRecognitionInterestingSimilarObligationTeacher Prompted3131HelpfulNo reason18Similar7Interesting44BlankRelevantLast resort5052ValidOthers' certaintyReasons for sharing Private ideas211020304050607063271511117543211Figure 3. Categories of students’ justifications for choosing and sharing ideas midway through the unit.To explore whether students were consciously choosing ideas based on their quality, we examined their writtenresponses to embedded prompts to justify their decisions. In these, students expressed a variety of reasons forICLS 2014 Proceedings898© ISLSexchanging ideas in the Public Basket (Figures 3 and 4). Most commonly, students based their decisions toshare and to copy ideas on the idea’s perceived validity (“… because we agree with it the most.” “…it was avery smart answer and it seemed like something that would be true.”).Reasons for sharing private ideas additionally included a desire for peer recognition (“...we wantedto… see what [our classmates] thought (if they [chose] our idea or not).”), and a desire to improve the PublicBasket (“[our idea] seemed acurate [sic] compared to the other (students’) ideas.” “… we thought it was a goodidea and nobody has it yet.” “… it was a general statement that other classmates would understand.”).Altogether, these findings suggest that students engaged in sophisticated decision-making when evaluating theirideas against those of their peers. In sharing ideas, some students even appeared to consciously consider thevalue of their contributions to this collaborative space.Figure 4. In choosing which Public idea to copy, these students consider various strategies, including randomselection, the certainty of the idea’s contributor, and the similarity of the idea to existing ideas of their own.How do Idea Sources and Diversity Relate to Explanation Quality?Mean # PrivateBasket ideasNotably, approximately 20.67% of students chose Public ideas because they were helpful; that is, because theyadded new information to their thinking (“… because it was well written and explained part of the lesson.” “…because we thought that it was similar to our idea but different enough to provide food for thought.”). Incontrast, 12% of students chose ideas because of their similarity to existing private ideas (“…because we wrotea private idea similar to that…”).If students were indeed choosing Public ideas based on difference or similarity with respect to theirown ideas, we might expect this to reflect in the actual diversity of students’ Private ideas. The relative benefitsof diversifying vs. converging on ideas might moreover be evident in the quality of students’ explanations.Specifically, how well do students explain who tend to collect ideas that simply agree with their own? How welldo students explain who tend to collect ideas that conflict with, or that otherwise diversify, their own ideas? Toexplore these questions, we coded each of students’ Private Basket ideas according to whether it was unique orredundant relative to the rest of the ideas in the Basket. Unique ideas added new information not already presentin the Basket, whereas redundant ideas restated already existing ideas. Results show that students’ Private IdeaBaskets contained a greater proportion of unique as opposed to redundant ideas, regardless of the source (i.e.,self-generated or copied from the Public Basket) (Figure 5).20Unique (total=16.76)15Redundant (total=1.95)1.35105013.180.593.58Public ideas chosenPrivate ideas generatedFigure 5. Proportion of unique and redundant ideas by sourceTo explore the relationship between idea diversity and students’ abilities to explain, we scoredstudents’ explanations to the final prompt in the unit: “Maya heard that her mother’s hair might fall out duringher cancer treatment. Why would this happen?” Explanations were scored based on the number of linksstudents made between key ideas presented in the unit (Table 2):ICLS 2014 Proceedings899© ISLS•••••••Cancer is when cells divide rapidly/out of control.Cancer treatment stops cell division to treat cancer.Chemotherapy targets rapidly dividing cells.Chemotherapy also stops normal cells from dividing.Skin/hair cells are rapidly dividing cells.When hair cells aren't replaced with new ones, hair falls out.When skin/hair follicle cells die, they can no longer hold hair in the scalp and the hair falls out.Table 2: Scoring rubric for explanationsScore012345DescriptionBlankOff-task, not possible to interpretNon-normative, lacks explanation, doesn’t address the question1 normative idea2 linked normative ideasElaborated response with 3+ linked normative ideas% of ideas in Private BasketsResults show the relative diversity of ideas in students’ Private Baskets to be correlated with the quality of theirexplanations at the unit’s end. Specifically, students with the poorest explanations also tended to have a greaternumber of unique ideas in their Private Baskets, whereas students with the best explanations tended to have agreater number of redundant ideas (F(2, 142) = 6.04, p<.005) (Figure 6).UniqueRedundant100%95%0.060.110.110.890.89mediumhigh90%85%0.9480%lowQuality of explanationFigure 6. Proportion of unique and redundant ideas in students’ Private Baskets, by explanation qualityMostly self-generated ideasMostly chosen/equally chosen and self-generated ideas100%% of students80%60%40%20%10.4917.4816.7827.27mediumhigh18.889.090%lowQuality of explanationFigure 7. Sources of redundant ideas by quality of explanationFurther analysis shows a relationship between the quality of students’ explanations and the sources ofthese redundant ideas: students themselves or their peers. That is, students who wrote better explanations alsotended to have self-generated more of the redundant ideas in their Private Baskets. In contrast, students whowrote poorer explanations tended to have mostly chosen, or to have equally chosen and self-generated, theirredundant ideas (χ² = 9.511, df = 2, p<.01) (Figure 7).ICLS 2014 Proceedings900© ISLSHow the Public IM Enhanced Teachers’ RolesIn her interview, one teacher noted how prior to this tool, she struggled to keep her students from simply relyingon the smart kids to give the answers. Because of its anonymity, the Public Basket placed all students’ ideas onequal footing. It was such that the teacher noticed that her students’ discussions are more interesting” as theymade serious attempts to consider and understand their peers’ ideas.The tool also helped teachers provide formative feedback. Instead of waiting until students had gonetoo far down a misguided path, teachers would scan through WISE’s grading interface, notice how studentswere organizing their ideas, and identify students in need of individual assistance. Teachers would also monitorstudents’ ideas to identify which topics appeared most challenging overall. Based on this information, teacherswould tailor whole-class opener activities to reinforce the unit’s instruction. Future work will explorevisualization tools to help teachers more easily monitor patterns in students’ ideas; as well as a feature thatallows teachers and researchers to moderate students’ exchanges, such as by seeding the Public Basket withideas, or promoting promising ideas for other students to notice.Discussion and ImplicationsUsing a new tool for students to exchange ideas during web-based science inquiry, we found relationshipsbetween the sources and diversity of the students’ ideas, and the quality of their explanations. Interestingly,students who had generated more redundant ideas also tended to have constructed more coherent explanations.One reason for this observation is that students who were already likely to produce high quality explanationsmanaged to identify the key ideas early in the unit. These students may thus have tended to rephrase these samekey ideas whenever prompted to add new entries. Meanwhile, students who were already likely to produce poorquality explanations may have been less able to recognize relevant, normative ideas. It follows that a highlydiverse set of ideas may indicate students who need more support distinguishing among their many ideas.Another explanation for this finding is that generating redundant ideas has cognitive benefits. It mayhelp students refine their understanding, as does self-explanation (Chi, DeLeeuw, Chiu, & LaVancher, 1994;Siegler, 2002). Elaborating by rearticulating ideas may be a metacognitive learning strategy that involvesactively creating links between new and prior knowledge (Mayer, 2002; Weinsten & Mayer, 1986). As withrewriting and revision, students who generate redundancy may be re-evaluating and clarifying their thinking(Ladd, 2003; Fitzgerald, 1992; Scardamalia & Bereiter, 1994).An advantage of this tool is that it allows careful engineering of students’ interactions withinformation, and thus, ways to explore variations in scaffolding the exchange of ideas. As analysis of these datacontinues, we are investigating the effects of prompting students to use the Public IM either to diversify or toreinforce their ideas, and how exposure to either diverse or redundant ideas might influence how students revisetheir explanations. Among other questions, we will explore when in the process of explanation (e.g., gathering,distinguishing, or sorting ideas), and for which students (e.g., low vs. high prior knowledge) each strategy mightbe most effective. We will also trace specific self-generated and copied ideas over time to see how these becomeintegrated into students’ explanations.Revisions to the technology may include features that support effective discourse between students,and more deliberative choices around the exchange of ideas. Future research might explore how lessons learnedabout the role of technology in the exchange of ideas might be applied to different contexts, such as engineeringdesign, medical decision-making, and other problem-based learning scenarios.Learning and Becoming in PracticeThis research relates to the theme of Learning and Becoming in Practice in multiple ways. First, it attends to thenotion that science inquiry entails participation in a global knowledge community. This involves developing andpracticing various collaborative skills, including expressing scientifically informed ideas, sharing ideas withpeers, and evaluating multiple sources of information. Second, our study explored the role of technology inhelping students thus engage meaningfully with information, and with each other. We observed how our toolsupported teachers attending to their students’ ideas throughout their inquiry, thus giving them the means tofocus assessment on learning processes and on the development of scientific practices, rather than just onoutcomes. Finally, our approach to design is one that emphasizes sustainability. By being customizable, forexample, the Public IM allows both researchers and teachers to explore different questions about how studentslearn, and how to support it. By also involving various stakeholders in the design of the tool, our design processinvites others to contribute to the tool’s improvement. These features help maintain the tool’s relevance, andensure its usability and usefulness over time.ReferencesAndriessen, J. E. B., Erkens, G., Overeem, E., & Jaspers, J. (1996, September). Using complex information inargumentation for collaborative text production. Paper presented on the First Conference on UsingComplex Information Systems (UCIS'96), Poitiers, France, 1996.ICLS 2014 Proceedings901© ISLSBell, P., & Linn, M. (2000). Scientific arguments as learning artifacts: designing for learning from the web withKIE. International Journal of Science Education, 22(8), 797-817.Bell, P. (2004). Promoting students’ argument construction and collaborative debate in the science classroom. InM. C. Linn, E. A. Davis & P. Bell (Eds.), Internet environments for science education (pp. 115-143).Mahwah, NJ: Erlbaum.Chi, M. T., De Leeuw, N., Chiu, M. H., & LaVancher, C. (1994). Eliciting self-explanations improvesunderstanding. Cognitive science, 18(3), 439-477.Chinn, C. A., & Brewer, W. F. (1998). An empirical test of a taxonomy of responses to anomalous data inscience. Journal of Research in Science Teaching, 35(6), 623-654.Cropley, A. (2006). In praise of convergent thinking. Creativity Research Journal, 18(3), 391-404.diSessa, A. A. (2000). Changing minds: Computers, learning, and literacy. Cambridge, MA: MIT Press.Fitzgerald, J. (1992). Towards knowledge in writing. New York, NY: Springer-Verlag.Kuhn, D., Garcia-Mila, M., Zohar, A., Andersen, C. (1995). Strategies of knowledge acquisition. WithCommentary by Sheldon H. White and by David Klahr and Sharon M. Carver; and a Reply by DeannaKuhn. Monographs of the Society for Research in Child Development, 60(4, Serial No. 245).Ladd, B. C. (2003). It's all writing: Experience using rewriting to learn in introductory computer science.Journal of Computing Sciences in Colleges, 18(5), 57-64.Linn, M.C. & Eylon, B-S. (2011). Science Learning and Instruction: Taking Advantage of Technology toPromote Knowledge Integration. New York, NY: Routledge.Linn, M. C., Hsi, S. H., & Hsi, S. (2000). Computers, teachers, peers: Science learning partners. Mahwah, NJ:Lawrence Erlbaum Associates, Inc.Matuk, C. F. & Linn, M. C. (2013, April 27 - May 1). Technology Integration to Scaffold and Assess StudentsUse of Visual Evidence In Science Inquiry. Paper presented at the American Educational ResearchAssociation Meeting (AERA2013): Education and Poverty: Theory, Research, Policy and Praxis, SanFrancisco, CA, USA.Matuk, C., McElhaney, K., Miller, D., King Chen, et al. (2013). Reflectively prototyping a tool for exchangingideas. In CSCL’13: Proceedings of the 10th International Conference on Computer SupportedCollaborative Learning, (Vol. 2, pp. 101-104). Madison, WI, 2013. International Society of theLearning Sciences.Matuk, C. F., McElhaney, K., King Chen, J., Miller, D., Lim-Breitbart, J., & Linn, M. C. (2012). The IdeaManager: A tool to scaffold students in documenting, sorting, and distinguishing ideas during scienceinquiry. In ICLS'12: Proceedings of the 10th international conference for the learning sciences,Sydney, Australia, 2012. International Society of the Learning Sciences.Mayer, R. E. (2002). Multimedia learning. Psychology of Learning and Motivation, 41, 85-139.McElhaney, K., Miller, D., Matuk, C., & Linn, M. (2012). Using the Idea Manager to promote coherentunderstanding of inquiry investigations. In Proceedings of the 10th International Conference for theLearning Sciences, Sydney, Australia, 2012. International Society of the Learning Sciences.McNeill, K. L., & Krajcik, J. (2008). Inquiry and scientific explanations: Helping students use evidence andreasoning. Science as inquiry in the secondary setting, 121-134.Moskaliuk, J. Kimmerle, J. & Cress, U. (2012) Collaborative knowledge building with wikis: The impact ofredundancy and polarity, Computers & Education, 58(4), 1049-1057.Quintana, C., Reiser, B. J., Davis, E. A., Krajcik, J., et al. (2004). A scaffolding design framework for softwareto support science inquiry. Journal of the Learning Sciences, 13(3), 337-386.Sandoval, W. A., & Millwood, K. A. (2005). The quality of students' use of evidence in written scientificexplanations. Cognition and Instruction, 23(1), 23-55.Scardamalia, M., & Bereiter, C. (1994). Computer support for knowledge-building communities. Journal of theLearning Sciences, 3(3), 265-283.Scardamalia, M., & Bereiter, C. (2006). Knowledge building: Theory, pedagogy, and technology. In K. Sawyer(Ed.), The Cambridge Handbook of the Learning Sciences (pp. 97-118). New York, NY: CambridgeUniversity Press.Schauble, L. (1996). The development of scientific reasoning in knowledge-rich contexts. DevelopmentalPsychology, 32(1), 102.Siegler, R. S. (2002). Microgenetic studies of self-explanation. In N. Granott & J. Parziale (Eds.),Microdevelopment: Transition processes in development and learning (pp. 31-58). New York, NY:Cambridge University Press.Weinstein, C. E., & Mayer, R. E. (1986). The teaching of learning strategies. In M. C. Wittrock & TheAmerican Educational Research Association (Eds.), Handbook of research on teaching: A project ofthe American Educational Research Association (pp. 315-327). New York, NY: MacMillan.Zhang, M., & Quintana, C. (2012). Scaffolding strategies for supporting middle school students’ online inquiryprocesses. Computers & Education, 58(1), 181-196.ICLS 2014 Proceedings902© ISLS