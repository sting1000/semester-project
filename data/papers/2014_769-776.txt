Dynamic Visualization of Motion for Student-Generated GraphsJonathan M. Vitale, Kevin Lai and Marcia C. Linn, University of California, Berkeleyjonvitale@berkeley.edu, laikevin@gmail.com, mclinn@berkeley.eduAbstract: Graph construction and interpretation are critical 21st-century skills. In this studywe investigate how 8th grade students construct graphs in the context of a week-long onlinecurriculum unit that links dynamic visualizations to graphical data. We test two forms ofvisualization: dual animation depicting both the student’s graph and the correct graph in termsof a narrative context and single animation depicting only the student’s graph. Quantitativeresults indicate that both forms of animation supported understanding, but dual animationfacilitated construction of more accurate graphs earlier in the unit. Case studies reveal uniquegraphing patterns associated with each form of animation.IntroductionIn this research we compare two forms of graph visualization to explore how new technologies can improvegraph understanding. Graphing is a critical mathematical and scientific skill, as well as a key practice used inpersonal and policy decisions. Growth in the field of data science suggests that the ability to apply graphingknowledge in a broad range of contexts will be an increasingly valuable 21st-century skill. As such, newstandards assert that students translate between quantitative, graphical and narrative forms (NGACBP, 2010).Given documented student difficulties with graph understanding (Shah & Hoeffner, 2002), we seek tools thatcan help students interpret graphs. We test a graph visualization tool under two conditions to explore howfeedback on graph construction can improve graph understanding.Graph understanding involves a variety of thinking skills, ranging from basic perceptual processing tohighly complex cognitive reasoning (Shah & Hoeffner, 2002). Successful graph construction and interpretationrequires students to coordinate between multiple representations (e.g. text, tables, and graphs in various formats)and sources of knowledge (e.g. perceptual, contextual, and mathematical). Given the complexity, iterativerefinement of instruction and testing of comprehensive alternatives is valuable (Quintana et al., 2004).To promote graph understanding we designed instruction using the Web-based Inquiry ScienceEnvironment and the knowledge integration (KI) framework and tested alternative uses of our visualizationtools (Linn & Eylon, 2011). The KI framework has proven useful for design of instruction featuring dynamicvisualizations (Ryoo & Linn, 2012). The pattern guides students to articulate predictions, add new ideas,distinguish between predictions and new ideas, and reflect on the problem. When students articulate their ideas,including non-normative ideas, they are prepared to compare and contrast these ideas with alternativesintroduced in the curriculum. By facilitating reflection on contrasting ideas, technology can support robustconceptual change.While the general pattern of the KI framework is widely applicable, the specific activities associatedwith each aspect of the KI pattern are dependent on the conceptual domain and available technologies. Forgraphing, we can elicit ideas by asking students to interpret a graph or to construct a graph about a complexsituation. Research shows that students often generate a “pictorial” interpretation of the graph rather thancapturing a relationship (Leinhardt, Zaslavsky, & Stein, 1990). For position vs. time plots (position-time),students often make a pictorial interpretation when they report that a flat line segment represents an objectmoving forward along a straight path, or that a non-zero slope represents an object moving up or down (Mokros& Tinker, 1987). Additionally, students may generate a graphical representation of an object “moving back” to areference point by drawing a line that essentially goes back in time. This response does not recognize that aposition-time graph will always move forward in time (i.e., from left to right).Dynamic visualizations (e.g. animations) have successfully promoted acquisition of ideas about graphs(Moreno, 2001) and specifically about motion graphs (Imhof, Scheiter, Edelmann, & Gerjets, 2013). Forexample, in the SimCalc software MathWorlds (Roschelle, Kaput, & Stroup, 2000), students view the animationof an elevator that moves according to the shape of a segmented line graph. Likewise, Ploetzner, Lippitsch,Galmbacher, Heuer, and Scherrer (2009) depict line graphs through an animation of a runner. By observingthese linked representations students have the opportunity to discover relationships between abstract spatialfeatures (e.g. slope) and narrative events.Our research extends this line of investigation to activities that help students distinguish among ideasabout motion graphs. Distinguishing requires that students develop and apply criteria to evaluate ideas and thencompare multiple ideas based on these criteria. This multi-step process represents a significant design challenge,given inherent limitations on students’ working memory (Sweller, 1988) and ability to attend to multiple visualphenomena within the same sensory modality (Mayer, 2001). A general solution is to reduce cognitive load bydistributing information to the environment so that the learner has less information to maintain in workingmemory (Zhang & Norman, 1994).ICLS 2014 Proceedings769© ISLSFor narrative-based position-time graphs, ideas may be elicited by prompting students to graph thenarrative. Animated feedback depicting the motion inherent in these graphs (“student animation”) then providesan opportunity to evaluate ideas by comparing observed motion to the imagined motion of narrative events.While this may be straightforward for simple narratives, for complex narratives the burden of remembering thesequence of events may overwhelm students. Furthermore, for subtle changes in motion the student may notclearly recognize any incongruity with the narrative text, as he or she interpreted it. In this case the mentalreference by which the animation is evaluated is challenging to construct and difficult to maintain in memory.A potential remedy is to provide an additional concrete reference animation that accurately depicts thenarrative (“normative animation”). While this design would seem to reduce the burden on students, there maybe unintended consequences of introducing a new visual representation. For example, splitting attentionbetween the two animations may inhibit comprehension (Mayer, 2001). Additionally, by relying solely on thenormative animation, rather than generating a mental simulation of the narrative, students may miss animportant learning opportunity (Black, Segal, Vitale, & Fadjo, 2012; Vitale, Black, & Swart, 2013).Furthermore, reliance on visual feedback has been associated with application of opportunistic trial-and-errorstrategies, which can interfere with learning in a digital environment (e.g., Logo, Cope & Simmons, 1994).In this research we compare the use of dual animations (Student+Normative condition) to a singleanimation (Student-only condition). We hypothesize that the Student+Normative condition will facilitate theproduction of more accurate graphs but anticipate that each condition has some advantages. We take anexploratory approach to analysis of student strategies, and how they reflect affordances of the graphing tools.We take an in-depth look at individual students’ graphing artifacts to evaluate how emergent strategies maypromote or inhibit learning.MethodsParticipants and ProceduresThree teachers from two suburban middle schools chose to participate in this study. A total of 384 eighth gradestudents participated in some part of this study. Out of these students 333 students completed the pretest, (somepart of) the curriculum unit, and the posttest. The populations served by school these schools differed markedlyin income-levels and home language [School A: N = 319, 7% reduced lunch, 3% ELL; School B: N = 65, 63%reduced lunch, 25% ELL]. Both pretest and posttest were administered to children individually. Pairs ofstudents were assigned to collaborative workgroups by their teacher to work on curriculum. In one class withinSchool B students worked individually. Workgroups were randomly assigned to a condition [S+N or S-only] bythe software and received one of two sets of similar activities. While graphing, students seeking help weredirected by either the classroom teacher or researcher to complete the graph and observe the animated feedback.Curricular MaterialsThis study was conducted in the context of a curriculum module entitled Graphing Stories. The goal of the unitwas to familiarize students with the process of constructing graphs and interpreting graphs in terms ofnarratives. The curriculum was developed within WISE (Web-based Inquiry Science Environment), utilizing avariety of instructional and assessment tools (Linn & Eylon, 2011). Within a WISE module each page displayedon screen is referred to as a “step”. Groups of related steps are referred to as “activities”.Table 1: Curriculum layout for “Graphing Stories”#Activity TitleDescription/Goals1.Graphs Tell a Story Intro to graphing concepts.2.Retell the StoryFirst narrative graphing exercise withwith Graphsanimated feedback.3.GraphingDirect instruction on the relationship ofMovementslope to speed and direction.4.Peer review of narratives based on graphs.5.Trading GraphInstructionDrive Your Car6.Your StoryPersonal narrative and graphing exercise.ICLS 2014 ProceedingsSecond narrative graphing exercise, withstudent control of axes to adjust scale.770Relevant Steps2.2/2.3/2.4 – Table/Graph “BearStory”/Feedback (Bear item)3.3/3.4 – Graph person standingstill/Feedback3.7/3/8 – Graph person movingforward and back/Feedback3.11/3.12 – Graph person movingfast and slow/Feedback5.2/5.3/5.4 – Table/Graph “Sam’sJourney”/Feedback (Sam item)5.6 – Graph “Rita’s Journey”© ISLSTable 1 displays the general layout and features of the Graphing Stories curriculum unit. In the contextof this study we highlight the steps that feature table and graph construction, followed by an animated feedback.Figure 1 display the feedback layout for the “Bear story” and “Sam’s journey,” respectively.Figure 1. Screenshot of animated feedback tool (Student+Normative), Bear item (left) and Sam item (right).For feedback on the Bear item, displayed in Figure 1 (left), the lower half of the image displays astudent-constructed graph imported from the previous step. Above the graph, animated “hikers” move adjacentto a number line representing the range of the narrative. The lower “hikers”, marked with a red star, moveaccording to the normative solution, while the upper “hikers” move according to the student graph. The verticalred line in the graph indicates the current time in the animation and moves from left-to-right. At the current statein the animation (40 minutes), the story indicates that the hikers should be resting at the “lunch spot”; however,this student did not include a resting segment, resulting in a visual discrepancy. For the Sam item (Figure 1,right), the animation depicts the motion of cars. In this case the graph incorrectly represents “going back” as areversal in time, thereby producing a non-functional graph. In all versions of the animation, during those periodsof time when the hikers or car is predicted to be at multiple positions at once, the student-based image of thehikers or car is replaced by the word “ERROR” to indicate that the graph cannot be animated appropriately.Test MaterialsThe pretest and posttest included graph interpretation items in mixed multiple choice and open responseformats. For this study we focus on two open response items. In “The Race”, students were asked to interpret anincomplete graph representing two runners racing towards a finish line from different starting positions (Figure2). Students were asked to predict the winner and provide a scientific explanation for their choice. For “AJourney” students were asked to select and explain which of three graphs of distance over time – including twonon-functional graphs – could represent a bicycle ride. Both items were intended to elicit students’ nonnormative concepts about slope and speed. Items were coded independently by two researchers, differenceswere resolved by consensus (inter-rater agreement: Race: kappa = .88; Journey; kappa = .80).Figure 2. Graph for “The Race” item given in pretest and posttest.Analysis ApproachAll graphs generated by students for the Bear and Sam items in Graphing Stories were scored using anautomated algorithm according to the rubric displayed in Table 2. First, student graphs were evaluated for thepresence of up to four specific features corresponding to concepts addressed in the unit, including: where toplace the initial point and how to represent “moving back”, “not moving”, and a change in speed. The presenceof a feature was assessed either, in the case of a single point, by evaluating whether the point deviated from theICLS 2014 Proceedings771© ISLSexpected coordinates less than a threshold or, in the case of a slope, by evaluating whether the rise and run ofthe segment deviated from expected less than a threshold (in both cases approximately 5% of axis length).Second, a score was constructed to reflect the number of detected features.Table 2: Graph scoring rubric: features and scoresFeatureDescriptionInitial PointInitial point (time = 0) is placed at expected coordinatesBackwards (neg. slope)“Moving backwards” is represented with a negative slope segmentMotionless (zero slope)“Standing still” is represented with a zero slope segmentSpeed change“Slow” to “fast” is represented with two segments with differing slopesScoreDescription3-6Total # of features present in graph (at least once) + 22If no features detected, were there at least two points?1Less than 2 points were detectedFor both Race and Journey items a KI rubric was applied to assess the extent to which student responsesupported multiple normative ideas, linked in a coherent manner (Linn & Eylon, 2011). In the case of graphitems normative ideas may include numerical evidence, relevant spatial characteristics of the graph (e.g. slope),formal concepts about graphs (e.g. functionality), and relevant connections to the narrative context (Table 3).Table 3: KI scoring rubric for “The Race” pre/post open response item.ScoreLevelDescription0No Answer12OfftaskIrrelevant/Incorrect3PartialNormative isolated ideaswithout a valid linkBasicElaborate a scientificallyvalid link45ComplexElaborate two or morescientifically valid linksExamplesDoes not address questionWei-Lynn is faster than Vijay orother incorrect statementsGeneral observations of thegraph OR statements about speedwith no reference to the graphConnects observations fromgraph to speed or compares linesbased on distance or timeI don’t know.I think Wei-Lynn will win the racebecause she is already ahead of Vijay.Vijay is running faster, he will winConnects observations fromgraph to Vijay’s speedANDConnects velocity or slope todistance and timeVijay is traveling faster, because his linehas a greater slope. His speed is 5m/s,while Wei-Lynn's speed is 2 m/s. ThoughWei-Lynn's line seems longer, Vijay willreach the finish line faster.I predict Vijay to win the race because hewas closer to the finish line 6 secondsafter the race began, meaning he has ahigher rate of speed.ResultsAn ANOVA of the pooled pre- and posttest data revealed a significant effect of testing session [F(1, 331) =18.6, p < .001], demonstrating that across both conditions students made gains from pre- to posttest (Figure 3).However, neither a main effect of experimental condition [F(1, 331) = 0.3, p > .1], nor an interaction betweencondition and testing session emerged [F(1, 331) = 1.4, p > .1].Figure 3. Mean scores for pretest and posttest, by conditionThese results suggest that both conditions were equally effective in terms of promoting student graphunderstanding. This could either indicate that the addition of the normative animation did not affect students’graph construction strategies, or that the emergent strategies had similar effects on student learning, on average.To address this distinction we investigated initial and final graphs for Bear and Sam graphing items (Figure 4).ICLS 2014 Proceedings772© ISLSFor the Bear item, while students in both conditions began with similar scores for their initial graphs,students in the S+N condition completed the step with more accurate graphs than students in the S-onlycondition [t(202) = 2.6, p < .05]. In contrast, while the final graphs of the Sam item did not differ by condition,students in the S+N condition produced more accurate graphs initially [t(141) = 4.5, p < .001].Figure 4. Comparison of initial and final graph scores for two curriculum items, by condition. (Note: for allfigures and tables p-values denoted as such: *** p < .001, ** p < .01, * p < .05, † p < .1)Across both conditions, for both items, there was a clear improvement from initial to final graphs;however, this could have been due to students taking an iterative strategy of deliberately plotting partial graphs(which would not attain high scores, initially). To determine whether the feedback tool promoted more accuraterevisions, rather than simply more complete revisions, we compared the accuracy of the first graph producedwith at least 4 points (sufficient to achieve max score) to the final graph. For both Bear and Sam items accuracyincreased from first 4-point graph to final graph [Bear: t(197) = 6.3, p < .001; Sam: t(126) = 4.9, p < .001].What differences in strategies may have driven the difference between conditions in accuracy ofgraphs? To address this question at a broad level we tallied the number of unique graphs produced for bothitems by counting each step visit in which the student created, deleted, or moved a point (Figure 5a). In mostcases revisions of graphs were completed by revisiting the graphing step following the feedback step. For theBear item students in the S+N condition made significantly more revisions than students in the S-only condition[t(203) = 3.3, p < .01]; however, by the final graphing item (Sam) an opposite trend emerged in which studentsin the S-only condition revised marginally more often [t(146) = 2.0, p = .05]. We also analyzed the mean timespent graphing each item by summing duration across all step visits (Figure 5b). For the Bear item, differencesin conditions reflect number of unique graphs: students in the S+N spent more time graphing than students inthe S-only condition [t(203) = 4.1, p < .001]; however, no differences emerged on the Sam item.Perhaps due to the large discrepancy on time for the Bear item, more students in the S+N conditionwho began the Bear item did not attempt the Sam item than in the S-only condition [S+N: n = 42; S-only: n =19; Χ 2(1) = 8.7, p < .01]. This attrition is reflected in the different degrees of freedom reported in previousanalyses. Of the students remaining by Sam there were no differences between groups on pretest “The Race”scores [t(186) = 0.05, p > .1], suggesting that these groups were equivalent in terms of prior knowledge.Figure 5. Comparisons of number of unique graphs (a) and time spent on graphing items (b) by condition.ICLS 2014 Proceedings773© ISLSCase StudiesThe summary measures discussed above indicate that initially (i.e., on the Bear item) students in the S+Ncondition spent more time graphing and viewed feedback more often than students in the S-only condition. Weanalyze specific cases from log data to demonstrate how initial student ideas and the affordances of the graphingtools impacted graphing strategies. Cases were selected from a subset of students who showed improvementfrom pretest to posttest to illustrate how the graphing activity may have supported learning.For pair A, in the Student-only condition, both students’ incorrect response to “The Race” pretest itemrevealed a misunderstanding of the relationships between slope, direction and speed. Figure 6 displays a seriesof plots that this pair produced for the Bear item, initially (plot 1) and following feedback (plots 2-8). While theinitial plot does include a segment representing “moving back” with a negative slope, this may not have beenpurposeful. In the 2nd through 7th attempts the pair tests multiple ideas about how to represent “moving back”,including segments that progressed backwards in time (plots 3 and 5). While the final plot correctly represents“moving back”, it misses a subsequent “resting” segment; however, this was congruent with their precedingtabular representation, which also missed this feature of the narrative.Figure 6: Pair A, Bear graphing item, S-only condition. Solid lines indicate student-constructed graph. Dottedlines indicate normative graph (students did not view this graph).Likewise, Pair B (Figure 7) in the S-only condition also missed several key features of the narrative intheir table: neither “moving back” nor “resting.” While this pair took a successful iterative approach to representdata in their table, by missing relevant features in the table this pair lost the opportunity to test ideas about howto represent “moving back.” However, in a subsequent, simpler narrative (“forward-back”) these students wereable to recognize their mistake and construct an appropriate graph.Figure 7: Pair B, Bear graphing item and Forward-Back graphing item, S-only condition.In these two examples students were able to produce graphs that (nearly) accurately depicted theinformation in their tabular representations. Therefore the animation that these students viewed likely fit theirinterpretation of the narrative. This prevented these students from recognizing missing features of their graph.On the other hand, the S+N condition feedback was not dependent on students’ interpretation of the narrative inadvance of viewing feedback, thereby affording easier evaluation of graph accuracy.ICLS 2014 Proceedings774© ISLSFor pair C (Figure 8), these students produced a graph (plot 4) with a transposed resting and backwardssegments, as well as a missing final speed change. Because, in this case, the students produced a correct tableprior to graphing, the errors in plot 4 likely represent a simple mistranslation of the tabular data. While theresulting animation would be discrepant from the narrative, the difference – particularly in regards to the speedchange – would be subtle. Yet, with the addition of the normative animation the discrepancy is clear. In thiscase the pair recognized the errors and successfully revised their graph (plot 5).Figure 8: Pair C, Bear graphing item, S+N condition.The S+N condition, however, also has the unanticipated consequence of supporting a process of trialand-error to achieve an accurate result. For example, Figure 8 shows 8 of 15 unique graphs that pair Dproduced in the Bear item. While these students understood how to represent both “moving back” and “resting”events graphically as shown in their early graphs, they appear to use the affordances of the feedback to rapidlyguess and check, without deliberate planning, to complete the speed change feature of their graphs.Figure 9: Sample of Pair D plots, Bear graphing item, S+N condition (7 plots removed).Conclusions and ImplicationsWhile graphing instruction is often situated in an abstract mathematical context, students need to interpretquantitative data represented in graphs in multiple professional fields and everyday life. Thus, activities such asconstructing graphs from a narrative provide students with an opportunity to engage in authentic professionalpractices. Additionally, by situating activities in personally-relevant contexts we invite students to makeconnections between formal concepts addressed in school and everyday experiences.The Graphing Stories curriculum unit in WISE has been designed and refined with the collaboration ofmultiple expert teachers and researchers to help students develop ability to link narratives to graphs and graphsto narratives. The curriculum seeks to help students test and refine their ideas and to develop the ability tointerpret graphs in new complex situations. Technology can help students add new ideas and also engage in thecomplex and difficult task of distinguishing between and reflecting on multiple ideas (Linn & Eylon, 2011).While dynamic visualizations are common in online tools, this investigation reveals that students needextensive opportunities to test and refine their ideas with guidance that helps them sort out conflictinginterpretations. When instruction promotes distinguishing between predicted and actual outcomes of avisualization students are more likely to revise their own thinking. The manner by which technology supportsdistinguishing is an important subject of learning sciences research. We encourage additional research thatbuilds on these findings.In this study the Student-only [single] condition supported evaluation of an animation in reference tothe imagined sequence of the narrative. This required the student to establish a clear interpretation of thesequence. As the case studies demonstrate, when students misinterpreted important sections of the narrative, asrevealed by the table, the feedback did not promote revision. On the other hand, the Student+Normative [dual]ICLS 2014 Proceedings775© ISLScondition alerted students of an error independently of their understanding of the narrative. In some cases thisaffordance led students to adopt a trial-and-error strategy that circumvented more rigorous planning.While we suspect that the similarity in posttest gains between groups is partially due to the tradeoffsillustrated in the case studies, there are several alternative explanations that require future research. First, it maybe the case that over the course of six learning activities students in both conditions achieved a personal ceilingon the material. This is demonstrated by the initial and final graphs for the Sam item. While students in theStudent-only condition arrived at the item more prepared to construct accurate graphs initially, their final graphswere generally of equal quality as those in Student+Normative condition. Future research will explore morecomplex tasks.While neither condition showed a clear advantage we suspect that some mix of dual and singleanimations would be beneficial. Specifically, while the normative animation could represent an initial scaffoldfor early items, it could be removed in later activities to help students develop new strategies. Additionally,alternative forms of feedback (e.g. text), in conjunction with the student animation, could facilitate evaluationand planning for graph revisions. More generally, this study represents an important direction for learningsciences research on the use of visualizations to advance graph understanding. While visualizations are avaluable tool for conveying ideas, the specific features and affordances require critical analysis. As the casestudies presented here illustrate, emergent student strategies are often surprising and ultimately informative.ReferencesBlack, J. B., Segal, A., Vitale, J. M., & Fadjo, C. L. (2012). Embodied cognition and learning environmentdesign. In D. Jonassen & S. Land (Eds.), Theoretical foundations of learning environments (2nd ed.,pp. 198–223). New York: Routledge.Cope, P., & Simmons, M. (1994). Some effects of limited feedback on performance and problem-solvingstrategy in a logo microworld. Journal of Educational Psychology, 86(3), 368–379.Imhof, B., Scheiter, K., Edelmann, J., & Gerjets, P. (2013). Learning about locomotion patterns: Effective useof multiple pictures and motion-indicating arrows. Computers & Education, 65, 45–55.Leinhardt, G., Zaslavsky, O., & Stein, M. K. (1990). Functions, graphs, and graphing: Tasks, learning, andteaching. Review of Educational Research, 60(1), 1–64. doi:10.2307/1170224Linn, M. C., & Eylon, B.-S. (2011). Science learning and instruction: Taking advantage of technology topromote knowledge integration. New York: Routledge.Mayer, R. E. (2001). Multimedia learning. New York: Cambridge University Press.Mokros, J., & Tinker, R. (1987). The impact of microcomputer-­‐based labs on children’s ability to interpretgraphs. Journal of Research in Science Teaching, 24(4), 369–383.Moreno, R. (2001). Designing for Understanding : A Learner-Centered Approach to Multimedia Learning.Cognition, (1999), 248–250. Retrieved from http://www.unm.edu/~moreno/conferences.htmNational Governers Association Center for Best Practices, C. of C. S. S. O. (2010). Common Core StateStandards. Washington, DC: National Governers Association Center for Best Practices, Council ofChief State School Officers.Ploetzner, R., Lippitsch, S., Galmbacher, M., Heuer, D., & Scherrer, S. (2009). Students’ difficulties in learningfrom dynamic visualisations and how they may be overcome. Computers in Human Behavior, 25, 56–65.Quintana, C., Reiser, B. J., Davis, E. A., Krajcik, J., Fretz, E., & Duncan, R. G. (2004). A scaffolding designframework for software to support science inquiry. The Journal of the Learning Sciences, 13(3), 337–386.Roschelle, J., Kaput, J., & Stroup, W. (2000). SimCalc : Accelerating students’ engagement with themathematics of change. In M. J. Jacobson & R. B. Kozma (Eds.), Innovations in science andmathematics education: Advanced designs for technologies of learning (pp. 47–75). Lawrence ErlbaumAssociates.Ryoo, K., & Linn, M. C. (2012). Automated feedback in a computer-based diagramming tool to help studentsdistinguish among energy ideas in life science. In Poster presented at the annual meeting of theAmerican Education Research Association in San Francisco, CA.Shah, P., & Hoeffner, J. (2002). Review of graph comprehension research: Implications for instruction.Educational Psychology Review, 14(1), 47–69.Sweller, J. (1988). Cognitive load during problem solving: Effects on learning. Cognitive Science, 12, 257–285.Vitale, J. M., Black, J. B., & Swart, M. I. (2013). Applying grounded coordination challenges to concretelearning materials: A study of number line estimation. Journal of Educational Psychology, Advance on.Zhang, J., & Norman, D. A. (1994). Representations in distributed cognitive tasks. Cognitive Science, 22, 87–122.ICLS 2014 Proceedings776© ISLS